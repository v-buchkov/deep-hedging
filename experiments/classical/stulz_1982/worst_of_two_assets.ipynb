{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-23T19:09:00.999486Z",
     "start_time": "2024-07-23T19:08:58.197164Z"
    }
   },
   "source": [
    "!pip install yfinance\n",
    "!pip install pandas_datareader"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: yfinance in /Users/buchkovv/lib/python3.10/site-packages (0.2.38)\r\n",
      "Requirement already satisfied: pandas>=1.3.0 in /Users/buchkovv/lib/python3.10/site-packages (from yfinance) (2.2.1)\r\n",
      "Requirement already satisfied: numpy>=1.16.5 in /Users/buchkovv/lib/python3.10/site-packages (from yfinance) (1.26.4)\r\n",
      "Requirement already satisfied: requests>=2.31 in /Users/buchkovv/lib/python3.10/site-packages (from yfinance) (2.31.0)\r\n",
      "Requirement already satisfied: multitasking>=0.0.7 in /Users/buchkovv/lib/python3.10/site-packages (from yfinance) (0.0.11)\r\n",
      "Requirement already satisfied: lxml>=4.9.1 in /Users/buchkovv/lib/python3.10/site-packages (from yfinance) (5.2.1)\r\n",
      "Requirement already satisfied: appdirs>=1.4.4 in /Users/buchkovv/lib/python3.10/site-packages (from yfinance) (1.4.4)\r\n",
      "Requirement already satisfied: pytz>=2022.5 in /Users/buchkovv/lib/python3.10/site-packages (from yfinance) (2024.1)\r\n",
      "Requirement already satisfied: frozendict>=2.3.4 in /Users/buchkovv/lib/python3.10/site-packages (from yfinance) (2.4.2)\r\n",
      "Requirement already satisfied: peewee>=3.16.2 in /Users/buchkovv/lib/python3.10/site-packages (from yfinance) (3.17.3)\r\n",
      "Requirement already satisfied: beautifulsoup4>=4.11.1 in /Users/buchkovv/lib/python3.10/site-packages (from yfinance) (4.12.3)\r\n",
      "Requirement already satisfied: html5lib>=1.1 in /Users/buchkovv/lib/python3.10/site-packages (from yfinance) (1.1)\r\n",
      "Requirement already satisfied: soupsieve>1.2 in /Users/buchkovv/lib/python3.10/site-packages (from beautifulsoup4>=4.11.1->yfinance) (2.5)\r\n",
      "Requirement already satisfied: six>=1.9 in /Users/buchkovv/lib/python3.10/site-packages (from html5lib>=1.1->yfinance) (1.16.0)\r\n",
      "Requirement already satisfied: webencodings in /Users/buchkovv/lib/python3.10/site-packages (from html5lib>=1.1->yfinance) (0.5.1)\r\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/buchkovv/lib/python3.10/site-packages (from pandas>=1.3.0->yfinance) (2.8.2)\r\n",
      "Requirement already satisfied: tzdata>=2022.7 in /Users/buchkovv/lib/python3.10/site-packages (from pandas>=1.3.0->yfinance) (2024.1)\r\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/buchkovv/lib/python3.10/site-packages (from requests>=2.31->yfinance) (3.3.2)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/buchkovv/lib/python3.10/site-packages (from requests>=2.31->yfinance) (3.6)\r\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/buchkovv/lib/python3.10/site-packages (from requests>=2.31->yfinance) (2.2.1)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/buchkovv/lib/python3.10/site-packages (from requests>=2.31->yfinance) (2024.2.2)\r\n",
      "\r\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m A new release of pip is available: \u001B[0m\u001B[31;49m23.3.2\u001B[0m\u001B[39;49m -> \u001B[0m\u001B[32;49m24.1.2\u001B[0m\r\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m To update, run: \u001B[0m\u001B[32;49mpip install --upgrade pip\u001B[0m\r\n",
      "Requirement already satisfied: pandas_datareader in /Users/buchkovv/lib/python3.10/site-packages (0.10.0)\r\n",
      "Requirement already satisfied: lxml in /Users/buchkovv/lib/python3.10/site-packages (from pandas_datareader) (5.2.1)\r\n",
      "Requirement already satisfied: pandas>=0.23 in /Users/buchkovv/lib/python3.10/site-packages (from pandas_datareader) (2.2.1)\r\n",
      "Requirement already satisfied: requests>=2.19.0 in /Users/buchkovv/lib/python3.10/site-packages (from pandas_datareader) (2.31.0)\r\n",
      "Requirement already satisfied: numpy<2,>=1.22.4 in /Users/buchkovv/lib/python3.10/site-packages (from pandas>=0.23->pandas_datareader) (1.26.4)\r\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/buchkovv/lib/python3.10/site-packages (from pandas>=0.23->pandas_datareader) (2.8.2)\r\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/buchkovv/lib/python3.10/site-packages (from pandas>=0.23->pandas_datareader) (2024.1)\r\n",
      "Requirement already satisfied: tzdata>=2022.7 in /Users/buchkovv/lib/python3.10/site-packages (from pandas>=0.23->pandas_datareader) (2024.1)\r\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/buchkovv/lib/python3.10/site-packages (from requests>=2.19.0->pandas_datareader) (3.3.2)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/buchkovv/lib/python3.10/site-packages (from requests>=2.19.0->pandas_datareader) (3.6)\r\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/buchkovv/lib/python3.10/site-packages (from requests>=2.19.0->pandas_datareader) (2.2.1)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/buchkovv/lib/python3.10/site-packages (from requests>=2.19.0->pandas_datareader) (2024.2.2)\r\n",
      "Requirement already satisfied: six>=1.5 in /Users/buchkovv/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas>=0.23->pandas_datareader) (1.16.0)\r\n",
      "\r\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m A new release of pip is available: \u001B[0m\u001B[31;49m23.3.2\u001B[0m\u001B[39;49m -> \u001B[0m\u001B[32;49m24.1.2\u001B[0m\r\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m To update, run: \u001B[0m\u001B[32;49mpip install --upgrade pip\u001B[0m\r\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-23T19:09:01.051318Z",
     "start_time": "2024-07-23T19:09:01.033793Z"
    }
   },
   "cell_type": "code",
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ],
   "id": "57d710d26b23ae75",
   "outputs": [],
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "id": "4a0f0569e6e7983e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-23T19:09:03.042485Z",
     "start_time": "2024-07-23T19:09:01.054006Z"
    }
   },
   "source": [
    "import abc\n",
    "import datetime as dt\n",
    "from dataclasses import dataclass\n",
    "from typing import Callable\n",
    "from enum import Enum\n",
    "from tqdm import tqdm\n",
    "\n",
    "from functools import lru_cache\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import stats\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as mtick\n",
    "\n",
    "import pandas_datareader.data as reader\n",
    "import yfinance as yfin\n",
    "\n",
    "yfin.pdr_override()\n",
    "RANDOM_SEED = 12"
   ],
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 0. Investment Idea.",
   "id": "d608c9b15d581e6d"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "**Idea**: *Long correlation in dividend stocks, as investors will rebalance from bonds to dividend stock simultaneously due to expectation of lower interest rates.*\\\n",
    "**Product**: *BarrierReverseConvertible*\\\n",
    "**Target Client**: *Retail / Private / UHNWI that seeks bond-like payoff*\n",
    "\n",
    "**Description**:\\\n",
    "It is no secret for anyone that the past period of QE have driven CBs around the world to the point, where they need to switch to QT very rapidly. Therefore, current high level of interest rates across the globe has allowed economies to slow down to presumably sufficient speed of growth (i.e., inflation has successfully slowed down).\n",
    "\n",
    "However, as CBs are expected to start lowering the rates soon, which seems to be quite an obvious scenario for the market, such a movement is already priced in. Thus, how can we profit from such a prediction further, without interfering into the markets guessing game with the Fed?\n",
    "\n",
    "The idea is to use the prediction for our advantage via trading second moments of the stock returns. As the **interest rates will go down**, investors that aim to have stable fixed income will likely start to look into **another sources of cash flows, such as dividend stocks**. Therefore, as many investors will sell bonds and **enter dividend stocks simultaneously, their correlation is expected to rise**.\n",
    "\n",
    "Thus, investment idea is for client to buy a structure that will provide resemblence with the bonds by its payoff and be long correlation between dividend stocks. Therefore, we should offer clients such product."
   ],
   "id": "6267be8d355bcb45"
  },
  {
   "cell_type": "markdown",
   "id": "98ab4886887f17b0",
   "metadata": {},
   "source": [
    "## 1. Market Data for Stocks."
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Let's download stocks data for S&P500 Index Constituents. The S&P500 stocks are chosen to be liquid enough for hedging greeks and to be familiar for the client that will buy the structure.",
   "id": "76834246bda64d14"
  },
  {
   "cell_type": "code",
   "id": "89fc21ecce6a762",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-23T19:09:03.091160Z",
     "start_time": "2024-07-23T19:09:03.057833Z"
    }
   },
   "source": [
    "N_YEARS = 20\n",
    "YEARS_TILL_MATURITY = 3\n",
    "TODAY = dt.datetime(2024, 5, 3)\n",
    "\n",
    "DIVIDEND_N_YEARS = 1\n",
    "N_STOCKS = 3"
   ],
   "outputs": [],
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "id": "999279d1ed5d3f0d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-23T19:09:03.646197Z",
     "start_time": "2024-07-23T19:09:03.092533Z"
    }
   },
   "source": [
    "SPX_TICKERS = pd.read_html(\"https://en.wikipedia.org/wiki/List_of_S%26P_500_companies\")[\n",
    "    0\n",
    "]\n",
    "SPX_TICKERS"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "    Symbol            Security             GICS Sector  \\\n",
       "0      MMM                  3M             Industrials   \n",
       "1      AOS         A. O. Smith             Industrials   \n",
       "2      ABT              Abbott             Health Care   \n",
       "3     ABBV              AbbVie             Health Care   \n",
       "4      ACN           Accenture  Information Technology   \n",
       "..     ...                 ...                     ...   \n",
       "498    XYL          Xylem Inc.             Industrials   \n",
       "499    YUM         Yum! Brands  Consumer Discretionary   \n",
       "500   ZBRA  Zebra Technologies  Information Technology   \n",
       "501    ZBH       Zimmer Biomet             Health Care   \n",
       "502    ZTS              Zoetis             Health Care   \n",
       "\n",
       "                                GICS Sub-Industry    Headquarters Location  \\\n",
       "0                        Industrial Conglomerates    Saint Paul, Minnesota   \n",
       "1                               Building Products     Milwaukee, Wisconsin   \n",
       "2                           Health Care Equipment  North Chicago, Illinois   \n",
       "3                                   Biotechnology  North Chicago, Illinois   \n",
       "4                  IT Consulting & Other Services          Dublin, Ireland   \n",
       "..                                            ...                      ...   \n",
       "498  Industrial Machinery & Supplies & Components   White Plains, New York   \n",
       "499                                   Restaurants     Louisville, Kentucky   \n",
       "500            Electronic Equipment & Instruments   Lincolnshire, Illinois   \n",
       "501                         Health Care Equipment          Warsaw, Indiana   \n",
       "502                               Pharmaceuticals   Parsippany, New Jersey   \n",
       "\n",
       "     Date added      CIK      Founded  \n",
       "0    1957-03-04    66740         1902  \n",
       "1    2017-07-26    91142         1916  \n",
       "2    1957-03-04     1800         1888  \n",
       "3    2012-12-31  1551152  2013 (1888)  \n",
       "4    2011-07-06  1467373         1989  \n",
       "..          ...      ...          ...  \n",
       "498  2011-11-01  1524472         2011  \n",
       "499  1997-10-06  1041061         1997  \n",
       "500  2019-12-23   877212         1969  \n",
       "501  2001-08-07  1136869         1927  \n",
       "502  2013-06-21  1555280         1952  \n",
       "\n",
       "[503 rows x 8 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Symbol</th>\n",
       "      <th>Security</th>\n",
       "      <th>GICS Sector</th>\n",
       "      <th>GICS Sub-Industry</th>\n",
       "      <th>Headquarters Location</th>\n",
       "      <th>Date added</th>\n",
       "      <th>CIK</th>\n",
       "      <th>Founded</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MMM</td>\n",
       "      <td>3M</td>\n",
       "      <td>Industrials</td>\n",
       "      <td>Industrial Conglomerates</td>\n",
       "      <td>Saint Paul, Minnesota</td>\n",
       "      <td>1957-03-04</td>\n",
       "      <td>66740</td>\n",
       "      <td>1902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AOS</td>\n",
       "      <td>A. O. Smith</td>\n",
       "      <td>Industrials</td>\n",
       "      <td>Building Products</td>\n",
       "      <td>Milwaukee, Wisconsin</td>\n",
       "      <td>2017-07-26</td>\n",
       "      <td>91142</td>\n",
       "      <td>1916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ABT</td>\n",
       "      <td>Abbott</td>\n",
       "      <td>Health Care</td>\n",
       "      <td>Health Care Equipment</td>\n",
       "      <td>North Chicago, Illinois</td>\n",
       "      <td>1957-03-04</td>\n",
       "      <td>1800</td>\n",
       "      <td>1888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ABBV</td>\n",
       "      <td>AbbVie</td>\n",
       "      <td>Health Care</td>\n",
       "      <td>Biotechnology</td>\n",
       "      <td>North Chicago, Illinois</td>\n",
       "      <td>2012-12-31</td>\n",
       "      <td>1551152</td>\n",
       "      <td>2013 (1888)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ACN</td>\n",
       "      <td>Accenture</td>\n",
       "      <td>Information Technology</td>\n",
       "      <td>IT Consulting &amp; Other Services</td>\n",
       "      <td>Dublin, Ireland</td>\n",
       "      <td>2011-07-06</td>\n",
       "      <td>1467373</td>\n",
       "      <td>1989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498</th>\n",
       "      <td>XYL</td>\n",
       "      <td>Xylem Inc.</td>\n",
       "      <td>Industrials</td>\n",
       "      <td>Industrial Machinery &amp; Supplies &amp; Components</td>\n",
       "      <td>White Plains, New York</td>\n",
       "      <td>2011-11-01</td>\n",
       "      <td>1524472</td>\n",
       "      <td>2011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499</th>\n",
       "      <td>YUM</td>\n",
       "      <td>Yum! Brands</td>\n",
       "      <td>Consumer Discretionary</td>\n",
       "      <td>Restaurants</td>\n",
       "      <td>Louisville, Kentucky</td>\n",
       "      <td>1997-10-06</td>\n",
       "      <td>1041061</td>\n",
       "      <td>1997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>500</th>\n",
       "      <td>ZBRA</td>\n",
       "      <td>Zebra Technologies</td>\n",
       "      <td>Information Technology</td>\n",
       "      <td>Electronic Equipment &amp; Instruments</td>\n",
       "      <td>Lincolnshire, Illinois</td>\n",
       "      <td>2019-12-23</td>\n",
       "      <td>877212</td>\n",
       "      <td>1969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>501</th>\n",
       "      <td>ZBH</td>\n",
       "      <td>Zimmer Biomet</td>\n",
       "      <td>Health Care</td>\n",
       "      <td>Health Care Equipment</td>\n",
       "      <td>Warsaw, Indiana</td>\n",
       "      <td>2001-08-07</td>\n",
       "      <td>1136869</td>\n",
       "      <td>1927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>502</th>\n",
       "      <td>ZTS</td>\n",
       "      <td>Zoetis</td>\n",
       "      <td>Health Care</td>\n",
       "      <td>Pharmaceuticals</td>\n",
       "      <td>Parsippany, New Jersey</td>\n",
       "      <td>2013-06-21</td>\n",
       "      <td>1555280</td>\n",
       "      <td>1952</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>503 rows Ã— 8 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "id": "ccca8d8b13cbc72c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-23T19:09:03.668437Z",
     "start_time": "2024-07-23T19:09:03.648570Z"
    }
   },
   "source": [
    "tickers = SPX_TICKERS.copy()\n",
    "tickers[\"yfin\"] = tickers[\"Symbol\"].apply(lambda x: yfin.Ticker(x))"
   ],
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "For our investment idea we need to choose dividends aristocrats - stocks that pay **high** dividends in **stable** manner. Therefore, let's calculate the dividend ratio - it will allow to pick stocks that have large average dividend (**high**) with low standard deviation (**stable**).",
   "id": "7d65609f68b4937f"
  },
  {
   "cell_type": "code",
   "id": "646f686de3e1d4f1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-23T19:09:11.633174Z",
     "start_time": "2024-07-23T19:09:03.669435Z"
    }
   },
   "source": [
    "def get_average_dividends(ticker: yfin.Ticker) -> float:\n",
    "    yfin_data = ticker.dividends\n",
    "    if isinstance(yfin_data.index, pd.RangeIndex):\n",
    "        yfin_data.index = pd.DatetimeIndex(yfin_data.index).tz_localize(\"GMT\")\n",
    "\n",
    "    dividends = yfin_data[\n",
    "        yfin_data.index.tz_convert(None)\n",
    "        >= dt.datetime(TODAY.year - N_YEARS, TODAY.month, TODAY.day)\n",
    "    ]\n",
    "    dividends_std = dividends.std()\n",
    "\n",
    "    if dividends_std == 0:\n",
    "        return np.nan\n",
    "\n",
    "    dividend_ratio = dividends.mean() / dividends_std\n",
    "\n",
    "    if np.isinf(dividend_ratio) or np.isnan(dividend_ratio):\n",
    "        return np.nan\n",
    "\n",
    "    return dividend_ratio\n",
    "\n",
    "\n",
    "tickers[\"avg_div\"] = tickers[\"yfin\"].apply(lambda x: get_average_dividends(x)).fillna(0)\n",
    "tickers"
   ],
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[7], line 23\u001B[0m\n\u001B[1;32m     18\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m np\u001B[38;5;241m.\u001B[39mnan\n\u001B[1;32m     20\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m dividend_ratio\n\u001B[0;32m---> 23\u001B[0m tickers[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mavg_div\u001B[39m\u001B[38;5;124m\"\u001B[39m] \u001B[38;5;241m=\u001B[39m \u001B[43mtickers\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43myfin\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m]\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mapply\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43;01mlambda\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mx\u001B[49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mget_average_dividends\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241m.\u001B[39mfillna(\u001B[38;5;241m0\u001B[39m)\n\u001B[1;32m     24\u001B[0m tickers\n",
      "File \u001B[0;32m~/lib/python3.10/site-packages/pandas/core/series.py:4915\u001B[0m, in \u001B[0;36mSeries.apply\u001B[0;34m(self, func, convert_dtype, args, by_row, **kwargs)\u001B[0m\n\u001B[1;32m   4780\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mapply\u001B[39m(\n\u001B[1;32m   4781\u001B[0m     \u001B[38;5;28mself\u001B[39m,\n\u001B[1;32m   4782\u001B[0m     func: AggFuncType,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m   4787\u001B[0m     \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs,\n\u001B[1;32m   4788\u001B[0m ) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m DataFrame \u001B[38;5;241m|\u001B[39m Series:\n\u001B[1;32m   4789\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m   4790\u001B[0m \u001B[38;5;124;03m    Invoke function on values of Series.\u001B[39;00m\n\u001B[1;32m   4791\u001B[0m \n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m   4906\u001B[0m \u001B[38;5;124;03m    dtype: float64\u001B[39;00m\n\u001B[1;32m   4907\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[1;32m   4908\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mSeriesApply\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   4909\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m   4910\u001B[0m \u001B[43m        \u001B[49m\u001B[43mfunc\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   4911\u001B[0m \u001B[43m        \u001B[49m\u001B[43mconvert_dtype\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mconvert_dtype\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   4912\u001B[0m \u001B[43m        \u001B[49m\u001B[43mby_row\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mby_row\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   4913\u001B[0m \u001B[43m        \u001B[49m\u001B[43margs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   4914\u001B[0m \u001B[43m        \u001B[49m\u001B[43mkwargs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m-> 4915\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mapply\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/lib/python3.10/site-packages/pandas/core/apply.py:1427\u001B[0m, in \u001B[0;36mSeriesApply.apply\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m   1424\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mapply_compat()\n\u001B[1;32m   1426\u001B[0m \u001B[38;5;66;03m# self.func is Callable\u001B[39;00m\n\u001B[0;32m-> 1427\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mapply_standard\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/lib/python3.10/site-packages/pandas/core/apply.py:1507\u001B[0m, in \u001B[0;36mSeriesApply.apply_standard\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m   1501\u001B[0m \u001B[38;5;66;03m# row-wise access\u001B[39;00m\n\u001B[1;32m   1502\u001B[0m \u001B[38;5;66;03m# apply doesn't have a `na_action` keyword and for backward compat reasons\u001B[39;00m\n\u001B[1;32m   1503\u001B[0m \u001B[38;5;66;03m# we need to give `na_action=\"ignore\"` for categorical data.\u001B[39;00m\n\u001B[1;32m   1504\u001B[0m \u001B[38;5;66;03m# TODO: remove the `na_action=\"ignore\"` when that default has been changed in\u001B[39;00m\n\u001B[1;32m   1505\u001B[0m \u001B[38;5;66;03m#  Categorical (GH51645).\u001B[39;00m\n\u001B[1;32m   1506\u001B[0m action \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mignore\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(obj\u001B[38;5;241m.\u001B[39mdtype, CategoricalDtype) \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m-> 1507\u001B[0m mapped \u001B[38;5;241m=\u001B[39m \u001B[43mobj\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_map_values\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   1508\u001B[0m \u001B[43m    \u001B[49m\u001B[43mmapper\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcurried\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mna_action\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43maction\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mconvert\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mconvert_dtype\u001B[49m\n\u001B[1;32m   1509\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1511\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(mapped) \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(mapped[\u001B[38;5;241m0\u001B[39m], ABCSeries):\n\u001B[1;32m   1512\u001B[0m     \u001B[38;5;66;03m# GH#43986 Need to do list(mapped) in order to get treated as nested\u001B[39;00m\n\u001B[1;32m   1513\u001B[0m     \u001B[38;5;66;03m#  See also GH#25959 regarding EA support\u001B[39;00m\n\u001B[1;32m   1514\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m obj\u001B[38;5;241m.\u001B[39m_constructor_expanddim(\u001B[38;5;28mlist\u001B[39m(mapped), index\u001B[38;5;241m=\u001B[39mobj\u001B[38;5;241m.\u001B[39mindex)\n",
      "File \u001B[0;32m~/lib/python3.10/site-packages/pandas/core/base.py:921\u001B[0m, in \u001B[0;36mIndexOpsMixin._map_values\u001B[0;34m(self, mapper, na_action, convert)\u001B[0m\n\u001B[1;32m    918\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(arr, ExtensionArray):\n\u001B[1;32m    919\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m arr\u001B[38;5;241m.\u001B[39mmap(mapper, na_action\u001B[38;5;241m=\u001B[39mna_action)\n\u001B[0;32m--> 921\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43malgorithms\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmap_array\u001B[49m\u001B[43m(\u001B[49m\u001B[43marr\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmapper\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mna_action\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mna_action\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mconvert\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mconvert\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/lib/python3.10/site-packages/pandas/core/algorithms.py:1743\u001B[0m, in \u001B[0;36mmap_array\u001B[0;34m(arr, mapper, na_action, convert)\u001B[0m\n\u001B[1;32m   1741\u001B[0m values \u001B[38;5;241m=\u001B[39m arr\u001B[38;5;241m.\u001B[39mastype(\u001B[38;5;28mobject\u001B[39m, copy\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m)\n\u001B[1;32m   1742\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m na_action \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m-> 1743\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mlib\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmap_infer\u001B[49m\u001B[43m(\u001B[49m\u001B[43mvalues\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmapper\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mconvert\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mconvert\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1744\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m   1745\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m lib\u001B[38;5;241m.\u001B[39mmap_infer_mask(\n\u001B[1;32m   1746\u001B[0m         values, mapper, mask\u001B[38;5;241m=\u001B[39misna(values)\u001B[38;5;241m.\u001B[39mview(np\u001B[38;5;241m.\u001B[39muint8), convert\u001B[38;5;241m=\u001B[39mconvert\n\u001B[1;32m   1747\u001B[0m     )\n",
      "File \u001B[0;32mlib.pyx:2972\u001B[0m, in \u001B[0;36mpandas._libs.lib.map_infer\u001B[0;34m()\u001B[0m\n",
      "Cell \u001B[0;32mIn[7], line 23\u001B[0m, in \u001B[0;36m<lambda>\u001B[0;34m(x)\u001B[0m\n\u001B[1;32m     18\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m np\u001B[38;5;241m.\u001B[39mnan\n\u001B[1;32m     20\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m dividend_ratio\n\u001B[0;32m---> 23\u001B[0m tickers[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mavg_div\u001B[39m\u001B[38;5;124m\"\u001B[39m] \u001B[38;5;241m=\u001B[39m tickers[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124myfin\u001B[39m\u001B[38;5;124m\"\u001B[39m]\u001B[38;5;241m.\u001B[39mapply(\u001B[38;5;28;01mlambda\u001B[39;00m x: \u001B[43mget_average_dividends\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m)\u001B[49m)\u001B[38;5;241m.\u001B[39mfillna(\u001B[38;5;241m0\u001B[39m)\n\u001B[1;32m     24\u001B[0m tickers\n",
      "Cell \u001B[0;32mIn[7], line 2\u001B[0m, in \u001B[0;36mget_average_dividends\u001B[0;34m(ticker)\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mget_average_dividends\u001B[39m(ticker: yfin\u001B[38;5;241m.\u001B[39mTicker) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m \u001B[38;5;28mfloat\u001B[39m:\n\u001B[0;32m----> 2\u001B[0m     yfin_data \u001B[38;5;241m=\u001B[39m \u001B[43mticker\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdividends\u001B[49m\n\u001B[1;32m      3\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(yfin_data\u001B[38;5;241m.\u001B[39mindex, pd\u001B[38;5;241m.\u001B[39mRangeIndex):\n\u001B[1;32m      4\u001B[0m         yfin_data\u001B[38;5;241m.\u001B[39mindex \u001B[38;5;241m=\u001B[39m pd\u001B[38;5;241m.\u001B[39mDatetimeIndex(yfin_data\u001B[38;5;241m.\u001B[39mindex)\u001B[38;5;241m.\u001B[39mtz_localize(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mGMT\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "File \u001B[0;32m~/lib/python3.10/site-packages/yfinance/ticker.py:135\u001B[0m, in \u001B[0;36mTicker.dividends\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    133\u001B[0m \u001B[38;5;129m@property\u001B[39m\n\u001B[1;32m    134\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mdividends\u001B[39m(\u001B[38;5;28mself\u001B[39m) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m _pd\u001B[38;5;241m.\u001B[39mSeries:\n\u001B[0;32m--> 135\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget_dividends\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/lib/python3.10/site-packages/yfinance/base.py:393\u001B[0m, in \u001B[0;36mTickerBase.get_dividends\u001B[0;34m(self, proxy)\u001B[0m\n\u001B[1;32m    392\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mget_dividends\u001B[39m(\u001B[38;5;28mself\u001B[39m, proxy\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m pd\u001B[38;5;241m.\u001B[39mSeries:\n\u001B[0;32m--> 393\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_lazy_load_price_history\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget_dividends\u001B[49m\u001B[43m(\u001B[49m\u001B[43mproxy\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/lib/python3.10/site-packages/yfinance/scrapers/history.py:396\u001B[0m, in \u001B[0;36mPriceHistory.get_dividends\u001B[0;34m(self, proxy)\u001B[0m\n\u001B[1;32m    394\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mget_dividends\u001B[39m(\u001B[38;5;28mself\u001B[39m, proxy\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m pd\u001B[38;5;241m.\u001B[39mSeries:\n\u001B[1;32m    395\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_history \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m--> 396\u001B[0m         \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mhistory\u001B[49m\u001B[43m(\u001B[49m\u001B[43mperiod\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mmax\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mproxy\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mproxy\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    397\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_history \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mDividends\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_history:\n\u001B[1;32m    398\u001B[0m         dividends \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_history[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mDividends\u001B[39m\u001B[38;5;124m\"\u001B[39m]\n",
      "File \u001B[0;32m~/lib/python3.10/site-packages/yfinance/utils.py:103\u001B[0m, in \u001B[0;36mlog_indent_decorator.<locals>.wrapper\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    100\u001B[0m logger\u001B[38;5;241m.\u001B[39mdebug(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mEntering \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mfunc\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__name__\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m()\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[1;32m    102\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m IndentationContext():\n\u001B[0;32m--> 103\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    105\u001B[0m logger\u001B[38;5;241m.\u001B[39mdebug(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mExiting \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mfunc\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__name__\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m()\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[1;32m    106\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m result\n",
      "File \u001B[0;32m~/lib/python3.10/site-packages/yfinance/scrapers/history.py:139\u001B[0m, in \u001B[0;36mPriceHistory.history\u001B[0;34m(self, period, interval, start, end, prepost, actions, auto_adjust, back_adjust, repair, keepna, proxy, rounding, timeout, raise_errors)\u001B[0m\n\u001B[1;32m    137\u001B[0m         get_fn \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_data\u001B[38;5;241m.\u001B[39mcache_get\n\u001B[1;32m    138\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m--> 139\u001B[0m     data \u001B[38;5;241m=\u001B[39m \u001B[43mget_fn\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    140\u001B[0m \u001B[43m        \u001B[49m\u001B[43murl\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43murl\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    141\u001B[0m \u001B[43m        \u001B[49m\u001B[43mparams\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mparams\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    142\u001B[0m \u001B[43m        \u001B[49m\u001B[43mproxy\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mproxy\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    143\u001B[0m \u001B[43m        \u001B[49m\u001B[43mtimeout\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtimeout\u001B[49m\n\u001B[1;32m    144\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    145\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mWill be right back\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;129;01min\u001B[39;00m data\u001B[38;5;241m.\u001B[39mtext \u001B[38;5;129;01mor\u001B[39;00m data \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m    146\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mRuntimeError\u001B[39;00m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m*** YAHOO! FINANCE IS CURRENTLY DOWN! ***\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    147\u001B[0m                            \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mOur engineers are working quickly to resolve \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    148\u001B[0m                            \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mthe issue. Thank you for your patience.\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "File \u001B[0;32m~/lib/python3.10/site-packages/yfinance/utils.py:103\u001B[0m, in \u001B[0;36mlog_indent_decorator.<locals>.wrapper\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    100\u001B[0m logger\u001B[38;5;241m.\u001B[39mdebug(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mEntering \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mfunc\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__name__\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m()\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[1;32m    102\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m IndentationContext():\n\u001B[0;32m--> 103\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    105\u001B[0m logger\u001B[38;5;241m.\u001B[39mdebug(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mExiting \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mfunc\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__name__\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m()\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[1;32m    106\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m result\n",
      "File \u001B[0;32m~/lib/python3.10/site-packages/yfinance/data.py:367\u001B[0m, in \u001B[0;36mYfData.get\u001B[0;34m(self, url, user_agent_headers, params, proxy, timeout)\u001B[0m\n\u001B[1;32m    357\u001B[0m     cookies \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m    359\u001B[0m request_args \u001B[38;5;241m=\u001B[39m {\n\u001B[1;32m    360\u001B[0m     \u001B[38;5;124m'\u001B[39m\u001B[38;5;124murl\u001B[39m\u001B[38;5;124m'\u001B[39m: url,\n\u001B[1;32m    361\u001B[0m     \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mparams\u001B[39m\u001B[38;5;124m'\u001B[39m: {\u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mparams, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mcrumbs},\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    365\u001B[0m     \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mheaders\u001B[39m\u001B[38;5;124m'\u001B[39m: user_agent_headers \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39muser_agent_headers\n\u001B[1;32m    366\u001B[0m }\n\u001B[0;32m--> 367\u001B[0m response \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_session\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mrequest_args\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    368\u001B[0m utils\u001B[38;5;241m.\u001B[39mget_yf_logger()\u001B[38;5;241m.\u001B[39mdebug(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mresponse code=\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mresponse\u001B[38;5;241m.\u001B[39mstatus_code\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m'\u001B[39m)\n\u001B[1;32m    369\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m response\u001B[38;5;241m.\u001B[39mstatus_code \u001B[38;5;241m>\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m400\u001B[39m:\n\u001B[1;32m    370\u001B[0m     \u001B[38;5;66;03m# Retry with other cookie strategy\u001B[39;00m\n",
      "File \u001B[0;32m~/lib/python3.10/site-packages/requests/sessions.py:602\u001B[0m, in \u001B[0;36mSession.get\u001B[0;34m(self, url, **kwargs)\u001B[0m\n\u001B[1;32m    594\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124mr\u001B[39m\u001B[38;5;124;03m\"\"\"Sends a GET request. Returns :class:`Response` object.\u001B[39;00m\n\u001B[1;32m    595\u001B[0m \n\u001B[1;32m    596\u001B[0m \u001B[38;5;124;03m:param url: URL for the new :class:`Request` object.\u001B[39;00m\n\u001B[1;32m    597\u001B[0m \u001B[38;5;124;03m:param \\*\\*kwargs: Optional arguments that ``request`` takes.\u001B[39;00m\n\u001B[1;32m    598\u001B[0m \u001B[38;5;124;03m:rtype: requests.Response\u001B[39;00m\n\u001B[1;32m    599\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m    601\u001B[0m kwargs\u001B[38;5;241m.\u001B[39msetdefault(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mallow_redirects\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;28;01mTrue\u001B[39;00m)\n\u001B[0;32m--> 602\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrequest\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mGET\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43murl\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/lib/python3.10/site-packages/requests/sessions.py:589\u001B[0m, in \u001B[0;36mSession.request\u001B[0;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001B[0m\n\u001B[1;32m    584\u001B[0m send_kwargs \u001B[38;5;241m=\u001B[39m {\n\u001B[1;32m    585\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtimeout\u001B[39m\u001B[38;5;124m\"\u001B[39m: timeout,\n\u001B[1;32m    586\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mallow_redirects\u001B[39m\u001B[38;5;124m\"\u001B[39m: allow_redirects,\n\u001B[1;32m    587\u001B[0m }\n\u001B[1;32m    588\u001B[0m send_kwargs\u001B[38;5;241m.\u001B[39mupdate(settings)\n\u001B[0;32m--> 589\u001B[0m resp \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msend\u001B[49m\u001B[43m(\u001B[49m\u001B[43mprep\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43msend_kwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    591\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m resp\n",
      "File \u001B[0;32m~/lib/python3.10/site-packages/requests/sessions.py:747\u001B[0m, in \u001B[0;36mSession.send\u001B[0;34m(self, request, **kwargs)\u001B[0m\n\u001B[1;32m    744\u001B[0m         \u001B[38;5;28;01mpass\u001B[39;00m\n\u001B[1;32m    746\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m stream:\n\u001B[0;32m--> 747\u001B[0m     \u001B[43mr\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcontent\u001B[49m\n\u001B[1;32m    749\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m r\n",
      "File \u001B[0;32m~/lib/python3.10/site-packages/requests/models.py:899\u001B[0m, in \u001B[0;36mResponse.content\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    897\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_content \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m    898\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m--> 899\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_content \u001B[38;5;241m=\u001B[39m \u001B[38;5;124;43mb\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mjoin\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43miter_content\u001B[49m\u001B[43m(\u001B[49m\u001B[43mCONTENT_CHUNK_SIZE\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;124mb\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    901\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_content_consumed \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mTrue\u001B[39;00m\n\u001B[1;32m    902\u001B[0m \u001B[38;5;66;03m# don't need to release the connection; that's been handled by urllib3\u001B[39;00m\n\u001B[1;32m    903\u001B[0m \u001B[38;5;66;03m# since we exhausted the data.\u001B[39;00m\n",
      "File \u001B[0;32m~/lib/python3.10/site-packages/requests/models.py:816\u001B[0m, in \u001B[0;36mResponse.iter_content.<locals>.generate\u001B[0;34m()\u001B[0m\n\u001B[1;32m    814\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mhasattr\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mraw, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mstream\u001B[39m\u001B[38;5;124m\"\u001B[39m):\n\u001B[1;32m    815\u001B[0m     \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m--> 816\u001B[0m         \u001B[38;5;28;01myield from\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mraw\u001B[38;5;241m.\u001B[39mstream(chunk_size, decode_content\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m)\n\u001B[1;32m    817\u001B[0m     \u001B[38;5;28;01mexcept\u001B[39;00m ProtocolError \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[1;32m    818\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m ChunkedEncodingError(e)\n",
      "File \u001B[0;32m~/lib/python3.10/site-packages/urllib3/response.py:1040\u001B[0m, in \u001B[0;36mHTTPResponse.stream\u001B[0;34m(self, amt, decode_content)\u001B[0m\n\u001B[1;32m   1024\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m   1025\u001B[0m \u001B[38;5;124;03mA generator wrapper for the read() method. A call will block until\u001B[39;00m\n\u001B[1;32m   1026\u001B[0m \u001B[38;5;124;03m``amt`` bytes have been read from the connection or until the\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m   1037\u001B[0m \u001B[38;5;124;03m    'content-encoding' header.\u001B[39;00m\n\u001B[1;32m   1038\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m   1039\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mchunked \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39msupports_chunked_reads():\n\u001B[0;32m-> 1040\u001B[0m     \u001B[38;5;28;01myield from\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mread_chunked(amt, decode_content\u001B[38;5;241m=\u001B[39mdecode_content)\n\u001B[1;32m   1041\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m   1042\u001B[0m     \u001B[38;5;28;01mwhile\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m is_fp_closed(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_fp) \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_decoded_buffer) \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m0\u001B[39m:\n",
      "File \u001B[0;32m~/lib/python3.10/site-packages/urllib3/response.py:1184\u001B[0m, in \u001B[0;36mHTTPResponse.read_chunked\u001B[0;34m(self, amt, decode_content)\u001B[0m\n\u001B[1;32m   1181\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m   1183\u001B[0m \u001B[38;5;28;01mwhile\u001B[39;00m \u001B[38;5;28;01mTrue\u001B[39;00m:\n\u001B[0;32m-> 1184\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_update_chunk_length\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1185\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mchunk_left \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m0\u001B[39m:\n\u001B[1;32m   1186\u001B[0m         \u001B[38;5;28;01mbreak\u001B[39;00m\n",
      "File \u001B[0;32m~/lib/python3.10/site-packages/urllib3/response.py:1108\u001B[0m, in \u001B[0;36mHTTPResponse._update_chunk_length\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m   1106\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mchunk_left \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m   1107\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m-> 1108\u001B[0m line \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_fp\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfp\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mreadline\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m  \u001B[38;5;66;03m# type: ignore[union-attr]\u001B[39;00m\n\u001B[1;32m   1109\u001B[0m line \u001B[38;5;241m=\u001B[39m line\u001B[38;5;241m.\u001B[39msplit(\u001B[38;5;124mb\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m;\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;241m1\u001B[39m)[\u001B[38;5;241m0\u001B[39m]\n\u001B[1;32m   1110\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n",
      "File \u001B[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/socket.py:705\u001B[0m, in \u001B[0;36mSocketIO.readinto\u001B[0;34m(self, b)\u001B[0m\n\u001B[1;32m    703\u001B[0m \u001B[38;5;28;01mwhile\u001B[39;00m \u001B[38;5;28;01mTrue\u001B[39;00m:\n\u001B[1;32m    704\u001B[0m     \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m--> 705\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_sock\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrecv_into\u001B[49m\u001B[43m(\u001B[49m\u001B[43mb\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    706\u001B[0m     \u001B[38;5;28;01mexcept\u001B[39;00m timeout:\n\u001B[1;32m    707\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_timeout_occurred \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mTrue\u001B[39;00m\n",
      "File \u001B[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/ssl.py:1273\u001B[0m, in \u001B[0;36mSSLSocket.recv_into\u001B[0;34m(self, buffer, nbytes, flags)\u001B[0m\n\u001B[1;32m   1269\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m flags \u001B[38;5;241m!=\u001B[39m \u001B[38;5;241m0\u001B[39m:\n\u001B[1;32m   1270\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[1;32m   1271\u001B[0m           \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mnon-zero flags not allowed in calls to recv_into() on \u001B[39m\u001B[38;5;132;01m%s\u001B[39;00m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;241m%\u001B[39m\n\u001B[1;32m   1272\u001B[0m           \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__class__\u001B[39m)\n\u001B[0;32m-> 1273\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mread\u001B[49m\u001B[43m(\u001B[49m\u001B[43mnbytes\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mbuffer\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1274\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m   1275\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28msuper\u001B[39m()\u001B[38;5;241m.\u001B[39mrecv_into(buffer, nbytes, flags)\n",
      "File \u001B[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/ssl.py:1129\u001B[0m, in \u001B[0;36mSSLSocket.read\u001B[0;34m(self, len, buffer)\u001B[0m\n\u001B[1;32m   1127\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m   1128\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m buffer \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m-> 1129\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_sslobj\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mread\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mlen\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mbuffer\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1130\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m   1131\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_sslobj\u001B[38;5;241m.\u001B[39mread(\u001B[38;5;28mlen\u001B[39m)\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "tickers[\"market_cap\"] = (\n",
    "    tickers[\"yfin\"].apply(lambda x: get_average_dividends(x)).fillna(0)\n",
    ")\n",
    "tickers"
   ],
   "id": "3a07481304b4775a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Further, let's download market data that will provide us needed statistical metrics for modelling the paths in Monte Carlo.",
   "id": "3445faca05f6af58"
  },
  {
   "cell_type": "code",
   "id": "81372f7d35b03e08",
   "metadata": {},
   "source": [
    "@dataclass\n",
    "class Ticker:\n",
    "    name: str\n",
    "    code: str\n",
    "\n",
    "\n",
    "class Tickers:\n",
    "    def __init__(self, tickers: list[Ticker]):\n",
    "        self._tickers = tickers\n",
    "\n",
    "        self._ticker_dict = self._get_ticker_dict(tickers)\n",
    "        self._ticker_inverse_dict = self._get_ticker_inverse_dict(tickers)\n",
    "\n",
    "        self.names = list(self._ticker_dict.keys())\n",
    "        self.codes = list(self._ticker_dict.values())\n",
    "\n",
    "    @staticmethod\n",
    "    def _get_ticker_dict(tickers: list[Ticker]) -> dict[str, str]:\n",
    "        return {ticker.name: ticker.code for ticker in tickers}\n",
    "\n",
    "    @staticmethod\n",
    "    def _get_ticker_inverse_dict(tickers: list[Ticker]) -> dict[str, str]:\n",
    "        return {ticker.code: ticker.name for ticker in tickers}\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self._tickers)\n",
    "\n",
    "    def __getitem__(self, item: [int, str]) -> [str, None]:\n",
    "        if isinstance(item, int):\n",
    "            return self._tickers[item]\n",
    "        elif isinstance(item, str):\n",
    "            if item in self._ticker_dict.keys():\n",
    "                return self.get(item)\n",
    "            elif item in self._ticker_inverse_dict.keys():\n",
    "                return self.get_inverse(item)\n",
    "            else:\n",
    "                return None\n",
    "        else:\n",
    "            raise TypeError(f\"Item {item} is not a valid ticker or index\")\n",
    "\n",
    "    def get(self, name: str) -> str:\n",
    "        return self._ticker_dict[name]\n",
    "\n",
    "    def get_inverse(self, code: str) -> str:\n",
    "        return self._ticker_inverse_dict[code]\n",
    "\n",
    "    def __iter__(self):\n",
    "        return iter(self._tickers)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "73b5dc6bccf308c5",
   "metadata": {},
   "source": [
    "class MarketData:\n",
    "    TRADING_DAYS = 252\n",
    "    TARGET_COLUMN = \"Adj Close\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        tickers: Tickers,\n",
    "        start: [dt.datetime, int],\n",
    "        end: dt.datetime,\n",
    "        sampling_period: str = \"D\",\n",
    "    ):\n",
    "        self.df = None\n",
    "        self.sampling_period = sampling_period\n",
    "\n",
    "        self.tickers = tickers\n",
    "        self.end = end\n",
    "\n",
    "        if isinstance(start, dt.datetime):\n",
    "            self.start = start\n",
    "        else:\n",
    "            self.start = dt.date(self.end.year - N_YEARS, self.end.month, self.end.day)\n",
    "\n",
    "        self._initialize()\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.tickers)\n",
    "\n",
    "    def _load_yahoo(self) -> None:\n",
    "        self.df = reader.get_data_yahoo(self.tickers.codes, self.start, self.end)[\n",
    "            self.TARGET_COLUMN\n",
    "        ]\n",
    "\n",
    "    def _resample_data(self) -> None:\n",
    "        if self.df is None:\n",
    "            self._load_yahoo()\n",
    "        self.df = self.df.resample(self.sampling_period).first().dropna(axis=0)\n",
    "        self._df_returns = self.df.pct_change(fill_method=None).dropna(axis=0)\n",
    "\n",
    "    def _initialize(self) -> None:\n",
    "        self._load_yahoo()\n",
    "        self._resample_data()\n",
    "\n",
    "    def plot(self) -> None:\n",
    "        n_stocks = len(self._df_returns.columns)\n",
    "\n",
    "        ax = (\n",
    "            self._df_returns.stack()\n",
    "            .reset_index()\n",
    "            .rename(columns={0: \"return\"})\n",
    "            .hist(\n",
    "                column=\"return\",\n",
    "                by=\"Ticker\",\n",
    "                range=[self.df.min().min(), self.df.max().max()],\n",
    "                bins=100,\n",
    "                grid=False,\n",
    "                figsize=(16, 16),\n",
    "                layout=(n_stocks, 1),\n",
    "                sharex=True,\n",
    "                color=\"#86bf91\",\n",
    "                zorder=2,\n",
    "                rwidth=0.9,\n",
    "            )\n",
    "        )\n",
    "\n",
    "        for i, x in enumerate(ax):\n",
    "            x.tick_params(\n",
    "                axis=\"both\",\n",
    "                which=\"both\",\n",
    "                bottom=\"off\",\n",
    "                top=\"off\",\n",
    "                labelbottom=\"on\",\n",
    "                left=\"off\",\n",
    "                right=\"off\",\n",
    "                labelleft=\"on\",\n",
    "            )\n",
    "\n",
    "            vals = x.get_yticks()\n",
    "            for tick in vals:\n",
    "                x.axhline(\n",
    "                    y=tick, linestyle=\"dashed\", alpha=0.4, color=\"#eeeeee\", zorder=1\n",
    "                )\n",
    "\n",
    "            x.set_xlabel(\n",
    "                f\"Daily Return ({self.start.year}-{self.end.year})\",\n",
    "                labelpad=20,\n",
    "                weight=\"bold\",\n",
    "                size=16,\n",
    "            )\n",
    "\n",
    "            x.set_title(f\"{self.tickers[self.df.columns[i]]}\", size=12)\n",
    "\n",
    "            if i == n_stocks // 2:\n",
    "                x.set_ylabel(\"Frequency\", labelpad=50, weight=\"bold\", size=12)\n",
    "\n",
    "            x.tick_params(axis=\"x\", rotation=0)\n",
    "\n",
    "    def __getitem__(self, item: [int, str], *args, **kwargs):\n",
    "        if isinstance(item, int):\n",
    "            return self.df.iloc[:, item].values\n",
    "        elif isinstance(item, str):\n",
    "            if item in self.df.columns:\n",
    "                return self.df.loc[:, item].values\n",
    "            else:\n",
    "                return self.df.loc[:, self.tickers[item]].values\n",
    "        else:\n",
    "            raise TypeError(f\"Item {item} is not a valid ticker or index\")\n",
    "\n",
    "    def get_means(self) -> np.array:\n",
    "        return self._df_returns.mean().to_numpy() * self.TRADING_DAYS\n",
    "\n",
    "    def get_var_covar(self) -> np.array:\n",
    "        return self._df_returns.cov().to_numpy() * self.TRADING_DAYS\n",
    "\n",
    "    def get_corr(self) -> np.array:\n",
    "        return self._df_returns.corr().to_numpy()\n",
    "\n",
    "    @lru_cache(maxsize=None)\n",
    "    def get_dividends(self) -> np.array:\n",
    "        # return np.array([yfin.Ticker(ticker).dividends.iloc[-1] / 100 for ticker in self.tickers.codes])\n",
    "        return np.array([0 for ticker in self.tickers.codes])"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "6ddc18d7fe2ac747",
   "metadata": {},
   "source": [
    "## 2. Investment Idea."
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Let's get data to support our investment thesis and check that there is indeed negative correlation between rates and our top-3 dividend stocks.",
   "id": "ca8235b5a98bd020"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "tickers_no_outliers = tickers[(np.abs(stats.zscore(tickers[\"avg_div\"])) < 3)]\n",
    "top_dividend_stocks = tickers_no_outliers.sort_values(\"avg_div\", ascending=False).iloc[\n",
    "    :N_STOCKS, :\n",
    "]"
   ],
   "id": "9b166e990b05cf5b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "tickers_no_outliers",
   "id": "dd069ddd64401d3",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "market_data_tickers = Tickers(\n",
    "    top_dividend_stocks.apply(\n",
    "        lambda row: Ticker(name=row.Security, code=row.Symbol), axis=1\n",
    "    ).to_list()\n",
    ")\n",
    "market_data_tickers"
   ],
   "id": "5560cb99bbeec601",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "md = MarketData(market_data_tickers, N_YEARS, TODAY)",
   "id": "c72b033008403e70",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "How can we measure by some scalar metric that the correlation matrix indeed show higher correlation? We can simply calculate the mean correlation of upper triangle (or of all values, expect diagonal, as the matrix is symmetric) and check, if the correlation is indeed higher on average.",
   "id": "89ee29fc6c6e2ed8"
  },
  {
   "cell_type": "code",
   "id": "448a8e4dd7d5d90a",
   "metadata": {},
   "source": [
    "hist_corr = []\n",
    "for date, data in md.df.rolling(180).corr().dropna().groupby(level=0):\n",
    "    data = data.to_numpy()\n",
    "    np.fill_diagonal(data, 0)\n",
    "    hist_corr.append([date, data.mean()])\n",
    "hist_corr = pd.DataFrame(hist_corr, columns=[\"Date\", \"Corr\"]).set_index(\"Date\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "6f2b4f0c3d88cbbf",
   "metadata": {},
   "source": [
    "hist_corr"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "For interest rate ticker let's use ^FVX - 5-year UST rates. We need the rates of the term that is expected to match the period, at which the fixed income investors (which we expect to substitute respective bonds with the dividend stocks) usually look, when placing investment decisions. Therefore, 5 years seem to be an appropriate term.",
   "id": "e3a89206c5791452"
  },
  {
   "cell_type": "code",
   "id": "984053047518c249",
   "metadata": {},
   "source": [
    "IR_TICKER = \"^FVX\"\n",
    "md_ir = MarketData(\n",
    "    Tickers([Ticker(name=\"USD IR rate\", code=IR_TICKER)]), N_YEARS, TODAY\n",
    ")\n",
    "hist_corr.join(md_ir.df, how=\"left\").corr()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "We can see that the rates (absolute level) and correlations (absolute level, not change) exhibit **high negative correlation**, thus, **our investment thesis seems to be correct** - lower levels of interest rates can be expected to correlate with the higher correlation between our 3 dividend stocks, chosen for the target structure.\n",
    "\n",
    "However, as 5-year USTs correspond to market expectations of the future interest rates, investors may already be looking into substituting those by the dividend stocks in their portfolios, thus, this investment idea is driven not fully by the realized expectations of the market that we know now, but also dependent on the future movements of 5-year USTs - thus, we need to be careful with correct period of the maturity for our Barrier Reverse Convertible note."
   ],
   "id": "772a2785a3c0a15f"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Also, let's check the chart for the changes in the rate in absolute scale (first chart) and the scale that starts at 1 (second chart).",
   "id": "143d31757e4146fe"
  },
  {
   "cell_type": "code",
   "id": "4b90fc21b51ca58c",
   "metadata": {},
   "source": [
    "hist_corr.join(md_ir.df, how=\"left\").plot();"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "10cf5214b2ed231d",
   "metadata": {},
   "source": [
    "hist_corr.join(md_ir.df.pct_change().dropna().cumsum(), how=\"left\").plot();"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Moreover, we can notice that the **correlation is currently pretty close to the minimum** values across 4-year values, thus, the idea to **take correlation long** might prove to be reasonable from this standpoint too.",
   "id": "d585ceba30ebbdb8"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Therefore, our investment idea looks reasonable from the data analysis standpoint. Thus, let's fix the chosen stocks and move on with the pricing.",
   "id": "f041995ac1f812db"
  },
  {
   "cell_type": "code",
   "id": "9336117c4e814be9",
   "metadata": {},
   "source": [
    "for stock in md.tickers:\n",
    "    print(stock)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "54d373551595353a",
   "metadata": {},
   "source": [
    "## 3. Interest Rate Curve."
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "We also need to use correct interest rate for our calculations, as the interest rate should not be fixed throughout our Monte Carlo paths. Therefore, let's use Nelson-Siegel-Svensson interpolation of rates, taken from https://www.federalreserve.gov/data/nominal-yield-curve.htm.",
   "id": "4b90c852a6aebef8"
  },
  {
   "cell_type": "code",
   "id": "9594c581cce427a3",
   "metadata": {},
   "source": [
    "class YieldCurve:\n",
    "    TARGET_COLUMN = \"ytm\"\n",
    "    DISCOUNT_FACTOR_COLUMN = \"discount_factor\"\n",
    "    FWD_RATE_COLUMN = \"fwd_rate\"\n",
    "\n",
    "    def __init__(self, initial_terms: np.array, *args, **kwargs) -> None:\n",
    "        self._rates_df = None\n",
    "        self._discount_factors = None\n",
    "        self._instant_fwd_rate = None\n",
    "\n",
    "        self._initialize(initial_terms)\n",
    "\n",
    "    def _initialize(self, terms: np.array) -> None:\n",
    "        self.create_curve(terms=terms)\n",
    "\n",
    "    @abc.abstractmethod\n",
    "    def get_rates(self, terms: list[float]) -> np.array:\n",
    "        pass\n",
    "\n",
    "    def create_curve(self, terms: list[float]) -> None:\n",
    "        self._rates_df = pd.DataFrame(\n",
    "            self.get_rates(terms), index=terms, columns=[self.TARGET_COLUMN]\n",
    "        )\n",
    "        self._create_discount_factors()\n",
    "        self._create_instant_fwd_rates()\n",
    "\n",
    "    def _create_discount_factors(self) -> pd.DataFrame:\n",
    "        if self._rates_df is None:\n",
    "            raise ValueError(\"Rate data is not fitted yet!\")\n",
    "        discount_factors = np.exp(\n",
    "            -self._rates_df[self.TARGET_COLUMN] * self._rates_df.index\n",
    "        )\n",
    "        self._discount_factors = pd.DataFrame(\n",
    "            discount_factors,\n",
    "            index=self._rates_df.index,\n",
    "            columns=[self.DISCOUNT_FACTOR_COLUMN],\n",
    "        )\n",
    "        return self._discount_factors\n",
    "\n",
    "    def _create_instant_fwd_rates(self) -> pd.DataFrame:\n",
    "        if self._discount_factors is None:\n",
    "            raise ValueError(\"Discount factor data is not fitted yet!\")\n",
    "\n",
    "        t_old = self._rates_df.index[0]\n",
    "        instant_fwd_rates = []\n",
    "        for t in self._rates_df.index[1:]:\n",
    "            dt = t - t_old\n",
    "            instant_fwd_rates.append(\n",
    "                -1\n",
    "                / dt\n",
    "                * (\n",
    "                    np.log(\n",
    "                        self._discount_factors.loc[t, self.DISCOUNT_FACTOR_COLUMN]\n",
    "                        / self._discount_factors.loc[t_old, self.DISCOUNT_FACTOR_COLUMN]\n",
    "                    )\n",
    "                )\n",
    "            )\n",
    "            t_old = t\n",
    "        self._instant_fwd_rate = pd.DataFrame(\n",
    "            instant_fwd_rates,\n",
    "            index=self._rates_df.index[1:],\n",
    "            columns=[self.FWD_RATE_COLUMN],\n",
    "        )\n",
    "        return self._instant_fwd_rate\n",
    "\n",
    "    @property\n",
    "    def curve_df(self) -> pd.DataFrame:\n",
    "        if self._rates_df is None:\n",
    "            raise ValueError(\"Rate data is not fitted yet! Call .create_curve() first.\")\n",
    "        return self._rates_df\n",
    "\n",
    "    @property\n",
    "    def discount_factors_df(self) -> pd.DataFrame:\n",
    "        return self._discount_factors\n",
    "\n",
    "    @property\n",
    "    def instant_fwd_rates_df(self) -> pd.DataFrame:\n",
    "        return self._instant_fwd_rate\n",
    "\n",
    "    @staticmethod\n",
    "    def _find_point(curve: pd.DataFrame, term: float) -> float:\n",
    "        index = np.absolute(curve.index - term).argmin()\n",
    "        return curve.iloc[index].values[0]\n",
    "\n",
    "    @lru_cache(maxsize=None)\n",
    "    def get_rate(self, term: float) -> float:\n",
    "        return self._find_point(self._rates_df, term)\n",
    "\n",
    "    @lru_cache(maxsize=None)\n",
    "    def get_discount_factor(self, term: float) -> float:\n",
    "        return self._find_point(self._discount_factors, term)\n",
    "\n",
    "    @lru_cache(maxsize=None)\n",
    "    def get_instant_fwd_rate(self, term: float) -> float:\n",
    "        return self._find_point(self._instant_fwd_rate, term)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "a3a48236a6c196a3",
   "metadata": {},
   "source": [
    "class NelsonSiegelCurve(YieldCurve):\n",
    "    def __init__(\n",
    "        self,\n",
    "        b0: float,\n",
    "        b1: float,\n",
    "        b2: float,\n",
    "        tau: float,\n",
    "        initial_terms: np.array = np.linspace(1 / 365, 25.0, 100),\n",
    "    ) -> None:\n",
    "        self.b0 = b0\n",
    "        self.b1 = b1\n",
    "        self.b2 = b2\n",
    "        self.tau = tau\n",
    "\n",
    "        super().__init__(initial_terms)\n",
    "\n",
    "    def get_rates(self, terms: list[float]) -> np.array:\n",
    "        terms = np.array(terms)\n",
    "        rates = (\n",
    "            self.b0\n",
    "            + (self.b1 + self.b2) * self.tau / terms * (1 - np.exp(-terms / self.tau))\n",
    "            - self.b2 * np.exp(-terms / self.tau)\n",
    "        )\n",
    "        return rates / 100"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "715dd9f7022403d5",
   "metadata": {},
   "source": [
    "ns_params = pd.read_csv(\"data/feds200628.csv\", index_col=0).dropna(axis=0)\n",
    "ns_params"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "6d1c43658a8e7827",
   "metadata": {},
   "source": [
    "ns_curve = NelsonSiegelCurve(\n",
    "    b0=ns_params[\"BETA0\"].iloc[-1],\n",
    "    b1=ns_params[\"BETA1\"].iloc[-1],\n",
    "    b2=ns_params[\"BETA2\"].iloc[-1],\n",
    "    tau=ns_params[\"TAU1\"].iloc[-1],\n",
    ")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "3068171083267b8a",
   "metadata": {},
   "source": [
    "ns_curve.curve_df.plot();"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "67122079143d2a67",
   "metadata": {},
   "source": [
    "ns_curve.instant_fwd_rates_df.plot();"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "2446bde2241421f8",
   "metadata": {},
   "source": "## 4. Monte Carlo Modelling."
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Next step is to create a Monte Carlo pricer that will be used to determine the future value of a derivative.\n",
    "\n",
    "The pricer is implemented to have **maximum flexibility** in terms of coding framework. We **need to specify only a payoff function** to our pricer, and it will return the respective price of a derivative. Therefore, we do not have to implement Monte Carlo for each derivative, but can use this pricer for any payoff that we can possibly create."
   ],
   "id": "7086383d3f3a0a20"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "class MonteCarloPricer:\n",
    "    PATHS = 20_000\n",
    "    # PATHS = 1_000\n",
    "    TRADING_DAYS: int = 252\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        payoff_function: Callable[[np.array], float],\n",
    "        random_seed: [int, None] = RANDOM_SEED,\n",
    "    ):\n",
    "        self.payoff_function = payoff_function\n",
    "        self.random_seed = random_seed\n",
    "\n",
    "    def _geometric_brownian_motion(\n",
    "        self,\n",
    "        current_spot: list[float],\n",
    "        days_till_maturity: int,\n",
    "        risk_free_rate_fn: Callable[[float], float],\n",
    "        dividends_fn: Callable[[float], float],\n",
    "        var_covar_fn: Callable[[float], np.array],\n",
    "        n_paths: [int, None] = None,\n",
    "        *args,\n",
    "        **kwargs,\n",
    "    ) -> np.array:\n",
    "        if n_paths is None:\n",
    "            n_paths = self.PATHS\n",
    "\n",
    "        t = days_till_maturity\n",
    "        n_stocks = len(current_spot)\n",
    "\n",
    "        time = np.linspace(0, t / self.TRADING_DAYS, t)\n",
    "        d_time = time[1] - time[0]\n",
    "\n",
    "        drift = []\n",
    "        cholesky = []\n",
    "        for t in time:\n",
    "            var_covar = var_covar_fn(t)\n",
    "            drift.append(\n",
    "                [\n",
    "                    (\n",
    "                        risk_free_rate_fn(t)\n",
    "                        - dividends_fn(t)\n",
    "                        - 0.5 * np.diag(var_covar) ** 2\n",
    "                    )\n",
    "                    * d_time\n",
    "                ]\n",
    "            )\n",
    "            cholesky.append(np.linalg.cholesky(var_covar))\n",
    "\n",
    "        drift = np.array(drift).reshape(1, len(time), n_stocks, 1)\n",
    "        cholesky = np.array(cholesky).reshape(1, len(time), n_stocks, n_stocks)\n",
    "\n",
    "        np.random.seed(self.random_seed)\n",
    "        diffusion = (\n",
    "            cholesky\n",
    "            @ np.random.normal(0, 1, size=(n_paths, len(time), n_stocks, 1))\n",
    "            * np.sqrt(d_time)\n",
    "        )\n",
    "        paths = np.exp(drift + diffusion)\n",
    "        paths = np.insert(paths, 0, np.array(current_spot).reshape(1, 1, -1, 1), axis=1)\n",
    "        paths = np.cumprod(paths, axis=1).squeeze(3)\n",
    "\n",
    "        return paths\n",
    "\n",
    "    def get_paths(\n",
    "        self,\n",
    "        current_spot: list[float],\n",
    "        time_till_maturity: float,\n",
    "        risk_free_rate_fn: Callable[[float], float],\n",
    "        dividends_fn: Callable[[float], float],\n",
    "        var_covar_fn: Callable[[float], np.array],\n",
    "        n_paths: [int, None] = None,\n",
    "    ) -> np.array:\n",
    "        return self._geometric_brownian_motion(\n",
    "            current_spot=current_spot,\n",
    "            days_till_maturity=int(round(self.TRADING_DAYS * time_till_maturity)),\n",
    "            risk_free_rate_fn=risk_free_rate_fn,\n",
    "            dividends_fn=dividends_fn,\n",
    "            var_covar_fn=var_covar_fn,\n",
    "            n_paths=n_paths,\n",
    "        )\n",
    "\n",
    "    def get_future_value(\n",
    "        self,\n",
    "        current_spot: list[float],\n",
    "        time_till_maturity: float,\n",
    "        risk_free_rate_fn: Callable[[float], float],\n",
    "        dividends_fn: Callable[[float], float],\n",
    "        var_covar_fn: Callable[[float], np.array],\n",
    "        n_paths: [int, None] = None,\n",
    "    ) -> float:\n",
    "        random_paths = self._geometric_brownian_motion(\n",
    "            current_spot=current_spot,\n",
    "            days_till_maturity=int(round(self.TRADING_DAYS * time_till_maturity)),\n",
    "            risk_free_rate_fn=risk_free_rate_fn,\n",
    "            dividends_fn=dividends_fn,\n",
    "            var_covar_fn=var_covar_fn,\n",
    "            n_paths=n_paths,\n",
    "        )\n",
    "\n",
    "        instrument_payoffs = self.payoff_function(random_paths)\n",
    "\n",
    "        return np.mean(instrument_payoffs)"
   ],
   "id": "95fb4f95541c4b57",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 5. Pricing Framework.",
   "id": "4eb44582af8092dd"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Now, let's move on to the pricing framework. In this notebook the pricing OOP is implemented to be as flexible as possible in terms of the pricing.\n",
    "\n",
    "Basically, it requires only determining the payoff functions for each base instrument / base derivative. And then you can obtain structured product by effectively combining the respective objects. For instance, to create a Capital Protection Note, which consists of long deposit / risk-free instrument and long call / put option, we simply need to write:\n",
    "$$capital\\_protection\\_note = RiskFreeBond(**params) + Option(**params)$$."
   ],
   "id": "149a829281d6cb20"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "class PositionSide(Enum):\n",
    "    LONG = 1\n",
    "    SHORT = -1"
   ],
   "id": "3b941779c2fd6f4e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "class Instrument:\n",
    "    CALENDAR_DAYS: int = 365\n",
    "\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def bid(self, margin: float) -> float:\n",
    "        return self.price() - margin\n",
    "\n",
    "    def offer(self, margin: float) -> float:\n",
    "        return self.price() + margin\n",
    "\n",
    "    @abc.abstractmethod\n",
    "    def coupon(self, frequency: float = 0.0, *args, **kwargs) -> float:\n",
    "        raise NotImplementedError\n",
    "\n",
    "    @abc.abstractmethod\n",
    "    def pv_coupons(self) -> float:\n",
    "        raise NotImplementedError\n",
    "\n",
    "    @abc.abstractmethod\n",
    "    def price(self, spot_start: [float, list[float], None] = None) -> float:\n",
    "        raise NotImplementedError\n",
    "\n",
    "    @abc.abstractmethod\n",
    "    def payoff(self, spot_paths: np.array) -> float:\n",
    "        raise NotImplementedError\n",
    "\n",
    "    @abc.abstractmethod\n",
    "    def __repr__(self):\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def __str__(self):\n",
    "        return self.__repr__()\n",
    "\n",
    "    def __add__(self, other):\n",
    "        return StructuredNote([(PositionSide.LONG, self), (PositionSide.LONG, other)])\n",
    "\n",
    "    def __sub__(self, other):\n",
    "        return StructuredNote([(PositionSide.LONG, self), (PositionSide.SHORT, other)])"
   ],
   "id": "cb6893ced529a22a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "class StructuredNote:\n",
    "    def __init__(\n",
    "        self, instruments: [list[tuple[PositionSide, Instrument]], None] = None\n",
    "    ):\n",
    "        if instruments is not None:\n",
    "            self.instruments = instruments\n",
    "        else:\n",
    "            self.instruments = []\n",
    "\n",
    "    def bid(self, margin: float) -> float:\n",
    "        return self.price() - margin\n",
    "\n",
    "    def offer(self, margin: float) -> float:\n",
    "        return self.price() + margin\n",
    "\n",
    "    def coupon(\n",
    "        self, frequency: float = 0.0, commission: float = 0.0, *args, **kwargs\n",
    "    ) -> float:\n",
    "        return sum(\n",
    "            [\n",
    "                instrument.coupon(frequency, commission)\n",
    "                for _, instrument in self.instruments\n",
    "            ]\n",
    "        )\n",
    "\n",
    "    def __add__(self, other: Instrument):\n",
    "        return self.instruments.append((PositionSide.LONG, other))\n",
    "\n",
    "    def __sub__(self, other: Instrument):\n",
    "        return self.instruments.append((PositionSide.SHORT, other))\n",
    "\n",
    "    def price(self) -> float:\n",
    "        return sum(\n",
    "            [\n",
    "                side.value * instrument.price() + instrument.pv_coupons()\n",
    "                for side, instrument in self.instruments\n",
    "            ]\n",
    "        )\n",
    "\n",
    "    def payoff(self, spot_paths: np.array) -> float:\n",
    "        return sum(\n",
    "            [\n",
    "                side.value * instrument.payoff(spot_paths)\n",
    "                for side, instrument in self.instruments\n",
    "            ]\n",
    "        )\n",
    "\n",
    "    def __repr__(self):\n",
    "        sp_str = f\"StructuredNote of:\\n\"\n",
    "        for side, instrument in self.instruments:\n",
    "            sp_str += f\"* {side} -> {instrument}\\n\"\n",
    "        return sp_str\n",
    "\n",
    "    def __str__(self):\n",
    "        return self.__repr__()"
   ],
   "id": "db0762b8e51ebab1",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def annuity_factor(annual_rate: float, frequency: float, till_maturity: float) -> float:\n",
    "    rate = annual_rate * frequency\n",
    "    number_of_payments = till_maturity / frequency\n",
    "    return (1 - (1 + rate) ** (-number_of_payments)) / rate"
   ],
   "id": "e7310e93489e7fc6",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "class RiskFreeBond(Instrument):\n",
    "    CALENDAR_DAYS: int = 365\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        yield_curve: YieldCurve,\n",
    "        start_date: dt.datetime,\n",
    "        end_date: dt.datetime,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.yield_curve = yield_curve\n",
    "        self.start_date = start_date\n",
    "        self.end_date = end_date\n",
    "\n",
    "        self.time_till_maturity = (\n",
    "            self.end_date - self.start_date\n",
    "        ).days / self.CALENDAR_DAYS\n",
    "\n",
    "    def pv_coupons(self) -> float:\n",
    "        return 1 - self.price()\n",
    "\n",
    "    def coupon(self, frequency: float = 0.0, *args, **kwargs) -> float:\n",
    "        if frequency > 0:\n",
    "            annual_rate = self.yield_curve.get_rate(self.time_till_maturity)\n",
    "            return self.pv_coupons() / annuity_factor(\n",
    "                annual_rate=annual_rate,\n",
    "                frequency=frequency,\n",
    "                till_maturity=self.time_till_maturity,\n",
    "            )\n",
    "        return 0\n",
    "\n",
    "    def price(self, spot_start: [float, list[float], None] = None):\n",
    "        return self.yield_curve.get_discount_factor(self.time_till_maturity)\n",
    "\n",
    "    def payoff(self, spot_paths: np.array) -> float:\n",
    "        return 1\n",
    "\n",
    "    def __repr__(self):\n",
    "        instrument_str = f\"RiskFreeBond:\\n\"\n",
    "        instrument_str += f\"* Term = {round(self.time_till_maturity, 2)} years\\n\"\n",
    "        instrument_str += f\"* YTM = {round(self.yield_curve.get_rate(self.time_till_maturity) * 100, 2)}%\\n\"\n",
    "        instrument_str += f\"* Start Date = {self.start_date}\\n\"\n",
    "        instrument_str += f\"* End Date = {self.end_date}\\n\"\n",
    "        return instrument_str"
   ],
   "id": "fd5f100f22e6c4d0",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "class ExoticOption(Instrument):\n",
    "    # 50 bps\n",
    "    DEFAULT_SPOT_CHANGE: float = 0.5 / 100\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        underlyings: MarketData,\n",
    "        yield_curve: YieldCurve,\n",
    "        strike_level: [float, list[float]],\n",
    "        start_date: dt.datetime,\n",
    "        end_date: dt.datetime,\n",
    "        *args,\n",
    "        **kwargs\n",
    "    ):\n",
    "        super().__init__()\n",
    "\n",
    "        self.underlyings = underlyings\n",
    "        self.yield_curve = yield_curve\n",
    "        self.strike_level = strike_level\n",
    "        self.start_date = start_date\n",
    "        self.end_date = end_date\n",
    "\n",
    "        self.time_till_maturity = (\n",
    "            self.end_date - self.start_date\n",
    "        ).days / self.CALENDAR_DAYS\n",
    "        self._price = None\n",
    "\n",
    "        self._mc_pricer = MonteCarloPricer(self.payoff)\n",
    "\n",
    "    @lru_cache(maxsize=None)\n",
    "    def _volatility_surface(self, term: float) -> np.array:\n",
    "        return self.underlyings.get_var_covar()\n",
    "\n",
    "    @lru_cache(maxsize=None)\n",
    "    def _dividends(self, term: float) -> np.array:\n",
    "        return self.underlyings.get_dividends()\n",
    "\n",
    "    def delta(\n",
    "        self, spot_change: [float, None] = None, spot_start: [list[float], None] = None\n",
    "    ) -> np.array:\n",
    "        if spot_change is None:\n",
    "            spot_change = self.DEFAULT_SPOT_CHANGE\n",
    "\n",
    "        n_stocks = len(self.underlyings)\n",
    "        spot_up = np.exp(spot_change)\n",
    "        spot_down = np.exp(-spot_change)\n",
    "\n",
    "        delta = []\n",
    "        for i in range(n_stocks):\n",
    "            if spot_start is None:\n",
    "                x_up, x_down = [1] * n_stocks, [1] * n_stocks\n",
    "            else:\n",
    "                x_up, x_down = spot_start.copy(), spot_start.copy()\n",
    "\n",
    "            x_up[i] *= spot_up\n",
    "            x_down[i] *= spot_down\n",
    "\n",
    "            price_up = self.price(x_up)\n",
    "            price_down = self.price(x_down)\n",
    "\n",
    "            delta.append((price_up - price_down) / (spot_up - spot_down))\n",
    "\n",
    "        return np.array(delta)\n",
    "\n",
    "    def gamma(\n",
    "        self, spot_change: [float, None] = None, spot_start: [list[float], None] = None\n",
    "    ) -> np.array:\n",
    "        if spot_change is None:\n",
    "            spot_change = self.DEFAULT_SPOT_CHANGE\n",
    "\n",
    "        n_stocks = len(self.underlyings)\n",
    "        spot_up = np.exp(spot_change)\n",
    "        spot_down = np.exp(-spot_change)\n",
    "\n",
    "        gamma = []\n",
    "        for i in range(n_stocks):\n",
    "            if spot_start is None:\n",
    "                x_up, x_down = [1] * n_stocks, [1] * n_stocks\n",
    "            else:\n",
    "                x_up, x_down = spot_start.copy(), spot_start.copy()\n",
    "\n",
    "            x_up[i] *= spot_up\n",
    "            x_down[i] *= spot_down\n",
    "\n",
    "            delta_up = self.delta(spot_start=x_up)\n",
    "            delta_down = self.delta(spot_start=x_down)\n",
    "\n",
    "            gamma.append((delta_up - delta_down) / (spot_up - spot_down))\n",
    "\n",
    "        return np.array(gamma)\n",
    "\n",
    "    def vega(\n",
    "        self, vol_change: float = 0.01, spot_start: [list[float], None] = None\n",
    "    ) -> np.array:\n",
    "        n_stocks = len(self.underlyings)\n",
    "        diagonal = np.diag(np.sqrt(np.diag(self.underlyings.get_var_covar())))\n",
    "        corr = self.underlyings.get_corr()\n",
    "        price_down = self.price()\n",
    "\n",
    "        vega = []\n",
    "        for i in range(n_stocks):\n",
    "            diag = diagonal.copy()\n",
    "            diag[i][i] += vol_change\n",
    "            new_var_covar = diag @ corr @ diag\n",
    "\n",
    "            future_value_new = self._mc_pricer.get_future_value(\n",
    "                current_spot=spot_start\n",
    "                if spot_start is not None\n",
    "                else [1.0] * len(self.underlyings),\n",
    "                time_till_maturity=self.time_till_maturity,\n",
    "                risk_free_rate_fn=self.yield_curve.get_instant_fwd_rate,\n",
    "                dividends_fn=self._dividends,\n",
    "                var_covar_fn=lambda term: new_var_covar,\n",
    "            )\n",
    "            price_up = future_value_new * self.yield_curve.get_discount_factor(\n",
    "                self.time_till_maturity\n",
    "            )\n",
    "\n",
    "            vega.append((price_up - price_down) / vol_change)\n",
    "\n",
    "        return np.array(vega)\n",
    "\n",
    "    def correlation_sensitivity(\n",
    "        self, corr_change: float = 0.01, spot_start: [list[float], None] = None\n",
    "    ) -> np.array:\n",
    "        n_stocks = len(self.underlyings)\n",
    "        diagonal = np.diag(np.sqrt(np.diag(self.underlyings.get_var_covar())))\n",
    "        correlation = self.underlyings.get_corr()\n",
    "        price_down = self.price()\n",
    "\n",
    "        vega = []\n",
    "        for i in range(n_stocks - 1):\n",
    "            corr = correlation.copy()\n",
    "            corr[i][i + 1] += corr_change\n",
    "            corr[i + 1][i] += corr_change\n",
    "            new_var_covar = diagonal @ corr @ diagonal\n",
    "\n",
    "            future_value_new = self._mc_pricer.get_future_value(\n",
    "                current_spot=spot_start\n",
    "                if spot_start is not None\n",
    "                else [1.0] * len(self.underlyings),\n",
    "                time_till_maturity=self.time_till_maturity,\n",
    "                risk_free_rate_fn=self.yield_curve.get_instant_fwd_rate,\n",
    "                dividends_fn=self._dividends,\n",
    "                var_covar_fn=lambda term: new_var_covar,\n",
    "            )\n",
    "            price_up = future_value_new * self.yield_curve.get_discount_factor(\n",
    "                self.time_till_maturity\n",
    "            )\n",
    "\n",
    "            vega.append((price_up - price_down) / corr_change)\n",
    "\n",
    "        return np.array(vega)\n",
    "\n",
    "    def price(self, spot_start: [float, list[float], None] = None) -> float:\n",
    "        future_value = self._mc_pricer.get_future_value(\n",
    "            current_spot=spot_start\n",
    "            if spot_start is not None\n",
    "            else [1.0] * len(self.underlyings),\n",
    "            time_till_maturity=self.time_till_maturity,\n",
    "            risk_free_rate_fn=self.yield_curve.get_instant_fwd_rate,\n",
    "            dividends_fn=self._dividends,\n",
    "            var_covar_fn=self._volatility_surface,\n",
    "        )\n",
    "        return future_value * self.yield_curve.get_discount_factor(\n",
    "            self.time_till_maturity\n",
    "        )\n",
    "\n",
    "    def get_paths(self, spot_start: [float, list[float], None] = None) -> np.array:\n",
    "        return self._mc_pricer.get_paths(\n",
    "            current_spot=spot_start\n",
    "            if spot_start is not None\n",
    "            else [1.0] * len(self.underlyings),\n",
    "            time_till_maturity=self.time_till_maturity,\n",
    "            risk_free_rate_fn=self.yield_curve.get_instant_fwd_rate,\n",
    "            dividends_fn=self._dividends,\n",
    "            var_covar_fn=self._volatility_surface,\n",
    "        )\n",
    "\n",
    "    @abc.abstractmethod\n",
    "    def __repr__(self):\n",
    "        raise NotImplementedError\n",
    "\n",
    "    @abc.abstractmethod\n",
    "    def payoff(self, spot_paths: np.array) -> float:\n",
    "        raise NotImplementedError"
   ],
   "id": "e9f379adc9e12cc7",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "class WorstOfBarrierPut(ExoticOption):\n",
    "    def __init__(\n",
    "        self,\n",
    "        underlyings: MarketData,\n",
    "        yield_curve: YieldCurve,\n",
    "        strike_level: float,\n",
    "        barrier_level: float,\n",
    "        start_date: dt.datetime,\n",
    "        end_date: dt.datetime,\n",
    "    ):\n",
    "        super().__init__(\n",
    "            underlyings=underlyings,\n",
    "            yield_curve=yield_curve,\n",
    "            strike_level=strike_level,\n",
    "            start_date=start_date,\n",
    "            end_date=end_date,\n",
    "        )\n",
    "\n",
    "        self.barrier_level = barrier_level\n",
    "\n",
    "    def pv_coupons(self) -> float:\n",
    "        return self.price()\n",
    "\n",
    "    def coupon(\n",
    "        self, frequency: float = 0.0, commission: float = 0.0, *args, **kwargs\n",
    "    ) -> float:\n",
    "        if frequency > 0:\n",
    "            annual_rate = self.yield_curve.get_rate(self.time_till_maturity)\n",
    "            return (self.pv_coupons() - commission) / annuity_factor(\n",
    "                annual_rate=annual_rate,\n",
    "                frequency=frequency,\n",
    "                till_maturity=self.time_till_maturity,\n",
    "            )\n",
    "        return 0.0\n",
    "\n",
    "    def __repr__(self):\n",
    "        instrument_str = f\"WorstOfBarrierPut:\\n\"\n",
    "        underlyings = \"\\n\".join(\n",
    "            [f\"-> {stock}\" for stock in worst_of_barrier_put.underlyings.tickers]\n",
    "        )\n",
    "        instrument_str += underlyings\n",
    "        instrument_str += f\"* Strike = {self.strike_level * 100}\\n\"\n",
    "        instrument_str += f\"* Barrier = {self.barrier_level * 100}\\n\"\n",
    "        instrument_str += f\"* Start Date = {self.start_date}\\n\"\n",
    "        instrument_str += f\"* End Date = {self.end_date}\\n\"\n",
    "        return instrument_str\n",
    "\n",
    "    def payoff(self, spot_paths: np.array) -> np.array:\n",
    "        indices = np.where(np.all(spot_paths[:, -1] >= self.barrier_level, axis=1))\n",
    "        returns = self.strike_level - spot_paths[:, -1].min(axis=1)\n",
    "        returns[indices] = 0\n",
    "\n",
    "        return returns"
   ],
   "id": "6e3595336a66219f",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "8578a15e9d81c1be",
   "metadata": {},
   "source": "## 6. Final Pricing."
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Finally, let's use the framework for pricing a specified Barrier Reverse Convertible. The strike will be set at 100% (as it usually done for the BRC) and the barrier level is chosen to be 50% for the purpose of investment idea illustration. However, we can shift barrier at any level that the client desires - the lower the barrier, the lower the coupon (due to lower probability of the option being activated, thus, option being ITM).\n",
    "\n",
    "The instrument provides the following payoff:\n",
    "* Client receives the fixed coupon at specified frequency (for the purpose of illustration of the investment idea quarterly frequency is chosen, but it can be set at any level - the lower the frequency, the lower the coupon due to time value of money).\n",
    "* At maturity, we check the prices of the 3 chosen stocks\n",
    "* If all the stocks are above the barrier, client receives 100% of the invested notional (coupons are paid additionally)\n",
    "* If at least one stock is below the barrier, client receives the respective % of invested notional without the amount by which the worst stock of all fell.\n",
    "\n",
    "A potential way to choose the barrier is to ask the client the applicable $p$ probability of loss and calculate the barrier via Monte Carlo paths, such that in $p$% paths out of all the barrier is hit at maturity."
   ],
   "id": "5c18702f6bac1333"
  },
  {
   "cell_type": "code",
   "id": "bebb60d656ff473d",
   "metadata": {},
   "source": [
    "COUPON_FREQUENCY = 0.25\n",
    "STRIKE_LEVEL = 1.0\n",
    "BARRIER_LEVEL = 0.5\n",
    "\n",
    "start_date = TODAY\n",
    "end_date = dt.datetime(TODAY.year + YEARS_TILL_MATURITY, TODAY.month, TODAY.day)\n",
    "\n",
    "worst_of_barrier_put = WorstOfBarrierPut(\n",
    "    underlyings=md,\n",
    "    yield_curve=ns_curve,\n",
    "    strike_level=STRIKE_LEVEL,\n",
    "    barrier_level=BARRIER_LEVEL,\n",
    "    start_date=start_date,\n",
    "    end_date=end_date,\n",
    ")\n",
    "risk_free_bond = RiskFreeBond(\n",
    "    yield_curve=ns_curve, start_date=start_date, end_date=end_date\n",
    ")\n",
    "barrier_reverse_convertible = risk_free_bond - worst_of_barrier_put"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "be76364b21e4921d",
   "metadata": {},
   "source": [
    "print(\n",
    "    f\"Price of the instrument is {barrier_reverse_convertible.price() * 100:.2f}% at inception.\"\n",
    ")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "At inception instrument costs 100%, as nothing in the market have changed, and we still have a deposit, cash from option premium received and short option that costs exactly the premium we have received.",
   "id": "bfcd23a7b3120c86"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Let's check the premium of the sold option, which will be distributed as coupons to the client that holds the note.",
   "id": "12378f7467f1d830"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "print(\n",
    "    f\"Option premium of the Worst-Of Barrier Put is {worst_of_barrier_put.price() * 100:.2f}% at inception.\"\n",
    ")"
   ],
   "id": "cbca2cf97123bbe3",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Therefore, our final instrument is:",
   "id": "37f7aab18a91afb"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "barrier_reverse_convertible",
   "id": "4a82f730646d1f4a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Which consists of:",
   "id": "f0925dd5e90ade9e"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "risk_free_bond",
   "id": "d1c888bd2720cc0d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "worst_of_barrier_put",
   "id": "32b79cb6526a438a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "So, if the price is 100%, what should we quote to the investor? As the investor looks the fixed income-like payoff, we are quoting the level of the coupon that the client will receive.",
   "id": "1cd4aefc125e8653"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "brc_coupon = barrier_reverse_convertible.coupon(COUPON_FREQUENCY)\n",
    "print(f\"BRC Coupon = {round(brc_coupon * 100, 2)}% quarterly\")\n",
    "print(f\"BRC Coupon = {round(brc_coupon * 100, 2) / COUPON_FREQUENCY}% p.a.\")"
   ],
   "id": "93cf81904679ea05",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "However, we as investment bank should take some % as the commission from the PV of the structured note. Let's specify the commission and quote the final coupon to the client.",
   "id": "5d3dec100d86117b"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# For example, we can set commission to be 0.5% p.a., taken at inception\n",
    "COMMISSION = 0.5 / 100 * YEARS_TILL_MATURITY\n",
    "brc_coupon = barrier_reverse_convertible.coupon(COUPON_FREQUENCY, commission=COMMISSION)\n",
    "print(f\"BRC Coupon = {round(brc_coupon * 100, 2)}% quarterly\")\n",
    "print(f\"BRC Coupon = {round(brc_coupon * 100, 2) / COUPON_FREQUENCY}% p.a.\")"
   ],
   "id": "bcc42c2b0a2a3d91",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "print(\n",
    "    f\"Risk-free alternative YTM = {ns_curve.get_rate(YEARS_TILL_MATURITY) * 100:.2f}%\"\n",
    ")"
   ],
   "id": "b319c15be31dd77e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Therefore, our product offers slightly less than 5% of the premium to the risk-free rate for the risk undertaken, however, not taking into account the potentially rising correlation",
   "id": "c7981abee81554bc"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 7. Checking the Logic via Charts.",
   "id": "5a855bff5ee01bdf"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Let's plot Monte Carlo paths, check that they look logically coherent and compare the scenarios, where the barrier is hit vs where it is not.",
   "id": "3814ed6e72b319d3"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def plot_paths(random_paths: np.array, market_data: MarketData) -> None:\n",
    "    n_stocks = random_paths.shape[-1]\n",
    "\n",
    "    plt.figure(figsize=(16, 10))\n",
    "    plt.subplot(n_stocks + 1, 1, 1)\n",
    "\n",
    "    plt.title(f\"Stock Paths of {', '.join(market_data.tickers.codes)}\")\n",
    "    for i in range(n_stocks):\n",
    "        plt.plot(random_paths[0, :, i].T, \"g\")\n",
    "        plt.grid()\n",
    "        plt.ylabel(\"Performance of stocks\")\n",
    "\n",
    "    for i in range(n_stocks):\n",
    "        plt.subplot(n_stocks + 1, 1, i + 2)\n",
    "        plt.plot(random_paths[:10, :, i].T, \"--b\")\n",
    "        plt.grid()\n",
    "        if i == n_stocks - 1:\n",
    "            plt.xlabel(\"Time\")\n",
    "        plt.ylabel(market_data.tickers[i].name)\n",
    "\n",
    "    plt.show()"
   ],
   "id": "3a28baebe7b16bc5",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def plot_barrier_hit(\n",
    "    random_paths: np.array, market_data: MarketData, barrier_level: float\n",
    ") -> None:\n",
    "    n_stocks = random_paths.shape[-1]\n",
    "\n",
    "    plt.figure(figsize=(16, 10))\n",
    "    plt.subplot(n_stocks + 1, 1, 1)\n",
    "\n",
    "    plt.title(f\"Stock Paths of {', '.join(market_data.tickers.codes)}\")\n",
    "    barrier_hit_paths = random_paths[\n",
    "        np.where(np.any(random_paths[:, -1] < barrier_level, axis=1))\n",
    "    ]\n",
    "    for i in range(n_stocks):\n",
    "        if barrier_hit_paths[0, -1, i] >= barrier_level:\n",
    "            plt.plot(barrier_hit_paths[0, :, i].T, \"--g\")\n",
    "        else:\n",
    "            plt.plot(barrier_hit_paths[0, :, i].T, \"--r\")\n",
    "        plt.grid()\n",
    "        plt.xlabel(\"Time\")\n",
    "        plt.ylabel(\"Performance of stocks\")\n",
    "\n",
    "    plt.plot(np.array([barrier_level] * paths.shape[1]), \"m\")\n",
    "\n",
    "    plt.show()"
   ],
   "id": "f89fb6637d60918e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def plot_barrier_not_hit(\n",
    "    random_paths: np.array, market_data: MarketData, barrier_level: float\n",
    ") -> None:\n",
    "    n_stocks = random_paths.shape[-1]\n",
    "\n",
    "    plt.figure(figsize=(16, 10))\n",
    "    plt.subplot(n_stocks + 1, 1, 1)\n",
    "\n",
    "    plt.title(f\"Stock Paths of {', '.join(market_data.tickers.codes)}\")\n",
    "    barrier_not_hit_paths = random_paths[\n",
    "        np.where(np.all(random_paths[:, -1] >= barrier_level, axis=1))\n",
    "    ]\n",
    "    for i in range(n_stocks):\n",
    "        plt.plot(barrier_not_hit_paths[0, :, i].T, \"--g\")\n",
    "        plt.grid()\n",
    "        plt.xlabel(\"Time\")\n",
    "        plt.ylabel(\"Performance of stocks\")\n",
    "\n",
    "    plt.plot(np.array([barrier_level] * paths.shape[1]), \"m\")\n",
    "\n",
    "    plt.show()"
   ],
   "id": "35f80f64ad7a4a14",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "paths = worst_of_barrier_put.get_paths()\n",
    "paths.shape"
   ],
   "id": "dfbba3fa88d2637a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "plot_paths(paths, md)",
   "id": "7338a740ecc19b2c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "plot_barrier_hit(paths, md, barrier_level=worst_of_barrier_put.barrier_level)",
   "id": "d721ef0171cf7ea5",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "plot_barrier_not_hit(paths, md, barrier_level=worst_of_barrier_put.barrier_level)",
   "id": "629ca80cb1527c14",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 8. Greeks.",
   "id": "99c784edd4e70302"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Finally, let's calculate the greeks for the structure. The greeks are computed for the worst-of call itself for simplicity, however, we should keep in mind that the structure supposed **holding worst-of call short**, thus, while hedging we should hedge out the minus values of the presented greeks.",
   "id": "7de1f69b13dcced9"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "N_POINTS_GRAPH = 10\n",
    "MIN_SPOT = -0.7\n",
    "MAX_SPOT = 0.7"
   ],
   "id": "134bc4b338a4f80a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def plot_greek(\n",
    "    greek_fn: Callable[[list[float]], float],\n",
    "    market_data: MarketData,\n",
    "    greek_name: str,\n",
    "    color: str = \"g\",\n",
    ") -> None:\n",
    "    n_stocks = len(market_data)\n",
    "\n",
    "    data = []\n",
    "    for stock_i in range(n_stocks):\n",
    "        spot_start = [1.0] * n_stocks\n",
    "        if greek_name.lower() == \"gamma\":\n",
    "            greeks = [[1.0, greek_fn()[stock_i][stock_i]]]\n",
    "            for spot in tqdm(np.linspace(MIN_SPOT, MAX_SPOT, N_POINTS_GRAPH)):\n",
    "                spot_start = [1 + spot] * n_stocks\n",
    "                greek = greek_fn(spot_start=spot_start)\n",
    "                greeks.append([1 + spot, greek[stock_i][stock_i]])\n",
    "        else:\n",
    "            greeks = [[1.0, greek_fn()[stock_i]]]\n",
    "            for spot in tqdm(np.linspace(MIN_SPOT, MAX_SPOT, N_POINTS_GRAPH)):\n",
    "                spot_start[stock_i] = 1 + spot\n",
    "                greeks.append([1 + spot, greek_fn(spot_start=spot_start)[stock_i]])\n",
    "        data.append(greeks)\n",
    "\n",
    "    data = np.array(data)\n",
    "    data = np.sort(data, axis=1)\n",
    "\n",
    "    plt.figure(figsize=(14, 7))\n",
    "    n_stocks = len(market_data.tickers)\n",
    "\n",
    "    for i in range(n_stocks):\n",
    "        plt.subplot(n_stocks, 1, i + 1)\n",
    "        plt.plot(data[i, :, 0], data[i, :, 1], label=f\"{greek_name}\", color=color)\n",
    "        plt.gca().xaxis.set_major_formatter(mtick.PercentFormatter(xmax=1.0))\n",
    "        plt.grid()\n",
    "\n",
    "        if i == 0:\n",
    "            plt.title(f\"{greek_name}\")\n",
    "\n",
    "        if i == n_stocks - 1:\n",
    "            plt.xlabel(\"Moneyness, %\")\n",
    "\n",
    "        plt.ylabel(f\"{market_data.tickers[i].name}\")\n",
    "\n",
    "    plt.show()"
   ],
   "id": "94dd2abbb0e3037",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "plot_greek(worst_of_barrier_put.gamma, md, greek_name=\"Gamma\")",
   "id": "aa7c3484a2a9d806",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Delta.",
   "id": "20b6d24815f2c788"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "deltas = worst_of_barrier_put.delta()\n",
    "for i, delta in enumerate(deltas):\n",
    "    print(f\"* {md.tickers[i].name} => {round(delta, 5)} delta\")"
   ],
   "id": "26dbb18dec333464",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "plot_greek(worst_of_barrier_put.delta, md, greek_name=\"Delta\")",
   "id": "ebe08dbc12f0762c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Deltas for our worst-of put are negative, as expected - as the option gains, when the stocks fall and breach the barrier, we need to hold stocks short for the hedging purposes.",
   "id": "7c3129f2c5529ef1"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Gamma (including X-Gamma).",
   "id": "76ed0b8336bb5678"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "gammas = worst_of_barrier_put.gamma()\n",
    "for i, gamma in enumerate(gammas):\n",
    "    print(f\"* {md.tickers[i].name} => {round(gamma[i], 5)} gamma\")"
   ],
   "id": "956f97a2a4b8f27e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Here we can notice gammas to be of both signs. The reason for that is the fact that the change in delta, caused by the spot change, might be negavtive for the volatile stock, whenever it is strongly correlated with other stocks - if other stocks are unchanged, but one stock rises, due to correlation it statistically means potential drop with higher volatility, as other stocks (being correlated) show that this stock statistically might fall back, but with higher volatility. It might not be the expected result in terms of financial logic, but in this case **it is driven by the assumption of stocks following multivariate GBM**.",
   "id": "d9d3e4efd11e5a7f"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "np.sqrt(np.diag(worst_of_barrier_put.underlyings.get_var_covar()))",
   "id": "9d608e5f128876d6",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "worst_of_barrier_put.underlyings.get_corr()",
   "id": "41c54add4853c7dc",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Indeed, the negative gamma is the stock with the largest volatility, and all the stocks are highly correlated.",
   "id": "c1e6191139af727d"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Now, let's have a look at x-gammas.",
   "id": "77e16b8904555428"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "gammas",
   "id": "9d5c91ddb4319d81",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Indeed, as the change in one stock's price up should mean that the probability of other stock to drop is now higher, as now the probability that the stocks will diverge (other stocks remain unchanged, but one stock moves => correlation breaks) is higher too => we should increase delta-hedge => we should hold larger short position in stocks.",
   "id": "bf27b3526c14d3f"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "plot_greek(worst_of_barrier_put.gamma, md, greek_name=\"Gamma\")",
   "id": "cb472bfafda7a021",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Vega.",
   "id": "3d3c030784fd177b"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Further, let's check vegas.",
   "id": "c899ec4b9cd21725"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "vegas = worst_of_barrier_put.vega()\n",
    "for i, vega in enumerate(vegas):\n",
    "    print(f\"* {md.tickers[i].name} => {round(vega, 5)} vega\")"
   ],
   "id": "93471c5b5ec0b28a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "The result is also expected and follows standard logic for vanilla options - the higher the volatility, the higher the probability of negative paths to breach the barrier, while all the positive paths are still producing zero payoff, thus, only negative paths affect the shift in payoff to be more positive, therefore, price should increase.",
   "id": "9d9f1b4ec4dd1330"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "plot_greek(worst_of_barrier_put.vega, md, greek_name=\"Vega\")",
   "id": "208902abe7fbbc87",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Correlation Sensitivity.",
   "id": "9cede68d10960470"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Finally, let's have a look at correlation sensitivity.",
   "id": "a9148c6dbe515616"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "worst_of_barrier_put.correlation_sensitivity()",
   "id": "556d374eeca3cc24",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Correlation sensitivity is negative, as by holding worst-of option long we are short volatility, thus, when volatility rises, the probability of at least one stock to breach the barrier decreases (because all stocks will move \"more simultaneously\" due to higher correlation, therefore, the price decreases.",
   "id": "9a62b5300096b4d5"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "**Important note**: the investment idea presented is offered to the client as the opportunity to gain from the rise in correlation at the market. However, we as market-maker that buys worst-of option from the client should not account for the potential rise in correlation and follow the hedging procedures from the risk-neutral perspective. Otherwise, the actual position in correlation would be not only at client's side, but also at our side too, which is divergent from the idea of market-making, but rather taking a position in market variables.",
   "id": "9357f086ed841d72"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
