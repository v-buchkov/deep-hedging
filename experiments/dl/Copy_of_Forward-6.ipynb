{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "41VE08_pyFuR"
   },
   "source": [
    "# **Deep Hedging**\n",
    "# Buchkov Viacheslav"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LKcSNj4tlRVK"
   },
   "source": [
    "import abc\n",
    "import math\n",
    "import os\n",
    "import random\n",
    "import sys\n",
    "from functools import lru_cache\n",
    "from pathlib import Path\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "\n",
    "# You may add any imports you need\n",
    "from torch.cuda.amp import GradScaler\n",
    "\n",
    "RANDOM_SEED = 12"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "47YPLjDL-Mtv"
   },
   "source": [
    "def seed_everything(seed):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "\n",
    "\n",
    "seed_everything(RANDOM_SEED)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZrCB4LgfO8y6"
   },
   "source": [
    "if torch.backends.mps.is_available():\n",
    "    DEVICE = torch.device(\"mps\")\n",
    "elif torch.cuda.is_available():\n",
    "    DEVICE = torch.device(\"cuda\")\n",
    "else:\n",
    "    DEVICE = torch.device(\"cpu\")"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QmkSjI1Regtf",
    "outputId": "850461e8-4e1b-4deb-ce4e-1461a8ca4a0c"
   },
   "source": [
    "from google.colab import drive\n",
    "\n",
    "drive.mount(\"/content/gdrive\", force_remount=True)\n",
    "\n",
    "ROOT_PATH = Path(\"dataset\")\n",
    "PATH = Path(\"/content/gdrive/MyDrive/\")\n",
    "N_DAYS = 5"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 450
    },
    "id": "kmiS11dsOnaq",
    "outputId": "48c57e4f-c6e2-48fe-c744-0c34a06d8923"
   },
   "source": [
    "data = pd.read_pickle(PATH / \"data.pkl\")\n",
    "data[\"rub_rate\"] = data[\"rub_rate\"] / 100\n",
    "data.dropna(inplace=True)\n",
    "data"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8UKB-Db2PqIK"
   },
   "source": [
    "import abc\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from enum import Enum\n",
    "\n",
    "\n",
    "class PositionSide(Enum):\n",
    "    LONG = 1\n",
    "    SHORT = -1\n",
    "\n",
    "\n",
    "class Instrument:\n",
    "    CALENDAR_DAYS: int = 365\n",
    "\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def bid(self, margin: float) -> float:\n",
    "        return self.price() - margin\n",
    "\n",
    "    def offer(self, margin: float) -> float:\n",
    "        return self.price() + margin\n",
    "\n",
    "    @staticmethod\n",
    "    def discount_factor(rate: float, term: float) -> float:\n",
    "        return np.exp(-rate * term)\n",
    "\n",
    "    @abc.abstractmethod\n",
    "    def coupon(self, frequency: float = 0.0, *args, **kwargs) -> float:\n",
    "        raise NotImplementedError\n",
    "\n",
    "    @abc.abstractmethod\n",
    "    def pv_coupons(self) -> float:\n",
    "        raise NotImplementedError\n",
    "\n",
    "    @abc.abstractmethod\n",
    "    def price(self, spot_start: [float, list[float], None] = None) -> float:\n",
    "        raise NotImplementedError\n",
    "\n",
    "    @abc.abstractmethod\n",
    "    def payoff(self, spot: [np.array, float]) -> float:\n",
    "        raise NotImplementedError\n",
    "\n",
    "    @abc.abstractmethod\n",
    "    def __repr__(self):\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def __str__(self):\n",
    "        return self.__repr__()\n",
    "\n",
    "    def __add__(self, other):\n",
    "        return StructuredNote([(PositionSide.LONG, self), (PositionSide.LONG, other)])\n",
    "\n",
    "    def __sub__(self, other):\n",
    "        return StructuredNote([(PositionSide.LONG, self), (PositionSide.SHORT, other)])\n",
    "\n",
    "\n",
    "class StructuredNote:\n",
    "    def __init__(\n",
    "        self, instruments: [list[tuple[PositionSide, Instrument]], None] = None\n",
    "    ):\n",
    "        if instruments is not None:\n",
    "            self.instruments = instruments\n",
    "        else:\n",
    "            self.instruments = []\n",
    "\n",
    "    def bid(self, margin: float) -> float:\n",
    "        return self.price() - margin\n",
    "\n",
    "    def offer(self, margin: float) -> float:\n",
    "        return self.price() + margin\n",
    "\n",
    "    def coupon(\n",
    "        self, frequency: float = 0.0, commission: float = 0.0, *args, **kwargs\n",
    "    ) -> float:\n",
    "        return sum(\n",
    "            [\n",
    "                instrument.coupon(frequency, commission)\n",
    "                for _, instrument in self.instruments\n",
    "            ]\n",
    "        )\n",
    "\n",
    "    def __add__(self, other: Instrument):\n",
    "        return self.instruments.append((PositionSide.LONG, other))\n",
    "\n",
    "    def __sub__(self, other: Instrument):\n",
    "        return self.instruments.append((PositionSide.SHORT, other))\n",
    "\n",
    "    def price(self) -> float:\n",
    "        return sum(\n",
    "            [\n",
    "                side.value * instrument.price() + instrument.pv_coupons()\n",
    "                for side, instrument in self.instruments\n",
    "            ]\n",
    "        )\n",
    "\n",
    "    def payoff(self, spot_paths: np.array) -> float:\n",
    "        return sum(\n",
    "            [\n",
    "                side.value * instrument.payoff(spot_paths)\n",
    "                for side, instrument in self.instruments\n",
    "            ]\n",
    "        )\n",
    "\n",
    "    def __repr__(self):\n",
    "        sp_str = f\"StructuredNote of:\\n\"\n",
    "        for side, instrument in self.instruments:\n",
    "            sp_str += f\"* {side} -> {instrument}\\n\"\n",
    "        return sp_str\n",
    "\n",
    "    def __str__(self):\n",
    "        return self.__repr__()"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WSq4YrPxPsBP"
   },
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "class Forward(Instrument):\n",
    "    def __init__(\n",
    "        self, rates_difference: float, spot_price: float, term: float, *args, **kwargs\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.rates_difference = rates_difference\n",
    "        self.spot_price = spot_price\n",
    "        self.term = term\n",
    "\n",
    "    def coupon(self, frequency: float = 0.0, *args, **kwargs) -> float:\n",
    "        return 0\n",
    "\n",
    "    def pv_coupons(self) -> float:\n",
    "        return 0\n",
    "\n",
    "    def get_strike(self, spot_price: [float, None] = None) -> float:\n",
    "        if spot_price is None:\n",
    "            spot_price = self.spot_price\n",
    "        return spot_price * self.discount_factor(\n",
    "            rate=-self.rates_difference, term=self.term\n",
    "        )\n",
    "\n",
    "    @property\n",
    "    def strike(self) -> float:\n",
    "        return self.get_strike()\n",
    "\n",
    "    def price(self, spot_start: [float, list[float], None] = None) -> float:\n",
    "        return 0\n",
    "\n",
    "    def payoff(self, spot: [float, np.array]) -> float:\n",
    "        return spot - self.strike\n",
    "\n",
    "    def __repr__(self):\n",
    "        return f\"Forward(strike={self.strike}, term={self.term}, spot_ref={self.spot_price})\""
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Na70Ea_A7hoi"
   },
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "class EuropeanCall(Instrument):\n",
    "    def __init__(\n",
    "        self, rates_difference: float, spot_price: float, term: float, *args, **kwargs\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.rates_difference = rates_difference\n",
    "        self.spot_price = spot_price\n",
    "        self.term = term\n",
    "\n",
    "    def coupon(self, frequency: float = 0.0, *args, **kwargs) -> float:\n",
    "        return 0\n",
    "\n",
    "    def pv_coupons(self) -> float:\n",
    "        return 0\n",
    "\n",
    "    def get_strike(self, spot_price: [float, None] = None) -> float:\n",
    "        return self.spot_price\n",
    "\n",
    "    @property\n",
    "    def strike(self) -> float:\n",
    "        return self.get_strike()\n",
    "\n",
    "    def price(self, spot_start: [float, list[float], None] = None) -> float:\n",
    "        return 0\n",
    "\n",
    "    def payoff(self, spot: [float, np.array]) -> float:\n",
    "        return max(spot - self.strike, 0)\n",
    "\n",
    "    def __repr__(self):\n",
    "        return f\"EuropeanCall(strike={self.strike}, term={self.term}, spot_ref={self.spot_price})\""
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Mou9GCV8Onar"
   },
   "source": [
    "# from src.base.instrument import Instrument\n",
    "# from src.forward.forward import Forward\n",
    "\n",
    "\n",
    "def create_instrument(period_df: pd.DataFrame) -> Instrument:\n",
    "    start = period_df.loc[period_df.index.min()]\n",
    "    return EuropeanCall(\n",
    "        rates_difference=start[\"rub_rate\"] - start[\"usd_rate\"],\n",
    "        spot_price=start[\"ask\"],\n",
    "        term=N_DAYS / 365,\n",
    "    )"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 450
    },
    "id": "JgRMD8IqOnar",
    "outputId": "8c879fa8-774a-44c9-f8a5-a5ecea4f8854"
   },
   "source": [
    "import datetime as dt\n",
    "\n",
    "start_date = data.index.min()\n",
    "end_date = start_date + dt.timedelta(days=N_DAYS)\n",
    "data[(data.index >= data.index.min()) & (data.index <= end_date)]"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BdcEuFc0Onas",
    "outputId": "7e37abfe-eaa0-48b0-d318-4dc293bedc2e"
   },
   "source": [
    "call = create_instrument(\n",
    "    data[(data.index >= data.index.min()) & (data.index <= end_date)]\n",
    ")\n",
    "call"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cty5h8mOOnas"
   },
   "source": [
    "## Dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HVpgB39EzM9H"
   },
   "source": [
    "from typing import Union, Type\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "# from src.base.instrument import Instrument\n",
    "\n",
    "\n",
    "class SpotDataset(Dataset):\n",
    "    BID_COLUMN: str = \"bid\"\n",
    "    ASK_COLUMN: str = \"ask\"\n",
    "    RATE_DOMESTIC_COLUMN: str = \"rub_rate\"\n",
    "    RATE_FOREIGN_COLUMN: str = \"usd_rate\"\n",
    "\n",
    "    TRADING_DAYS: int = 252\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        instrument_cls: Type[Instrument],\n",
    "        n_days: int = N_DAYS,\n",
    "        path: Path = PATH,\n",
    "        data: Union[pd.DataFrame, None] = None,\n",
    "    ):\n",
    "        self.instrument_cls = instrument_cls\n",
    "        self.n_days = n_days\n",
    "\n",
    "        self.data = self._create_df(path) if data is None else data.copy()\n",
    "\n",
    "        self.data[\"time_diff\"] = self.data.index.to_series().diff()\n",
    "        self.data.loc[self.data.index[0], \"time_diff\"] = pd.to_timedelta(\n",
    "            \"0 days 00:00:00\"\n",
    "        )\n",
    "        self.data[\"time_diff\"] = (\n",
    "            self.data[\"time_diff\"].cumsum() / np.timedelta64(1, \"D\") / 365\n",
    "        )\n",
    "        # self.data[\"rub_rate\"] = self.data[\"rub_rate\"] / 100\n",
    "\n",
    "        # self.data = self.data.dropna()\n",
    "        self.data = self.data.ffill()\n",
    "        # self.X, self.y = self._create_dataset()\n",
    "\n",
    "    @staticmethod\n",
    "    def _create_df(path: Path) -> pd.DataFrame:\n",
    "        if \"data.pkl\" in os.listdir(path):\n",
    "            return pd.read_pickle(PATH / \"data.pkl\")\n",
    "        else:\n",
    "            pass\n",
    "\n",
    "    def _create_instrument(self, period_df: pd.DataFrame) -> Instrument:\n",
    "        start = period_df.loc[period_df.index.min()]\n",
    "        spot_start = (start[\"bid\"] + start[\"ask\"]) / 2\n",
    "        return (\n",
    "            self.instrument_cls(\n",
    "                rates_difference=start[\"rub_rate\"] - start[\"usd_rate\"],\n",
    "                spot_price=spot_start,\n",
    "                term=N_DAYS / 365,\n",
    "            ),\n",
    "            spot_start,\n",
    "        )\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(\n",
    "            self.data[\n",
    "                self.data.index < self.data.index.max() - dt.timedelta(days=self.n_days)\n",
    "            ]\n",
    "        )\n",
    "\n",
    "    def __getitem__(self, idx: int):\n",
    "        start_date = self.data.index[idx]\n",
    "        end_date = start_date + dt.timedelta(days=self.n_days)\n",
    "\n",
    "        features = self.data[\n",
    "            (self.data.index >= start_date) & (self.data.index <= end_date)\n",
    "        ].copy()\n",
    "        features[\"time_diff\"] = features.iloc[-1, -1] - features[\"time_diff\"]\n",
    "        instrument, spot_start = self._create_instrument(features)\n",
    "        # features[\"spot_start\"] = spot_start\n",
    "        target = instrument.payoff(spot=features.ask.iloc[-1])\n",
    "\n",
    "        return torch.Tensor(features.to_numpy()).to(torch.float32), torch.Tensor(\n",
    "            [target]\n",
    "        ).to(torch.float32)\n",
    "\n",
    "    @property\n",
    "    def average_dt(self):\n",
    "        return self.data.index.to_series().diff(1).mean() / (\n",
    "            np.timedelta64(1, \"D\") * self.TRADING_DAYS\n",
    "        )"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uARQpAIhOnat",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "cf6f79b6-d532-4600-f837-6cd050a5fd63"
   },
   "source": [
    "spot_dataset = SpotDataset(instrument_cls=EuropeanCall)\n",
    "AVERAGE_DT = spot_dataset.average_dt\n",
    "AVERAGE_DT"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DSRMeUecOnau",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "5230ec38-62b7-4299-fa16-ae002993abf6"
   },
   "source": [
    "spot_dataset[2]"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LAQJ_pvEOnau",
    "outputId": "932f0a51-04b1-4d16-f5a6-a3091c1db4da"
   },
   "source": [
    "spot_dataset[0][0][-1][-1] * 365"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oNFI-9syOnav"
   },
   "source": [
    "def get_pnl(\n",
    "    spot: torch.Tensor, weights: torch.Tensor, dt: float = AVERAGE_DT\n",
    ") -> torch.float32:\n",
    "    model_device = spot.device\n",
    "    weights_all = torch.concat(\n",
    "        [\n",
    "            torch.zeros(spot.shape[0], 1, requires_grad=False).to(model_device),\n",
    "            weights,\n",
    "            torch.zeros(spot.shape[0], 1, requires_grad=False).to(model_device),\n",
    "        ],\n",
    "        dim=1,\n",
    "    )\n",
    "    weights_diff = weights_all.diff(n=1, dim=1)\n",
    "\n",
    "    rates_diff = spot[:, :, 2] - spot[:, :, 3]\n",
    "\n",
    "    bought = torch.where(weights_diff > 0, weights_diff, 0)\n",
    "    sold = torch.where(weights_diff < 0, weights_diff, 0)\n",
    "\n",
    "    interest = (rates_diff * -weights_all).sum(dim=1) * dt\n",
    "\n",
    "    cash_outflow = (-spot[:, 1:, 1] * bought).sum(dim=1)\n",
    "    cash_inflow = (-spot[:, 1:, 0] * sold).sum(dim=1)\n",
    "\n",
    "    return (cash_outflow + cash_inflow + interest).unsqueeze(1)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PuiJpFh0Onav"
   },
   "source": [
    "class NeuralHedger(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        input_size: int = 5,\n",
    "        num_layers: int = 3,\n",
    "        hidden_size: int = 32,\n",
    "        dt: float = AVERAGE_DT,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.input_size = input_size\n",
    "        self.num_layers = num_layers\n",
    "        self.hidden_size = hidden_size\n",
    "        self.dt = dt\n",
    "\n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size, self.hidden_size, num_layers=num_layers, batch_first=True\n",
    "        )\n",
    "\n",
    "        self.hedging_weights = nn.Sequential(\n",
    "            nn.Linear(self.hidden_size, self.hidden_size),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(self.hidden_size, self.hidden_size),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(self.hidden_size, 1),\n",
    "        )\n",
    "\n",
    "    def forward(\n",
    "        self,\n",
    "        spot: torch.Tensor,\n",
    "        hidden: [(torch.Tensor), None] = None,\n",
    "        return_hidden: bool = False,\n",
    "    ) -> [torch.Tensor, (torch.Tensor, torch.Tensor, torch.Tensor)]:\n",
    "        model_device = spot.device\n",
    "        if hidden is None:\n",
    "            h_t = torch.zeros(\n",
    "                self.num_layers, spot.size(0), self.hidden_size, dtype=torch.float32\n",
    "            ).to(model_device)\n",
    "            c_t = torch.zeros(\n",
    "                self.num_layers, spot.size(0), self.hidden_size, dtype=torch.float32\n",
    "            ).to(model_device)\n",
    "        elif len(hidden) != 2:\n",
    "            raise ValueError(f\"Expected two hidden state variables, got {len(hidden)}\")\n",
    "        else:\n",
    "            h_t, c_t = hidden\n",
    "\n",
    "        h_t, c_t = self.lstm(spot, (h_t, c_t))\n",
    "        outputs = self.hedging_weights(h_t)[:, 1:-1, :].squeeze(2)\n",
    "\n",
    "        if return_hidden:\n",
    "            return outputs, (h_t, c_t)\n",
    "        else:\n",
    "            return outputs\n",
    "\n",
    "    def get_pnl(self, spot: torch.Tensor) -> [torch.Tensor, torch.float32]:\n",
    "        # hedging_weights = nn.Softmax()(self.forward(spot, return_hidden=False), dim=XXX)\n",
    "        hedging_weights = self.forward(spot, return_hidden=False)\n",
    "        return hedging_weights, get_pnl(spot=spot, weights=hedging_weights, dt=self.dt)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hi-6nEFNOnav",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "bb5d8cc4-ab12-4c75-b50e-dfcc3e9de461"
   },
   "source": [
    "hedger = NeuralHedger()\n",
    "loader = DataLoader(spot_dataset, batch_size=32, shuffle=True, drop_last=True)\n",
    "\n",
    "for feature, target in loader:\n",
    "    print(feature.shape)\n",
    "    pnl = hedger.get_pnl(feature.to(torch.float32))\n",
    "    break\n",
    "pnl"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VfXJSR-XOnaw"
   },
   "source": [
    "from tqdm import tqdm\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "\n",
    "def train_epoch(\n",
    "    model: nn.Module,\n",
    "    optimizer: torch.optim.Optimizer,\n",
    "    criterion: nn.Module,\n",
    "    loader: DataLoader,\n",
    "    tqdm_desc: str = \"Model\",\n",
    "):\n",
    "    device = next(model.parameters()).device\n",
    "\n",
    "    if tqdm_desc is None:\n",
    "        iterator = loader\n",
    "    else:\n",
    "        iterator = tqdm(loader, desc=tqdm_desc)\n",
    "\n",
    "    train_loss = 0.0\n",
    "    model_diff = 0.0\n",
    "    model.train()\n",
    "    scaler = GradScaler()\n",
    "    pnl_path = []\n",
    "    weight_path = []\n",
    "    diffs_path = []\n",
    "    for features, target_pnl in iterator:\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        features = features.to(device)\n",
    "        target_pnl = target_pnl.to(device)\n",
    "\n",
    "        with torch.autocast(device_type=\"cuda\", dtype=torch.float16):\n",
    "            weights, model_pnl = model.get_pnl(features)\n",
    "            loss = criterion(target_pnl, model_pnl)\n",
    "\n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.step(optimizer)\n",
    "\n",
    "        scaler.update()\n",
    "\n",
    "        diff = target_pnl - model_pnl\n",
    "\n",
    "        train_loss += loss.item()\n",
    "        model_diff += diff.mean().item()\n",
    "\n",
    "        diffs_path.append(diff.detach().cpu().numpy())\n",
    "        weight_path.append(weights.detach().cpu().numpy())\n",
    "\n",
    "    train_loss /= len(loader.dataset)\n",
    "    model_diff /= len(loader.dataset)\n",
    "\n",
    "    return train_loss, weight_path, model_diff, diffs_path\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def validation_epoch(\n",
    "    model: nn.Module,\n",
    "    criterion: nn.Module,\n",
    "    loader: DataLoader,\n",
    "    tqdm_desc: [str, None] = None,\n",
    "):\n",
    "    device = next(model.parameters()).device\n",
    "\n",
    "    if tqdm_desc is None:\n",
    "        iterator = loader\n",
    "    else:\n",
    "        iterator = tqdm(loader, desc=tqdm_desc)\n",
    "\n",
    "    val_loss = 0.0\n",
    "    model_diff = 0.0\n",
    "    model.eval()\n",
    "    diffs_path = []\n",
    "    weight_path = []\n",
    "    for features, target_pnl in iterator:\n",
    "        features = features.to(device)\n",
    "        target_pnl = target_pnl.to(device)\n",
    "\n",
    "        weights, model_pnl = model.get_pnl(features)\n",
    "\n",
    "        loss = criterion(target_pnl, model_pnl)\n",
    "        diff = target_pnl - model_pnl\n",
    "\n",
    "        val_loss += loss.item()\n",
    "        model_diff += diff.mean().item()\n",
    "\n",
    "        diffs_path.append(diff.detach().cpu().numpy())\n",
    "        weight_path.append(weights.detach().cpu().numpy())\n",
    "\n",
    "    val_loss /= len(loader.dataset)\n",
    "    model_diff /= len(loader.dataset)\n",
    "\n",
    "    return val_loss, weight_path, model_diff, diffs_path"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Wij0ERxmMoCl"
   },
   "source": [
    "from IPython.display import clear_output\n",
    "\n",
    "\n",
    "def plot_losses(\n",
    "    train_losses: list[float],\n",
    "    val_losses: list[float],\n",
    "    train_pnls: list[float],\n",
    "    val_pnls: list[float],\n",
    "):\n",
    "    clear_output()\n",
    "    fig, axs = plt.subplots(1, 2, figsize=(13, 4))\n",
    "    axs[0].plot(range(1, len(train_losses) + 1), train_losses, label=\"train\")\n",
    "    axs[0].plot(range(1, len(val_losses) + 1), val_losses, label=\"val\")\n",
    "    axs[0].set_ylabel(\"loss\")\n",
    "\n",
    "    axs[1].plot(range(1, len(train_pnls) + 1), train_pnls, label=\"train\")\n",
    "    axs[1].plot(range(1, len(val_pnls) + 1), val_pnls, label=\"val\")\n",
    "    axs[1].set_ylabel(\"PnL, RUB\")\n",
    "\n",
    "    for ax in axs:\n",
    "        ax.set_xlabel(\"epoch\")\n",
    "        ax.legend()\n",
    "\n",
    "    plt.show()"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7kOgOK7kOnaw"
   },
   "source": [
    "from typing import Tuple, List, Optional, Any\n",
    "\n",
    "\n",
    "def train(\n",
    "    model: nn.Module,\n",
    "    optimizer: torch.optim.Optimizer,\n",
    "    scheduler: Optional[Any],\n",
    "    train_loader: DataLoader,\n",
    "    val_loader: DataLoader,\n",
    "    num_epochs: int,\n",
    "    print_logs: bool = True,\n",
    ") -> Tuple[List[float], List[float]]:\n",
    "    train_losses, val_losses = [], []\n",
    "    train_diffs, val_diffs = [], []\n",
    "    criterion = nn.MSELoss().to(DEVICE)\n",
    "\n",
    "    for epoch in range(1, num_epochs + 1):\n",
    "        if print_logs:\n",
    "            desc_train = f\"Training {epoch}/{num_epochs}\"\n",
    "            desc_val = f\"Validation {epoch}/{num_epochs}\"\n",
    "        else:\n",
    "            desc_train, desc_val = None, None\n",
    "\n",
    "        train_loss, weights, train_diff, train_path = train_epoch(\n",
    "            model, optimizer, criterion, train_loader, tqdm_desc=desc_train\n",
    "        )\n",
    "        val_loss, weights, val_diff, val_path = validation_epoch(\n",
    "            model, criterion, val_loader, tqdm_desc=desc_val\n",
    "        )\n",
    "\n",
    "        if scheduler is not None:\n",
    "            scheduler.step()\n",
    "\n",
    "        train_losses += [train_loss]\n",
    "        val_losses += [val_loss]\n",
    "\n",
    "        train_diffs += [train_diff]\n",
    "        val_diffs += [val_diff]\n",
    "\n",
    "        plot_losses(train_losses, val_losses, train_diffs, val_diffs)\n",
    "\n",
    "    return train_losses, val_losses, weights, train_diffs, val_diffs"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TdKQ5Ap2JoJa",
    "outputId": "7d609839-51c5-4a70-a09a-f90a3ee4a107"
   },
   "source": [
    "TEST_SIZE = 0.1\n",
    "train_data = data.resample(\"30 min\").ffill()\n",
    "time_split = train_data.index[int(train_data.index.shape[0] * (1 - TEST_SIZE))]\n",
    "train_df, test_df = (\n",
    "    train_data[train_data.index <= time_split],\n",
    "    train_data[train_data.index > time_split],\n",
    ")\n",
    "train_df.shape, test_df.shape"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 388
    },
    "id": "nRscxjBSOnax",
    "outputId": "5c98a0dd-99f5-4f34-f09c-4cbe27640d12"
   },
   "source": [
    "N_EPOCHS = 3\n",
    "\n",
    "hedger = NeuralHedger().to(DEVICE)\n",
    "\n",
    "# train_set = SpotDataset(data=train_df, instrument_cls=EuropeanCall)\n",
    "# val_set = SpotDataset(data=test_df, instrument_cls=EuropeanCall)\n",
    "\n",
    "train_set = SpotDataset(data=train_df, instrument_cls=Forward)\n",
    "val_set = SpotDataset(data=test_df, instrument_cls=Forward)\n",
    "\n",
    "train_loader = DataLoader(train_set, batch_size=32, shuffle=True, drop_last=False)\n",
    "val_loader = DataLoader(val_set, batch_size=32, shuffle=True, drop_last=False)\n",
    "\n",
    "# optimizer = torch.optim.SGD(hedger.parameters(), lr=0.001, momentum=0.9)\n",
    "optimizer = torch.optim.Adam(hedger.parameters())\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=N_EPOCHS)\n",
    "\n",
    "train_losses, val_losses, weights, train_diffs, val_diffs = train(\n",
    "    model=hedger,\n",
    "    optimizer=optimizer,\n",
    "    scheduler=scheduler,\n",
    "    train_loader=train_loader,\n",
    "    val_loader=val_loader,\n",
    "    num_epochs=N_EPOCHS,\n",
    "    print_logs=True,\n",
    ")"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3q0ps9fQfkDx"
   },
   "source": [
    "# torch.save(hedger, PATH / \"fwd_out_new.pt\")"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "def assess_model(model: nn.Module, baseline: nn.Module) -> None:\n",
    "    _, weights, _, model_diff = validation_epoch(model, nn.MSELoss(), val_loader)\n",
    "    _, _, _, baseline_diff = validation_epoch(baseline, nn.MSELoss(), val_loader)\n",
    "\n",
    "    model_diff = np.concatenate(model_diff, axis=0)\n",
    "    baseline_diff = np.concatenate(baseline_diff, axis=0)\n",
    "\n",
    "    # print(weights[-1])\n",
    "    # print(model_diff)\n",
    "\n",
    "    print(\n",
    "        f\"Average weight = {weights[-1].mean()}, Weights = [{weights[-1].min()}; {weights[-1].max()}]\"\n",
    "    )\n",
    "\n",
    "    print(\n",
    "        f\"Means: model = {model_diff.mean():.6f}, baseline = {baseline_diff.mean():.6f}\"\n",
    "    )\n",
    "\n",
    "    print(f\"Stds: model = {model_diff.std():.6f}, baseline = {baseline_diff.std():.6f}\")\n",
    "\n",
    "    print(\n",
    "        f\"VaRs 5%: model = {np.abs(np.quantile(model_diff, 0.05)):.6f}, baseline = {np.abs(np.quantile(baseline_diff, 0.05)):.6f}\"\n",
    "    )\n",
    "\n",
    "    t_value = (model_diff.mean() - baseline_diff.mean()) / np.sqrt(\n",
    "        model_diff.std() ** 2 / model_diff.shape[0]\n",
    "        + baseline_diff.std() ** 2 / baseline_diff.shape[0]\n",
    "    )\n",
    "    print(f\"T-stat = {t_value:.6f}\")\n",
    "\n",
    "    bins = np.linspace(-0.25, 0.25, 100)\n",
    "\n",
    "    plt.hist(model_diff, bins, alpha=0.5, label=\"model\")\n",
    "    plt.hist(baseline_diff, bins, alpha=0.5, label=\"baseline\")\n",
    "    plt.legend(loc=\"upper right\")\n",
    "    plt.show()"
   ],
   "metadata": {
    "id": "S0i34ec91c9v"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nd9N5PtFsiBe"
   },
   "source": [
    "class BaselineForward(nn.Module):\n",
    "    def __init__(self, dt: float = AVERAGE_DT):\n",
    "        super().__init__()\n",
    "\n",
    "        self.lstm = nn.LSTM(1, 1, num_layers=1, batch_first=True)\n",
    "        self.dt = dt\n",
    "\n",
    "    def forward(self, spot: torch.Tensor, return_hidden: bool = False) -> torch.Tensor:\n",
    "        return (\n",
    "            torch.Tensor([[1] * (spot.shape[1] - 2)] * spot.shape[0])\n",
    "            .to(torch.float32)\n",
    "            .to(DEVICE)\n",
    "        )\n",
    "\n",
    "    def get_pnl(self, spot: torch.Tensor) -> torch.float32:\n",
    "        # hedging_weights = nn.Softmax()(self.forward(spot, return_hidden=False), dim=XXX)\n",
    "        hedging_weights = self.forward(spot, return_hidden=False)\n",
    "        return hedging_weights, get_pnl(spot=spot, weights=hedging_weights, dt=self.dt)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "assess_model(hedger, BaselineForward().to(DEVICE))"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 515
    },
    "id": "IULEBkEGSgVi",
    "outputId": "e08f91b9-a43e-4f4b-c4d9-ae77f5d41e5d"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "assess_model(hedger, BaselineForward().to(DEVICE))"
   ],
   "metadata": {
    "id": "zhzB_lLn3Cnu",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 515
    },
    "outputId": "875c21b6-3797-4435-affa-1ad7d33715c1"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "h05ZeQ4D7O_2"
   },
   "source": [
    "## Option."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jtrsaV7s7Sl0"
   },
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "class EuropeanCall(Instrument):\n",
    "    def __init__(self, rates_difference: float, spot_price: float, term: float):\n",
    "        super().__init__()\n",
    "        self.rates_difference = rates_difference\n",
    "        self.spot_price = spot_price\n",
    "        self.term = term\n",
    "\n",
    "    def coupon(self, frequency: float = 0.0, *args, **kwargs) -> float:\n",
    "        return 0\n",
    "\n",
    "    def pv_coupons(self) -> float:\n",
    "        return 0\n",
    "\n",
    "    def get_strike(self, spot_price: [float, None] = None) -> float:\n",
    "        return self.spot_price\n",
    "\n",
    "    @property\n",
    "    def strike(self) -> float:\n",
    "        return self.get_strike()\n",
    "\n",
    "    def price(self, spot_start: [float, list[float], None] = None) -> float:\n",
    "        return 0\n",
    "\n",
    "    def payoff(self, spot: [float, np.array]) -> float:\n",
    "        return max(spot - self.strike, 0)\n",
    "\n",
    "    def __repr__(self):\n",
    "        return f\"EuropeanCall(strike={self.strike}, term={self.term}, spot_ref={self.spot_price})\""
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "class BaselineEuropeanCall(nn.Module):\n",
    "    def __init__(self, dt: float = AVERAGE_DT):\n",
    "        super().__init__()\n",
    "\n",
    "        self.lstm = nn.LSTM(1, 1, num_layers=1, batch_first=True)\n",
    "        self.dt = dt\n",
    "\n",
    "        self.strike = 1\n",
    "\n",
    "    def _call_delta(\n",
    "        self, mid: torch.Tensor, rates: torch.Tensor, terms: torch.Tensor\n",
    "    ) -> torch.float32:\n",
    "        \"\"\"\n",
    "        Call option delta [dV/dS] via analytical form solution of Black-Scholes-Merton.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        delta : float\n",
    "            Option delta.\n",
    "        \"\"\"\n",
    "        strikes = mid[:, 0] * self.strike\n",
    "        # print(strikes[: -1])\n",
    "        sigma = mid.std(dim=1).unsqueeze(1)\n",
    "        # print(\"***\")\n",
    "        d1 = (\n",
    "            torch.log(mid / strikes.unsqueeze(1)) + (rates + sigma**2 / 2) * terms\n",
    "        ) / (sigma * torch.sqrt(terms))\n",
    "        d1 = d1[:, 1:-1]\n",
    "        # print(d1.shape)\n",
    "        # print(\"***\")\n",
    "\n",
    "        cdf_d1 = torch.distributions.normal.Normal(0, 1).cdf(d1)\n",
    "\n",
    "        return cdf_d1\n",
    "\n",
    "    def forward(self, spot: torch.Tensor, return_hidden: bool = False) -> torch.Tensor:\n",
    "        mid = (spot[:, :, 0] + spot[:, :, 1]) / 2\n",
    "        rates = spot[:, :, 2] - spot[:, :, 3]\n",
    "        terms = spot[:, :, 4]\n",
    "        return self._call_delta(mid=mid, rates=rates, terms=terms)\n",
    "\n",
    "    def get_pnl(self, spot: torch.Tensor) -> torch.float32:\n",
    "        # hedging_weights = nn.Softmax()(self.forward(spot, return_hidden=False), dim=XXX)\n",
    "        hedging_weights = self.forward(spot, return_hidden=False)\n",
    "        return hedging_weights, get_pnl(spot=spot, weights=hedging_weights, dt=self.dt)"
   ],
   "metadata": {
    "id": "JazkoYw9N04B"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "baseline = BaselineEuropeanCall().to(DEVICE)\n",
    "loader = DataLoader(spot_dataset, batch_size=32, shuffle=True, drop_last=True)\n",
    "for feature, target in loader:\n",
    "    print(feature.shape)\n",
    "    w = baseline(feature)\n",
    "    pnl = baseline.get_pnl(feature.to(torch.float32))\n",
    "    break\n",
    "w"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "utlXWctRPBgY",
    "outputId": "2ee77dc9-b1e9-469a-feae-c5bc337a57d8"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "w.shape"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dNirg90qV_P-",
    "outputId": "a79beb62-fcbd-484d-945f-034f90ed0c6b"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "w[:, -1]"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PqqTyLdIV_9s",
    "outputId": "cec1385b-064a-4bbf-b71c-679315d4cd81"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "feature[:, -1, :2]"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6-ONEScGWHG4",
    "outputId": "ecd17729-6896-44bb-bc53-9fa3fb8efbf5"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "feature[0]"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "p55DY0VCVmjn",
    "outputId": "b65a78bc-587d-4cd7-c854-3cd5c9d0a2fa"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "class NeuralHedger(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        input_size: int = 5,\n",
    "        num_layers: int = 3,\n",
    "        hidden_size: int = 32,\n",
    "        dt: float = AVERAGE_DT,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.input_size = input_size\n",
    "        self.num_layers = num_layers\n",
    "        self.hidden_size = hidden_size\n",
    "        self.dt = dt\n",
    "\n",
    "        self.batch_norm = nn.BatchNorm1d(1441)\n",
    "\n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size, self.hidden_size, num_layers=num_layers, batch_first=True\n",
    "        )\n",
    "\n",
    "        self.hedging_weights = nn.Sequential(\n",
    "            nn.Linear(self.hidden_size, self.hidden_size),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(self.hidden_size, self.hidden_size),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(self.hidden_size, 1),\n",
    "        )\n",
    "\n",
    "    def forward(\n",
    "        self,\n",
    "        spot: torch.Tensor,\n",
    "        hidden: [(torch.Tensor), None] = None,\n",
    "        return_hidden: bool = False,\n",
    "    ) -> [torch.Tensor, (torch.Tensor, torch.Tensor, torch.Tensor)]:\n",
    "        model_device = spot.device\n",
    "        if hidden is None:\n",
    "            h_t = torch.zeros(\n",
    "                self.num_layers, spot.size(0), self.hidden_size, dtype=torch.float32\n",
    "            ).to(model_device)\n",
    "            c_t = torch.zeros(\n",
    "                self.num_layers, spot.size(0), self.hidden_size, dtype=torch.float32\n",
    "            ).to(model_device)\n",
    "        elif len(hidden) != 2:\n",
    "            raise ValueError(f\"Expected two hidden state variables, got {len(hidden)}\")\n",
    "        else:\n",
    "            h_t, c_t = hidden\n",
    "\n",
    "        price = self.batch_norm(spot[:, :, :2])\n",
    "        rates = self.batch_norm(spot[:, :, 2:4])\n",
    "        spot = torch.cat([price, rates, spot[:, :, 4:]], dim=2)\n",
    "\n",
    "        h_t, c_t = self.lstm(spot, (h_t, c_t))\n",
    "        outputs = self.hedging_weights(h_t)[:, 1:-1, :].squeeze(2)\n",
    "\n",
    "        if return_hidden:\n",
    "            return outputs, (h_t, c_t)\n",
    "        else:\n",
    "            return outputs\n",
    "\n",
    "    def get_pnl(self, spot: torch.Tensor) -> [torch.Tensor, torch.float32]:\n",
    "        # hedging_weights = nn.Softmax()(self.forward(spot, return_hidden=False), dim=XXX)\n",
    "        weights = self.forward(spot, return_hidden=False)\n",
    "\n",
    "        model_device = spot.device\n",
    "        weights_all = torch.concat(\n",
    "            [\n",
    "                torch.zeros(spot.shape[0], 1, requires_grad=False).to(model_device),\n",
    "                weights,\n",
    "                torch.zeros(spot.shape[0], 1, requires_grad=False).to(model_device),\n",
    "            ],\n",
    "            dim=1,\n",
    "        )\n",
    "        weights_diff = weights_all.diff(n=1, dim=1)\n",
    "\n",
    "        rates_diff = spot[:, :, 2] - spot[:, :, 3]\n",
    "\n",
    "        bought = torch.where(weights_diff > 0, weights_diff, 0)\n",
    "        sold = torch.where(weights_diff < 0, weights_diff, 0)\n",
    "\n",
    "        interest = (rates_diff * -weights_all).sum(dim=1) * self.dt\n",
    "\n",
    "        cash_outflow = (-spot[:, 1:, 1] * bought).sum(dim=1)\n",
    "        cash_inflow = (-spot[:, 1:, 0] * sold).sum(dim=1)\n",
    "\n",
    "        pnl = (cash_outflow + cash_inflow + interest).unsqueeze(1)\n",
    "\n",
    "        return weights, pnl"
   ],
   "metadata": {
    "id": "RlPV1uOiLR2q"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "call_hedger = NeuralHedger().to(DEVICE)\n",
    "loader = DataLoader(\n",
    "    SpotDataset(data=train_df, instrument_cls=EuropeanCall),\n",
    "    batch_size=32,\n",
    "    shuffle=True,\n",
    "    drop_last=False,\n",
    ")\n",
    "for feature, target in loader:\n",
    "    print(feature.shape)\n",
    "    w = call_hedger(feature.to(DEVICE))\n",
    "    pnl = call_hedger.get_pnl(feature.to(torch.float32).to(DEVICE))\n",
    "    break\n",
    "w"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "X7U4AhpWt9wE",
    "outputId": "4b4d47b1-966b-4b0c-b2ae-43bb0558d4ca"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "hedger = NeuralHedger()\n",
    "loader = DataLoader(\n",
    "    SpotDataset(data=train_df, instrument_cls=EuropeanCall),\n",
    "    batch_size=32,\n",
    "    shuffle=True,\n",
    "    drop_last=False,\n",
    ")\n",
    "\n",
    "for feature, target in loader:\n",
    "    print(feature.shape)\n",
    "    pnl = hedger.get_pnl(feature.to(torch.float32))\n",
    "    break\n",
    "pnl"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wXbAlMSsPr9_",
    "outputId": "857cf604-cf56-475e-df31-c927091f52a4"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "class BaselineTrivial(nn.Module):\n",
    "    def __init__(self, dt: float = AVERAGE_DT):\n",
    "        super().__init__()\n",
    "\n",
    "        self.lstm = nn.LSTM(1, 1, num_layers=1, batch_first=True)\n",
    "        self.dt = dt\n",
    "\n",
    "    def forward(self, spot: torch.Tensor, return_hidden: bool = False) -> torch.Tensor:\n",
    "        return (\n",
    "            torch.Tensor([[0] * (spot.shape[1] - 2)] * spot.shape[0])\n",
    "            .to(torch.float32)\n",
    "            .to(DEVICE)\n",
    "        )\n",
    "\n",
    "    def get_pnl(self, spot: torch.Tensor) -> torch.float32:\n",
    "        # hedging_weights = nn.Softmax()(self.forward(spot, return_hidden=False), dim=XXX)\n",
    "        hedging_weights = self.forward(spot, return_hidden=False)\n",
    "        return hedging_weights, get_pnl(spot=spot, weights=hedging_weights, dt=self.dt)"
   ],
   "metadata": {
    "id": "2pAqlUWqJkFl"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "TEST_SIZE = 0.1\n",
    "train_data = data.resample(\"5 min\").ffill()\n",
    "time_split = train_data.index[int(train_data.index.shape[0] * (1 - TEST_SIZE))]\n",
    "train_df, test_df = (\n",
    "    train_data[train_data.index <= time_split],\n",
    "    train_data[train_data.index > time_split],\n",
    ")"
   ],
   "metadata": {
    "id": "Qi0KX1_Y7K1f"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "N_EPOCHS = 30\n",
    "\n",
    "hedger = NeuralHedger().to(DEVICE)\n",
    "\n",
    "train_set = SpotDataset(data=train_df, instrument_cls=EuropeanCall)\n",
    "val_set = SpotDataset(data=test_df, instrument_cls=EuropeanCall)\n",
    "\n",
    "train_loader = DataLoader(train_set, batch_size=32, shuffle=True, drop_last=False)\n",
    "val_loader = DataLoader(val_set, batch_size=32, shuffle=True, drop_last=False)\n",
    "\n",
    "optimizer = torch.optim.Adam(hedger.parameters())\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=N_EPOCHS)\n",
    "\n",
    "train_losses, val_losses, weights, train_diffs, val_diffs = train(\n",
    "    model=hedger,\n",
    "    optimizer=optimizer,\n",
    "    scheduler=scheduler,\n",
    "    train_loader=train_loader,\n",
    "    val_loader=val_loader,\n",
    "    num_epochs=N_EPOCHS,\n",
    "    print_logs=True,\n",
    ")"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 390
    },
    "id": "jsPzA3t66iEy",
    "outputId": "a5f74954-b41b-44f4-bccb-c97be51431cd"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "assess_model(hedger, BaselineEuropeanCall().to(DEVICE))"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 515
    },
    "id": "2OKann_46ine",
    "outputId": "d050096a-f5be-4246-e2e3-42e125910e44"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "N_EPOCHS = 30\n",
    "\n",
    "hedger = NeuralHedger().to(DEVICE)\n",
    "\n",
    "train_set = SpotDataset(data=train_df, instrument_cls=EuropeanCall)\n",
    "val_set = SpotDataset(data=test_df, instrument_cls=EuropeanCall)\n",
    "\n",
    "train_loader = DataLoader(train_set, batch_size=32, shuffle=True, drop_last=False)\n",
    "val_loader = DataLoader(val_set, batch_size=32, shuffle=True, drop_last=False)\n",
    "\n",
    "# optimizer = torch.optim.SGD(hedger.parameters(), lr=0.5 / 100, momentum=0.9, weight_decay=2e-05)\n",
    "optimizer = torch.optim.Adam(hedger.parameters())\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=N_EPOCHS)\n",
    "\n",
    "train_losses, val_losses, weights, train_diffs, val_diffs = train(\n",
    "    model=hedger,\n",
    "    optimizer=optimizer,\n",
    "    scheduler=scheduler,\n",
    "    train_loader=train_loader,\n",
    "    val_loader=val_loader,\n",
    "    num_epochs=N_EPOCHS,\n",
    "    print_logs=True,\n",
    ")"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 391
    },
    "id": "qH92SPjimGSV",
    "outputId": "d29aa0f8-35bc-4796-9808-99b1d150a936"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "assess_model(hedger, BaselineEuropeanCall().to(DEVICE))"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 515
    },
    "id": "GWsICzm3mG5B",
    "outputId": "007fa303-69c4-4956-85f1-3393d0be8025"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# BATCH_SIZE = 8\n",
    "N_EPOCHS = 30\n",
    "\n",
    "hedger = NeuralHedger().to(DEVICE)\n",
    "\n",
    "train_set = SpotDataset(data=train_df, instrument_cls=EuropeanCall)\n",
    "val_set = SpotDataset(data=test_df, instrument_cls=EuropeanCall)\n",
    "\n",
    "train_loader = DataLoader(train_set, batch_size=32, shuffle=True, drop_last=False)\n",
    "val_loader = DataLoader(val_set, batch_size=32, shuffle=True, drop_last=False)\n",
    "\n",
    "# optimizer = torch.optim.SGD(hedger.parameters(), lr=0.001, momentum=0.9)\n",
    "optimizer = torch.optim.Adam(hedger.parameters())\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=N_EPOCHS)\n",
    "\n",
    "train_losses, val_losses, weights, train_diffs, val_diffs = train(\n",
    "    model=hedger,\n",
    "    optimizer=optimizer,\n",
    "    scheduler=scheduler,\n",
    "    train_loader=train_loader,\n",
    "    val_loader=val_loader,\n",
    "    num_epochs=N_EPOCHS,\n",
    "    print_logs=True,\n",
    ")"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 388
    },
    "id": "JCK_5gEHScWk",
    "outputId": "085fb3b4-6dbc-4d9e-e816-94bc5b1e7934"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "assess_model(hedger, BaselineEuropeanCall().to(DEVICE))"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 515
    },
    "id": "pO0wdtxiSeP4",
    "outputId": "0ae172d0-1f53-44a8-a213-3f8af4c30b45"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# BATCH_SIZE = 16\n",
    "N_EPOCHS = 30\n",
    "\n",
    "hedger = NeuralHedger().to(DEVICE)\n",
    "\n",
    "train_set = SpotDataset(data=train_df, instrument_cls=EuropeanCall)\n",
    "val_set = SpotDataset(data=test_df, instrument_cls=EuropeanCall)\n",
    "\n",
    "train_loader = DataLoader(train_set, batch_size=32, shuffle=True, drop_last=False)\n",
    "val_loader = DataLoader(val_set, batch_size=32, shuffle=True, drop_last=False)\n",
    "\n",
    "# optimizer = torch.optim.SGD(hedger.parameters(), lr=0.001, momentum=0.9)\n",
    "optimizer = torch.optim.Adam(hedger.parameters())\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=N_EPOCHS)\n",
    "\n",
    "train_losses, val_losses, weights, train_diffs, val_diffs = train(\n",
    "    model=hedger,\n",
    "    optimizer=optimizer,\n",
    "    scheduler=scheduler,\n",
    "    train_loader=train_loader,\n",
    "    val_loader=val_loader,\n",
    "    num_epochs=N_EPOCHS,\n",
    "    print_logs=True,\n",
    ")"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 388
    },
    "id": "D0hzQtzFbdvS",
    "outputId": "05dcb52c-5b12-441f-d81b-6b02189f9397"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "assess_model(hedger, BaselineEuropeanCall().to(DEVICE))"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 515
    },
    "id": "QHRORX7Bbef3",
    "outputId": "85fb554a-cf94-4538-dfc3-d0396b4c2676"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6gpXp84S7Y2T",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 388
    },
    "outputId": "0857d8d2-2e87-4306-d321-d8b91f8bd06a"
   },
   "source": [
    "N_EPOCHS = 30\n",
    "\n",
    "hedger = NeuralHedger().to(DEVICE)\n",
    "\n",
    "train_set = SpotDataset(data=train_df, instrument_cls=EuropeanCall)\n",
    "val_set = SpotDataset(data=test_df, instrument_cls=EuropeanCall)\n",
    "\n",
    "train_loader = DataLoader(train_set, batch_size=32, shuffle=True, drop_last=False)\n",
    "val_loader = DataLoader(val_set, batch_size=32, shuffle=True, drop_last=False)\n",
    "\n",
    "# optimizer = torch.optim.SGD(hedger.parameters(), lr=0.001, momentum=0.9)\n",
    "optimizer = torch.optim.Adam(hedger.parameters())\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=N_EPOCHS)\n",
    "\n",
    "train_losses, val_losses, weights, train_diffs, val_diffs = train(\n",
    "    model=hedger,\n",
    "    optimizer=optimizer,\n",
    "    scheduler=scheduler,\n",
    "    train_loader=train_loader,\n",
    "    val_loader=val_loader,\n",
    "    num_epochs=N_EPOCHS,\n",
    "    print_logs=True,\n",
    ")"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YkGZ3kuULB55"
   },
   "source": [
    "torch.save(hedger, PATH / \"opt_out_new_30_bn_till_sgd.pt\")"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "assess_model(hedger, BaselineEuropeanCall().to(DEVICE))"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 515
    },
    "id": "ZT-c8AVzLg_z",
    "outputId": "7b5bc748-5ffc-4acd-e158-8ab113211b04"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "assess_model(hedger, BaselineEuropeanCall().to(DEVICE))"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 515
    },
    "id": "ThXZTcubFoiG",
    "outputId": "bb337fd8-bdd3-4b36-d17b-7f5122a58cb4"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "assess_model(hedger, BaselineEuropeanCall().to(DEVICE))"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 515
    },
    "id": "gQNnkp903Ywx",
    "outputId": "86bb7c7d-4243-4d06-c8da-570ac679e54e"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "assess_model(hedger, BaselineEuropeanCall().to(DEVICE))"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 515
    },
    "id": "bZ1fQ5ERvVwa",
    "outputId": "3d9c1baa-4ba9-432c-feb2-330e4e357620"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "assess_model(hedger, BaselineEuropeanCall().to(DEVICE))"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 515
    },
    "id": "LUpUQDGJO92S",
    "outputId": "026d13c9-c356-465f-ea28-32b2d6023c55"
   },
   "execution_count": null,
   "outputs": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "max_cell_id": 35
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
