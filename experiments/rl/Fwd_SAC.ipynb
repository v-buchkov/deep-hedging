{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "41VE08_pyFuR"
   },
   "source": [
    "# **Deep Hedging**\n",
    "# Buchkov Viacheslav"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "LKcSNj4tlRVK"
   },
   "source": [
    "import abc\n",
    "import math\n",
    "import os\n",
    "import random\n",
    "import sys\n",
    "from functools import lru_cache\n",
    "from pathlib import Path\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "\n",
    "# You may add any imports you need\n",
    "from torch.cuda.amp import GradScaler\n",
    "\n",
    "RANDOM_SEED = 12"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "47YPLjDL-Mtv"
   },
   "source": [
    "def seed_everything(seed):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "\n",
    "\n",
    "seed_everything(RANDOM_SEED)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "ZrCB4LgfO8y6"
   },
   "source": [
    "if torch.backends.mps.is_available():\n",
    "    DEVICE = torch.device(\"mps\")\n",
    "elif torch.cuda.is_available():\n",
    "    DEVICE = torch.device(\"cuda\")\n",
    "else:\n",
    "    DEVICE = torch.device(\"cpu\")"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QmkSjI1Regtf",
    "outputId": "46311ac0-1162-4bad-e863-99deea39ce21"
   },
   "source": [
    "from google.colab import drive\n",
    "\n",
    "drive.mount(\"/content/gdrive\", force_remount=True)\n",
    "\n",
    "ROOT_PATH = Path(\"dataset\")\n",
    "PATH = Path(\"/content/gdrive/MyDrive/\")\n",
    "N_DAYS = 5"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 450
    },
    "id": "kmiS11dsOnaq",
    "outputId": "8ecadc2e-a185-41dc-96e9-e2383025e916"
   },
   "source": [
    "data = pd.read_pickle(PATH / \"data.pkl\")\n",
    "data[\"rub_rate\"] = data[\"rub_rate\"] / 100\n",
    "data.dropna(inplace=True)\n",
    "data"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "8UKB-Db2PqIK"
   },
   "source": [
    "import abc\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from enum import Enum\n",
    "\n",
    "\n",
    "class PositionSide(Enum):\n",
    "    LONG = 1\n",
    "    SHORT = -1\n",
    "\n",
    "\n",
    "class Instrument:\n",
    "    CALENDAR_DAYS: int = 365\n",
    "\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def bid(self, margin: float) -> float:\n",
    "        return self.price() - margin\n",
    "\n",
    "    def offer(self, margin: float) -> float:\n",
    "        return self.price() + margin\n",
    "\n",
    "    @staticmethod\n",
    "    def discount_factor(rate: float, term: float) -> float:\n",
    "        return np.exp(-rate * term)\n",
    "\n",
    "    @abc.abstractmethod\n",
    "    def coupon(self, frequency: float = 0.0, *args, **kwargs) -> float:\n",
    "        raise NotImplementedError\n",
    "\n",
    "    @abc.abstractmethod\n",
    "    def pv_coupons(self) -> float:\n",
    "        raise NotImplementedError\n",
    "\n",
    "    @abc.abstractmethod\n",
    "    def price(self, spot_start: [float, list[float], None] = None) -> float:\n",
    "        raise NotImplementedError\n",
    "\n",
    "    @abc.abstractmethod\n",
    "    def payoff(self, spot: [np.array, float]) -> float:\n",
    "        raise NotImplementedError\n",
    "\n",
    "    @abc.abstractmethod\n",
    "    def __repr__(self):\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def __str__(self):\n",
    "        return self.__repr__()\n",
    "\n",
    "    def __add__(self, other):\n",
    "        return StructuredNote([(PositionSide.LONG, self), (PositionSide.LONG, other)])\n",
    "\n",
    "    def __sub__(self, other):\n",
    "        return StructuredNote([(PositionSide.LONG, self), (PositionSide.SHORT, other)])\n",
    "\n",
    "\n",
    "class StructuredNote:\n",
    "    def __init__(\n",
    "        self, instruments: [list[tuple[PositionSide, Instrument]], None] = None\n",
    "    ):\n",
    "        if instruments is not None:\n",
    "            self.instruments = instruments\n",
    "        else:\n",
    "            self.instruments = []\n",
    "\n",
    "    def bid(self, margin: float) -> float:\n",
    "        return self.price() - margin\n",
    "\n",
    "    def offer(self, margin: float) -> float:\n",
    "        return self.price() + margin\n",
    "\n",
    "    def coupon(\n",
    "        self, frequency: float = 0.0, commission: float = 0.0, *args, **kwargs\n",
    "    ) -> float:\n",
    "        return sum(\n",
    "            [\n",
    "                instrument.coupon(frequency, commission)\n",
    "                for _, instrument in self.instruments\n",
    "            ]\n",
    "        )\n",
    "\n",
    "    def __add__(self, other: Instrument):\n",
    "        return self.instruments.append((PositionSide.LONG, other))\n",
    "\n",
    "    def __sub__(self, other: Instrument):\n",
    "        return self.instruments.append((PositionSide.SHORT, other))\n",
    "\n",
    "    def price(self) -> float:\n",
    "        return sum(\n",
    "            [\n",
    "                side.value * instrument.price() + instrument.pv_coupons()\n",
    "                for side, instrument in self.instruments\n",
    "            ]\n",
    "        )\n",
    "\n",
    "    def payoff(self, spot_paths: np.array) -> float:\n",
    "        return sum(\n",
    "            [\n",
    "                side.value * instrument.payoff(spot_paths)\n",
    "                for side, instrument in self.instruments\n",
    "            ]\n",
    "        )\n",
    "\n",
    "    def __repr__(self):\n",
    "        sp_str = f\"StructuredNote of:\\n\"\n",
    "        for side, instrument in self.instruments:\n",
    "            sp_str += f\"* {side} -> {instrument}\\n\"\n",
    "        return sp_str\n",
    "\n",
    "    def __str__(self):\n",
    "        return self.__repr__()"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "WSq4YrPxPsBP"
   },
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "class Forward(Instrument):\n",
    "    def __init__(\n",
    "        self, rates_difference: float, spot_price: float, term: float, *args, **kwargs\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.rates_difference = rates_difference\n",
    "        self.spot_price = spot_price\n",
    "        self.term = term\n",
    "\n",
    "    def coupon(self, frequency: float = 0.0, *args, **kwargs) -> float:\n",
    "        return 0\n",
    "\n",
    "    def pv_coupons(self) -> float:\n",
    "        return 0\n",
    "\n",
    "    def get_strike(self, spot_price: [float, None] = None) -> float:\n",
    "        if spot_price is None:\n",
    "            spot_price = self.spot_price\n",
    "        return spot_price * self.discount_factor(\n",
    "            rate=-self.rates_difference, term=self.term\n",
    "        )\n",
    "\n",
    "    @property\n",
    "    def strike(self) -> float:\n",
    "        return self.get_strike()\n",
    "\n",
    "    def price(self, spot_start: [float, list[float], None] = None) -> float:\n",
    "        return 0\n",
    "\n",
    "    def payoff(self, spot: [float, np.array]) -> float:\n",
    "        return spot - self.strike\n",
    "\n",
    "    def __repr__(self):\n",
    "        return f\"Forward(strike={self.strike}, term={self.term}, spot_ref={self.spot_price})\""
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "Na70Ea_A7hoi"
   },
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "class EuropeanCall(Instrument):\n",
    "    def __init__(\n",
    "        self, rates_difference: float, spot_price: float, term: float, *args, **kwargs\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.rates_difference = rates_difference\n",
    "        self.spot_price = spot_price\n",
    "        self.term = term\n",
    "\n",
    "    def coupon(self, frequency: float = 0.0, *args, **kwargs) -> float:\n",
    "        return 0\n",
    "\n",
    "    def pv_coupons(self) -> float:\n",
    "        return 0\n",
    "\n",
    "    def get_strike(self, spot_price: [float, None] = None) -> float:\n",
    "        return self.spot_price\n",
    "\n",
    "    @property\n",
    "    def strike(self) -> float:\n",
    "        return self.get_strike()\n",
    "\n",
    "    def price(self, spot_start: [float, list[float], None] = None) -> float:\n",
    "        return 0\n",
    "\n",
    "    def payoff(self, spot: [float, np.array]) -> float:\n",
    "        return max(spot - self.strike, 0)\n",
    "\n",
    "    def __repr__(self):\n",
    "        return f\"EuropeanCall(strike={self.strike}, term={self.term}, spot_ref={self.spot_price})\""
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "Mou9GCV8Onar"
   },
   "source": [
    "# from src.base.instrument import Instrument\n",
    "# from src.forward.forward import Forward\n",
    "\n",
    "\n",
    "def create_instrument(period_df: pd.DataFrame) -> Instrument:\n",
    "    start = period_df.loc[period_df.index.min()]\n",
    "    return EuropeanCall(\n",
    "        rates_difference=start[\"rub_rate\"] - start[\"usd_rate\"],\n",
    "        spot_price=start[\"ask\"],\n",
    "        term=N_DAYS / 365,\n",
    "    )"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 450
    },
    "id": "JgRMD8IqOnar",
    "outputId": "f0698189-68b0-42db-c7b6-a5c8a3ed6593"
   },
   "source": [
    "import datetime as dt\n",
    "\n",
    "start_date = data.index.min()\n",
    "end_date = start_date + dt.timedelta(days=N_DAYS)\n",
    "data[(data.index >= data.index.min()) & (data.index <= end_date)]"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BdcEuFc0Onas",
    "outputId": "aca10ac4-13a5-4607-8388-d939fcca89e9"
   },
   "source": [
    "call = create_instrument(\n",
    "    data[(data.index >= data.index.min()) & (data.index <= end_date)]\n",
    ")\n",
    "call"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cty5h8mOOnas"
   },
   "source": [
    "## Dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vQ8jn9mdv2QR"
   },
   "source": [
    "# Env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "gv_rNh-6v1oG"
   },
   "source": [
    "# from typing import Type, Union\n",
    "\n",
    "# import gym\n",
    "# from gym import spaces\n",
    "\n",
    "# import numpy as np\n",
    "# import pandas as pd\n",
    "# pd.options.mode.chained_assignment = None\n",
    "\n",
    "# N_DAYS = 5\n",
    "\n",
    "\n",
    "# class DerivativeEnv(gym.Env):\n",
    "#     METADATA = {'render.modes': ['human']}\n",
    "\n",
    "#     BID_COLUMN: str = \"bid\"\n",
    "#     ASK_COLUMN: str = \"ask\"\n",
    "#     RATE_DOMESTIC_COLUMN: str = \"rub_rate\"\n",
    "#     RATE_FOREIGN_COLUMN: str = \"usd_rate\"\n",
    "\n",
    "#     TRADING_DAYS: int = 252\n",
    "\n",
    "#     def __init__(\n",
    "#             self,\n",
    "#             instrument_cls: Type[Instrument],\n",
    "#             n_days: int = N_DAYS,\n",
    "#             path: Path = PATH,\n",
    "#             data: Union[pd.DataFrame, None] = None,\n",
    "#             random_seed: Union[int, None] = None,\n",
    "#             device: Union[str, None] = None\n",
    "#     ):\n",
    "#         # Internal attributes\n",
    "#         self.instrument_cls = instrument_cls\n",
    "#         self.n_days = n_days\n",
    "\n",
    "#         self.random_seed = random_seed\n",
    "\n",
    "#         self.device = self._get_device() if device is None else device\n",
    "\n",
    "#         self.data = self._create_df(path) if data is None else data.copy()\n",
    "#         self.data.dropna(inplace=True)\n",
    "\n",
    "#         self.data[\"time_diff\"] = self.data.index.to_series().diff()\n",
    "#         self.data.loc[self.data.index[0], \"time_diff\"] = pd.to_timedelta(\"0 days 00:00:00\")\n",
    "#         self.data[\"time_diff\"] = self.data[\"time_diff\"].cumsum() / np.timedelta64(1, 'D') / 365\n",
    "\n",
    "#         self.dt = self.get_average_dt()\n",
    "\n",
    "#         self._last_point = self.data.shape[0] - self.data[self.data.index >= self.data.index.max() - dt.timedelta(days=self.n_days)].shape[0]\n",
    "\n",
    "#         # RL attributes\n",
    "#         self.action_space = spaces.Box(low=-5, high=5, dtype=np.float32)\n",
    "\n",
    "#         self.observation_space = spaces.Box(low=-np.inf, high=np.inf, shape=(1, 5), dtype=np.float32)\n",
    "\n",
    "#         self._initialize()\n",
    "\n",
    "#     def _get_device(self) -> torch.device:\n",
    "#         if torch.backends.mps.is_available():\n",
    "#             return torch.device('mps')\n",
    "#         elif torch.cuda.is_available():\n",
    "#             return torch.device('cuda')\n",
    "#         else:\n",
    "#             return torch.device('cpu')\n",
    "\n",
    "#     def _initialize(self):\n",
    "#         self.current_step = 0\n",
    "#         self._pnl = 0\n",
    "#         self.weights = torch.Tensor([0]).to(self.device)\n",
    "#         self.pnl_path = []\n",
    "#         self.diff_path = []\n",
    "\n",
    "#         self._trajectory_data, self._target_pnl, self._max_step = self._sample_trajectory()\n",
    "\n",
    "#     def get_pnl(self, weights: torch.Tensor, spot: torch.Tensor) -> tuple[torch.Tensor, torch.float32]:\n",
    "#         weights_diff = weights - self.weights\n",
    "\n",
    "#         rates_diff = spot[:, 2] - spot[:, 3]\n",
    "\n",
    "#         bought = torch.where(weights_diff > 0, weights_diff, 0)\n",
    "#         sold = torch.where(weights_diff < 0, weights_diff, 0)\n",
    "\n",
    "#         interest = (rates_diff * -weights) * self.dt\n",
    "\n",
    "#         cash_outflow = (-spot[:, 1] * bought)\n",
    "#         cash_inflow = (-spot[:, 0] * sold)\n",
    "\n",
    "#         return (cash_outflow + cash_inflow + interest).unsqueeze(1)\n",
    "\n",
    "#     def _create_instrument(self, period_df: pd.DataFrame) -> Instrument:\n",
    "#         start = period_df.loc[period_df.index.min()]\n",
    "#         return self.instrument_cls(\n",
    "#             rates_difference=start[\"rub_rate\"] - start[\"usd_rate\"],\n",
    "#             spot_price=start[\"ask\"],\n",
    "#             term=N_DAYS / 365\n",
    "#         )\n",
    "\n",
    "#     @staticmethod\n",
    "#     def _create_df(path: Path) -> pd.DataFrame:\n",
    "#         if \"data.pkl\" in os.listdir(path):\n",
    "#             return pd.read_pickle(PATH / \"data.pkl\")\n",
    "#         else:\n",
    "#             pass\n",
    "\n",
    "#     def _sample_trajectory(self) -> list[torch.Tensor, torch.Tensor, int]:\n",
    "#         if self.random_seed is not None:\n",
    "#             np.random.seed(self.random_seed)\n",
    "\n",
    "#         idx = np.random.choice(np.arange(self._last_point), replace=True)\n",
    "#         start_date = self.data.index[idx]\n",
    "#         end_date = start_date + dt.timedelta(days=self.n_days)\n",
    "\n",
    "#         features = self.data[(self.data.index >= start_date) & (self.data.index <= end_date)]\n",
    "#         time_start = features.iloc[0, -1]\n",
    "#         features[\"time_diff\"] = features[\"time_diff\"].apply(lambda x: x - time_start)\n",
    "#         target = self._create_instrument(features).payoff(spot=features.ask.iloc[-1])\n",
    "\n",
    "#         data = torch.Tensor(features.to_numpy()).to(torch.float32).to(self.device)\n",
    "#         target_pnl = torch.Tensor([target]).to(torch.float32).to(self.device)\n",
    "#         max_step = features.shape[0] - 2\n",
    "\n",
    "#         return data, target_pnl, max_step\n",
    "\n",
    "#     def _next_obs(self):\n",
    "#         return self._trajectory_data[self.current_step, :].unsqueeze(0)\n",
    "\n",
    "#     def get_average_dt(self):\n",
    "#         return self.data.index.to_series().diff(1).mean() / (np.timedelta64(1, 'D') * self.TRADING_DAYS)\n",
    "\n",
    "#     def step(self, action):\n",
    "#         self.current_step += 1\n",
    "\n",
    "#         reward = 0\n",
    "#         done = 0\n",
    "\n",
    "#         obs = self._next_obs()\n",
    "#         if self.current_step == self._max_step:\n",
    "#             action = torch.Tensor([0]).to(self.device)\n",
    "#             self._pnl += self.get_pnl(weights=action, spot=obs)\n",
    "\n",
    "#             diff = self._target_pnl - self._pnl\n",
    "#             reward = -(diff) ** 2\n",
    "\n",
    "#             self.pnl_path.append(self._pnl)\n",
    "#             self.diff_path.append(diff)\n",
    "\n",
    "#             self.current_step = 0\n",
    "#             self._pnl = 0\n",
    "#             self._trajectory_data, self._target_pnl, self._max_step = self._sample_trajectory()\n",
    "\n",
    "#             done = 1\n",
    "#         else:\n",
    "#             self._pnl += self.get_pnl(weights=action, spot=obs)\n",
    "#             self.weights = action\n",
    "\n",
    "#         return obs, reward, done, {}\n",
    "\n",
    "#     def reset(self):\n",
    "#         # Reset the state of the environment to an initial state\n",
    "#         self._initialize()\n",
    "\n",
    "#         return self._next_obs()\n",
    "\n",
    "#     def render(self, mode='human', close=False):\n",
    "#         print(self.pnl_path)\n",
    "#         print(self.diff_path)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "4RXTz-pXLL7v",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 139
    },
    "outputId": "7c776921-ca6a-4294-a81c-5b3668820766"
   },
   "source": [
    "# env = DerivativeEnv(instrument_cls=Forward)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Bw4D-m6bMBzE"
   },
   "source": [
    "# obs = env.reset()\n",
    "# obs"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nd9N5PtFsiBe"
   },
   "source": [
    "# class BaselinePolicyForward(nn.Module):\n",
    "#     def __init__(self, dt: float = env.dt):\n",
    "#         super().__init__()\n",
    "\n",
    "#         self.lstm = nn.LSTM(1, 1, num_layers=1, batch_first=True)\n",
    "#         self.dt = dt\n",
    "\n",
    "#     def forward(self, spot: torch.Tensor, return_hidden: bool = False) -> torch.Tensor:\n",
    "#         return torch.Tensor([1]).to(torch.float32).to(DEVICE)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sccCLcsAMcxV"
   },
   "source": [
    "# baseline = BaselinePolicyForward().to(DEVICE)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0qCaWYjuMdzP"
   },
   "source": [
    "# baseline(obs)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8Gr8dwgRLWJF"
   },
   "source": [
    "# obs = env.reset()\n",
    "# done = 0\n",
    "# while not done:\n",
    "#   # action, _states = model.predict(obs)\n",
    "#   action = baseline(obs.to(DEVICE))\n",
    "#   obs, rewards, done, _ = env.step(action)\n",
    "#   # env.render()"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WlSvauxbTk5K"
   },
   "source": [
    "# obs"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dF6h78ziT7cD"
   },
   "source": [
    "# obs[0][-1] * 365"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yk14xK08Txqc"
   },
   "source": [
    "# rewards"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_62JrqZwv4r8"
   },
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZK_xGGnIUOe5",
    "outputId": "e292df89-3a47-4cff-c78b-50ed2cce05ec"
   },
   "source": [
    "!pip install stable-baselines3[extra]"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Vu8fcP8eXYK3"
   },
   "source": [
    "# from typing import Type, Union\n",
    "\n",
    "# import gym\n",
    "# from gym import spaces\n",
    "\n",
    "# import numpy as np\n",
    "# import pandas as pd\n",
    "# pd.options.mode.chained_assignment = None\n",
    "\n",
    "# N_DAYS = 5\n",
    "\n",
    "\n",
    "# class DerivativeEnv(gym.Env):\n",
    "#     METADATA = {'render.modes': ['human']}\n",
    "\n",
    "#     BID_COLUMN: str = \"bid\"\n",
    "#     ASK_COLUMN: str = \"ask\"\n",
    "#     RATE_DOMESTIC_COLUMN: str = \"rub_rate\"\n",
    "#     RATE_FOREIGN_COLUMN: str = \"usd_rate\"\n",
    "\n",
    "#     TRADING_DAYS: int = 252\n",
    "\n",
    "#     def __init__(\n",
    "#             self,\n",
    "#             instrument_cls: Type[Instrument],\n",
    "#             n_days: int = N_DAYS,\n",
    "#             path: Path = PATH,\n",
    "#             data: Union[pd.DataFrame, None] = None,\n",
    "#             random_seed: Union[int, None] = None,\n",
    "#             device: Union[str, None] = None\n",
    "#     ):\n",
    "#         # Internal attributes\n",
    "#         self.instrument_cls = instrument_cls\n",
    "#         self.n_days = n_days\n",
    "\n",
    "#         self.random_seed = random_seed\n",
    "\n",
    "#         self.device = self._get_device() if device is None else device\n",
    "\n",
    "#         self.data = self._create_df(path) if data is None else data.copy()\n",
    "#         self.data.dropna(inplace=True)\n",
    "\n",
    "#         self.data[\"time_diff\"] = self.data.index.to_series().diff()\n",
    "#         self.data.loc[self.data.index[0], \"time_diff\"] = pd.to_timedelta(\"0 days 00:00:00\")\n",
    "#         self.data[\"time_diff\"] = self.data[\"time_diff\"].cumsum() / np.timedelta64(1, 'D') / 365\n",
    "\n",
    "#         self.dt = self.get_average_dt()\n",
    "\n",
    "#         self._last_point = self.data.shape[0] - self.data[self.data.index >= self.data.index.max() - dt.timedelta(days=self.n_days)].shape[0]\n",
    "\n",
    "#         # RL attributes\n",
    "#         self.action_space = spaces.Box(low=-5, high=5, dtype=np.float32)\n",
    "\n",
    "#         self.observation_space = spaces.Box(low=-np.inf, high=np.inf, shape=(1, 5), dtype=np.float32)\n",
    "\n",
    "#         self._initialize()\n",
    "\n",
    "#     def _get_device(self) -> torch.device:\n",
    "#         if torch.backends.mps.is_available():\n",
    "#             return torch.device('mps')\n",
    "#         elif torch.cuda.is_available():\n",
    "#             return torch.device('cuda')\n",
    "#         else:\n",
    "#             return torch.device('cpu')\n",
    "\n",
    "#     def _initialize(self):\n",
    "#         self.current_step = 0\n",
    "#         self._pnl = 0\n",
    "#         self.weights = np.array([0])\n",
    "#         self.pnl_path = []\n",
    "#         self.diff_path = []\n",
    "\n",
    "#         self._trajectory_data, self._target_pnl, self._max_step = self._sample_trajectory()\n",
    "\n",
    "#     def get_pnl(self, weights: torch.Tensor, spot: torch.Tensor) -> tuple[torch.Tensor, torch.float32]:\n",
    "#         weights_diff = weights - self.weights\n",
    "\n",
    "#         rates_diff = spot[2] - spot[3]\n",
    "\n",
    "#         bought = np.where(weights_diff > 0, weights_diff, 0)\n",
    "#         sold = np.where(weights_diff < 0, weights_diff, 0)\n",
    "\n",
    "#         interest = (rates_diff * -weights) * self.dt\n",
    "\n",
    "#         cash_outflow = (-spot[1] * bought)\n",
    "#         cash_inflow = (-spot[0] * sold)\n",
    "\n",
    "#         return (cash_outflow + cash_inflow + interest)[0]\n",
    "\n",
    "#     def _create_instrument(self, period_df: pd.DataFrame) -> Instrument:\n",
    "#         start = period_df.loc[period_df.index.min()]\n",
    "#         return self.instrument_cls(\n",
    "#             rates_difference=start[\"rub_rate\"] - start[\"usd_rate\"],\n",
    "#             spot_price=start[\"ask\"],\n",
    "#             term=N_DAYS / 365\n",
    "#         )\n",
    "\n",
    "#     @staticmethod\n",
    "#     def _create_df(path: Path) -> pd.DataFrame:\n",
    "#         if \"data.pkl\" in os.listdir(path):\n",
    "#             return pd.read_pickle(PATH / \"data.pkl\")\n",
    "#         else:\n",
    "#             pass\n",
    "\n",
    "#     def _sample_trajectory(self) -> list[torch.Tensor, torch.Tensor, int]:\n",
    "#         if self.random_seed is not None:\n",
    "#             np.random.seed(self.random_seed)\n",
    "\n",
    "#         idx = np.random.choice(np.arange(self._last_point), replace=True)\n",
    "#         start_date = self.data.index[idx]\n",
    "#         end_date = start_date + dt.timedelta(days=self.n_days)\n",
    "\n",
    "#         features = self.data[(self.data.index >= start_date) & (self.data.index <= end_date)]\n",
    "#         time_start = features.iloc[0, -1]\n",
    "#         features[\"time_diff\"] = features[\"time_diff\"].apply(lambda x: x - time_start)\n",
    "#         target = self._create_instrument(features).payoff(spot=features.ask.iloc[-1])\n",
    "\n",
    "#         data = features.to_numpy()\n",
    "#         target_pnl = target\n",
    "#         max_step = features.shape[0] - 2\n",
    "\n",
    "#         return data, target_pnl, max_step\n",
    "\n",
    "#     def _next_obs(self):\n",
    "#         return self._trajectory_data[self.current_step, :]\n",
    "\n",
    "#     def get_average_dt(self):\n",
    "#         return self.data.index.to_series().diff(1).mean() / (np.timedelta64(1, 'D') * self.TRADING_DAYS)\n",
    "\n",
    "#     def step(self, action):\n",
    "#         self.current_step += 1\n",
    "\n",
    "#         reward = 0\n",
    "#         done = 0\n",
    "\n",
    "#         obs = self._next_obs()\n",
    "\n",
    "#         # print(self._pnl, self.get_pnl(weights=action, spot=obs))\n",
    "#         if self.current_step == self._max_step:\n",
    "#             action = np.array([0])\n",
    "#             self._pnl += self.get_pnl(weights=action, spot=obs)\n",
    "#             # print(self._pnl)\n",
    "\n",
    "#             # print(\"________\")\n",
    "\n",
    "#             diff = self._target_pnl - self._pnl\n",
    "#             # print(\"***\")\n",
    "#             # print(diff)\n",
    "#             # print(\"***\")\n",
    "#             reward = -(diff) ** 2\n",
    "\n",
    "#             self.pnl_path.append(self._pnl)\n",
    "#             self.diff_path.append(diff)\n",
    "\n",
    "#             self.current_step = 0\n",
    "#             self._pnl = 0\n",
    "#             self._trajectory_data, self._target_pnl, self._max_step = self._sample_trajectory()\n",
    "\n",
    "#             done = 1\n",
    "#         else:\n",
    "#             self._pnl += self.get_pnl(weights=action, spot=obs)\n",
    "\n",
    "#         self.weights = action\n",
    "\n",
    "#         return obs, reward, done, {}\n",
    "\n",
    "#     def reset(self):\n",
    "#         # Reset the state of the environment to an initial state\n",
    "#         self._initialize()\n",
    "\n",
    "#         return self._next_obs()\n",
    "\n",
    "#     def render(self, mode='human', close=False):\n",
    "#         print(self.pnl_path)\n",
    "#         print(self.diff_path)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "7QmsKyQp1OnZ"
   },
   "source": [
    "from typing import Type, Union\n",
    "\n",
    "import gym\n",
    "from gym import spaces\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "pd.options.mode.chained_assignment = None\n",
    "\n",
    "N_DAYS = 5\n",
    "\n",
    "\n",
    "class DerivativeEnv(gym.Env):\n",
    "    METADATA = {\"render.modes\": [\"human\"]}\n",
    "\n",
    "    BID_COLUMN: str = \"bid\"\n",
    "    ASK_COLUMN: str = \"ask\"\n",
    "    RATE_DOMESTIC_COLUMN: str = \"rub_rate\"\n",
    "    RATE_FOREIGN_COLUMN: str = \"usd_rate\"\n",
    "\n",
    "    TRADING_DAYS: int = 252\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        instrument_cls: Type[Instrument],\n",
    "        n_days: int = N_DAYS,\n",
    "        path: Path = PATH,\n",
    "        data: Union[pd.DataFrame, None] = None,\n",
    "        random_seed: Union[int, None] = None,\n",
    "        device: Union[str, None] = None,\n",
    "    ):\n",
    "        # Internal attributes\n",
    "        self.instrument_cls = instrument_cls\n",
    "        self.n_days = n_days\n",
    "\n",
    "        self.random_seed = random_seed\n",
    "\n",
    "        self.device = self._get_device() if device is None else device\n",
    "\n",
    "        self.data = self._create_df(path) if data is None else data.copy()\n",
    "        self.data.dropna(inplace=True)\n",
    "\n",
    "        self.data[\"time_diff\"] = self.data.index.to_series().diff()\n",
    "        self.data.loc[self.data.index[0], \"time_diff\"] = pd.to_timedelta(\n",
    "            \"0 days 00:00:00\"\n",
    "        )\n",
    "        self.data[\"time_diff\"] = (\n",
    "            self.data[\"time_diff\"].cumsum() / np.timedelta64(1, \"D\") / 365\n",
    "        )\n",
    "\n",
    "        self.dt = self.get_average_dt()\n",
    "\n",
    "        self._last_point = (\n",
    "            self.data.shape[0]\n",
    "            - self.data[\n",
    "                self.data.index\n",
    "                >= self.data.index.max() - dt.timedelta(days=self.n_days)\n",
    "            ].shape[0]\n",
    "        )\n",
    "\n",
    "        # RL attributes\n",
    "        self._initialize()\n",
    "\n",
    "        self.action_space = spaces.Box(\n",
    "            low=-5,\n",
    "            high=5,\n",
    "            shape=(self._trajectory_data.shape[0] - 2,),\n",
    "            dtype=np.float32,\n",
    "        )\n",
    "\n",
    "        self.observation_space = spaces.Box(\n",
    "            low=-np.inf,\n",
    "            high=np.inf,\n",
    "            shape=self._trajectory_data.shape,\n",
    "            dtype=np.float32,\n",
    "        )\n",
    "\n",
    "    def _get_device(self) -> torch.device:\n",
    "        if torch.backends.mps.is_available():\n",
    "            return torch.device(\"mps\")\n",
    "        elif torch.cuda.is_available():\n",
    "            return torch.device(\"cuda\")\n",
    "        else:\n",
    "            return torch.device(\"cpu\")\n",
    "\n",
    "    def _initialize(self):\n",
    "        self._pnl = 0\n",
    "        self.weights = np.array([0])\n",
    "        self.pnl_path = []\n",
    "        self.diff_path = []\n",
    "\n",
    "        (\n",
    "            self._trajectory_data,\n",
    "            self._target_pnl,\n",
    "            self._max_step,\n",
    "        ) = self._sample_trajectory()\n",
    "\n",
    "    def _create_instrument(self, period_df: pd.DataFrame) -> Instrument:\n",
    "        start = period_df.loc[period_df.index.min()]\n",
    "        return self.instrument_cls(\n",
    "            rates_difference=start[\"rub_rate\"] - start[\"usd_rate\"],\n",
    "            spot_price=start[\"ask\"],\n",
    "            term=N_DAYS / 365,\n",
    "        )\n",
    "\n",
    "    @staticmethod\n",
    "    def _create_df(path: Path) -> pd.DataFrame:\n",
    "        if \"data.pkl\" in os.listdir(path):\n",
    "            return pd.read_pickle(PATH / \"data.pkl\")\n",
    "        else:\n",
    "            pass\n",
    "\n",
    "    def _sample_trajectory(self) -> list[torch.Tensor, torch.Tensor, int]:\n",
    "        if self.random_seed is not None:\n",
    "            np.random.seed(self.random_seed)\n",
    "\n",
    "        idx = np.random.choice(np.arange(self._last_point), replace=True)\n",
    "        start_date = self.data.index[idx]\n",
    "        end_date = start_date + dt.timedelta(days=self.n_days)\n",
    "\n",
    "        features = self.data[\n",
    "            (self.data.index >= start_date) & (self.data.index <= end_date)\n",
    "        ]\n",
    "        time_start = features.iloc[0, -1]\n",
    "        features[\"time_diff\"] = features[\"time_diff\"].apply(lambda x: x - time_start)\n",
    "        target = self._create_instrument(features).payoff(spot=features.ask.iloc[-1])\n",
    "\n",
    "        data = features.to_numpy()\n",
    "        target_pnl = target\n",
    "        max_step = features.shape[0] - 2\n",
    "\n",
    "        return data, target_pnl, max_step\n",
    "\n",
    "    def get_average_dt(self):\n",
    "        return self.data.index.to_series().diff(1).mean() / (\n",
    "            np.timedelta64(1, \"D\") * self.TRADING_DAYS\n",
    "        )\n",
    "\n",
    "    def step(self, action):\n",
    "        diff = self._target_pnl - self.get_pnl(\n",
    "            weights=action, spot=self._trajectory_data\n",
    "        )\n",
    "        reward = -((diff) ** 2)\n",
    "\n",
    "        self.pnl_path.append(self._pnl)\n",
    "        self.diff_path.append(diff)\n",
    "\n",
    "        (\n",
    "            self._trajectory_data,\n",
    "            self._target_pnl,\n",
    "            self._max_step,\n",
    "        ) = self._sample_trajectory()\n",
    "\n",
    "        done = 1\n",
    "\n",
    "        return self._trajectory_data, reward, done, {}\n",
    "\n",
    "    def reset(self):\n",
    "        # Reset the state of the environment to an initial state\n",
    "        self._initialize()\n",
    "\n",
    "        return self._trajectory_data\n",
    "\n",
    "    def get_pnl(\n",
    "        self, weights: torch.Tensor, spot: torch.Tensor\n",
    "    ) -> tuple[torch.Tensor, torch.float32]:\n",
    "        weights_all = np.concatenate([np.zeros((1,)), weights, np.zeros((1,))])\n",
    "        weights_diff = np.diff(weights_all, n=1)\n",
    "\n",
    "        rates_diff = spot[:, 2] - spot[:, 3]\n",
    "\n",
    "        bought = np.where(weights_diff > 0, weights_diff, 0)\n",
    "        sold = np.where(weights_diff < 0, weights_diff, 0)\n",
    "\n",
    "        interest = (rates_diff * -weights_all * self.dt).sum()\n",
    "\n",
    "        cash_outflow = (-spot[1:, 1] * bought).sum()\n",
    "        cash_inflow = (-spot[1:, 0] * sold).sum()\n",
    "\n",
    "        return cash_outflow + cash_inflow + interest\n",
    "\n",
    "    def render(self, mode=\"human\", close=False):\n",
    "        print(self.pnl_path)\n",
    "        print(self.diff_path)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "RarV7Ncv3MaO"
   },
   "source": [
    "env = DerivativeEnv(data=data.resample(\"30 min\").ffill(), instrument_cls=Forward)\n",
    "\n",
    "\n",
    "class BaselinePolicyForward(nn.Module):\n",
    "    def __init__(self, dt: float = env.dt):\n",
    "        super().__init__()\n",
    "\n",
    "        self.lstm = nn.LSTM(1, 1, num_layers=1, batch_first=True)\n",
    "        self.dt = dt\n",
    "\n",
    "    def forward(self, spot: torch.Tensor, return_hidden: bool = False) -> torch.Tensor:\n",
    "        return torch.Tensor([1] * (spot.shape[0] - 2)).to(torch.float32).to(DEVICE)\n",
    "\n",
    "\n",
    "baseline = BaselinePolicyForward().to(DEVICE)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "x-eg8uRDbVTl"
   },
   "source": [
    "env = DerivativeEnv(data=data.resample(\"30 min\").ffill(), instrument_cls=Forward)\n",
    "base_diffs = []\n",
    "obs = env.reset()\n",
    "for i in range(100):\n",
    "    done = False\n",
    "    while not done:\n",
    "        obs = torch.Tensor(obs).to(DEVICE)\n",
    "        action = baseline(obs)\n",
    "        obs, reward, done, info = env.step(action.detach().cpu().numpy())\n",
    "        if reward != 0:\n",
    "            base_diffs.append(reward)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lIawhxG0bqN2",
    "outputId": "8f4178de-8a16-4c2e-d1de-a0fc1497cb00"
   },
   "source": [
    "base_diffs"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qdKv52Cu-er0"
   },
   "source": [
    "!pip install sb3-contrib"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Jby1vrAYV-JG",
    "outputId": "6527dce7-9fd1-4d56-8a2d-c07ce429d2d0"
   },
   "source": [
    "from stable_baselines3.common.vec_env import DummyVecEnv\n",
    "\n",
    "# from sb3_contrib import RecurrentPPO\n",
    "# from stable_baselines3 import PPO\n",
    "# from stable_baselines3 import PPO\n",
    "from stable_baselines3 import SAC\n",
    "\n",
    "env = DummyVecEnv(\n",
    "    [\n",
    "        lambda: DerivativeEnv(\n",
    "            data=data.resample(\"30 min\").ffill(), instrument_cls=Forward\n",
    "        )\n",
    "    ]\n",
    ")\n",
    "\n",
    "model = SAC(\"MlpPolicy\", env, verbose=1)\n",
    "model.learn(total_timesteps=1_000_000)\n",
    "\n",
    "vec_env = model.get_env()\n",
    "obs = vec_env.reset()\n",
    "diffs = []\n",
    "for i in range(10_000):\n",
    "    action, _states = model.predict(obs, deterministic=True)\n",
    "    obs, reward, done, info = vec_env.step(action)\n",
    "    if reward != 0:\n",
    "        diffs.append(reward)\n",
    "    # vec_env.render()\n",
    "    # VecEnv resets automatically\n",
    "    # if done:\n",
    "    #   obs = env.reset()\n",
    "\n",
    "env.close()"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4aQw00MgZzqM",
    "outputId": "f6019655-4b0d-4ad4-c2ba-007f1d311388"
   },
   "source": [
    "np.stack(diffs).mean()"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "CIeFQofj-xeI",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "4ca5bd87-5f99-436b-dacc-ba0586ce2207"
   },
   "source": [
    "np.stack(diffs).std()"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "v7OVG3P5qsI5",
    "outputId": "c1650223-84cc-4369-88cb-8e6c47d04a2f"
   },
   "source": [
    "diffs"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IdhCGVr_sXPh",
    "outputId": "cfa6a040-1ffc-48f9-8a42-124116823ffe"
   },
   "source": [
    "action"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NIWqrKn5u9KU"
   },
   "source": [
    "for i in range(10_000):\n",
    "    action, _states = model.predict(obs, deterministic=True)\n",
    "    obs, reward, done, info = vec_env.step(action)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XFaZgQ1lgm_R",
    "outputId": "8720e974-a94e-45b5-a862-95fc0f7746e1"
   },
   "source": [
    "np.array(base_diffs).mean()"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XAs4ewQxY8B0",
    "outputId": "38db8e4d-13af-42a4-a9f0-9cd57be41c34"
   },
   "source": [
    "action"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8Dr1u6uEUXm2"
   },
   "source": [
    "env = DummyVecEnv([lambda: DerivativeEnv(instrument_cls=Forward)])\n",
    "model = SAC(MlpPolicy, env, verbose=1)\n",
    "model.learn(total_timesteps=100)\n",
    "obs = env.reset()\n",
    "for i in range(2000):\n",
    "    action, _states = model.predict(obs)\n",
    "    obs, rewards, done, info = env.step(action)\n",
    "    env.render()"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LAQJ_pvEOnau",
    "outputId": "4136d26a-d254-4295-e7df-17ba46fbd9b9"
   },
   "source": [
    "spot_dataset[0][0][-1][-1] * 365"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PuiJpFh0Onav"
   },
   "source": [
    "class NeuralHedger(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        input_size: int = 5,\n",
    "        num_layers: int = 3,\n",
    "        hidden_size: int = 32,\n",
    "        dt: float = AVERAGE_DT,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.input_size = input_size\n",
    "        self.num_layers = num_layers\n",
    "        self.hidden_size = hidden_size\n",
    "        self.dt = dt\n",
    "\n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size, self.hidden_size, num_layers=num_layers, batch_first=True\n",
    "        )\n",
    "\n",
    "        self.hedging_weights = nn.Sequential(\n",
    "            nn.Linear(self.hidden_size, self.hidden_size),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(self.hidden_size, self.hidden_size),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(self.hidden_size, 1),\n",
    "        )\n",
    "\n",
    "    def forward(\n",
    "        self,\n",
    "        spot: torch.Tensor,\n",
    "        hidden: [(torch.Tensor), None] = None,\n",
    "        return_hidden: bool = False,\n",
    "    ) -> [torch.Tensor, (torch.Tensor, torch.Tensor, torch.Tensor)]:\n",
    "        model_device = spot.device\n",
    "        if hidden is None:\n",
    "            h_t = torch.zeros(\n",
    "                self.num_layers, spot.size(0), self.hidden_size, dtype=torch.float32\n",
    "            ).to(model_device)\n",
    "            c_t = torch.zeros(\n",
    "                self.num_layers, spot.size(0), self.hidden_size, dtype=torch.float32\n",
    "            ).to(model_device)\n",
    "        elif len(hidden) != 2:\n",
    "            raise ValueError(f\"Expected two hidden state variables, got {len(hidden)}\")\n",
    "        else:\n",
    "            h_t, c_t = hidden\n",
    "\n",
    "        h_t, c_t = self.lstm(spot, (h_t, c_t))\n",
    "        outputs = self.hedging_weights(h_t)[:, 1:-1, :].squeeze(2)\n",
    "\n",
    "        if return_hidden:\n",
    "            return outputs, (h_t, c_t)\n",
    "        else:\n",
    "            return outputs\n",
    "\n",
    "    def get_pnl(self, spot: torch.Tensor) -> [torch.Tensor, torch.float32]:\n",
    "        # hedging_weights = nn.Softmax()(self.forward(spot, return_hidden=False), dim=XXX)\n",
    "        hedging_weights = self.forward(spot, return_hidden=False)\n",
    "        return hedging_weights, get_pnl(spot=spot, weights=hedging_weights, dt=self.dt)\n",
    "\n",
    "    def get_metric(\n",
    "        self, spot: torch.Tensor, target: torch.Tensor, lambda_: float = 0.5\n",
    "    ) -> torch.float32:\n",
    "        hedging_weights = self.forward(spot, return_hidden=False)\n",
    "        pnl = get_pnl(spot=spot, weights=hedging_weights, dt=self.dt)\n",
    "        pnl_diff = target - pnl\n",
    "        loss = lambda_ * (pnl_diff**2).mean() + (1 - lambda_) * pnl_diff.std()\n",
    "        return hedging_weights, pnl, loss"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hi-6nEFNOnav",
    "outputId": "974882aa-a34f-481d-e4b6-a44b3fd847be"
   },
   "source": [
    "hedger = NeuralHedger()\n",
    "loader = DataLoader(spot_dataset, batch_size=32, shuffle=True, drop_last=True)\n",
    "\n",
    "for feature, target in loader:\n",
    "    print(feature.shape)\n",
    "    pnl = hedger.get_metric(feature.to(torch.float32), target)\n",
    "    break\n",
    "pnl"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2UZNip4bOnaw"
   },
   "source": [
    "# pnl.shape, target.shape"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VfXJSR-XOnaw"
   },
   "source": [
    "from tqdm import tqdm\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "\n",
    "def train_epoch(\n",
    "    model: nn.Module,\n",
    "    optimizer: torch.optim.Optimizer,\n",
    "    criterion: nn.Module,\n",
    "    loader: DataLoader,\n",
    "    tqdm_desc: str = \"Model\",\n",
    "):\n",
    "    device = next(model.parameters()).device\n",
    "\n",
    "    if tqdm_desc is None:\n",
    "        iterator = loader\n",
    "    else:\n",
    "        iterator = tqdm(loader, desc=tqdm_desc)\n",
    "\n",
    "    train_loss = 0.0\n",
    "    model.train()\n",
    "    scaler = GradScaler()\n",
    "    for features, target_pnl in iterator:\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        features = features.to(device)\n",
    "        target_pnl = target_pnl.to(device)\n",
    "\n",
    "        with torch.autocast(device_type=\"cuda\", dtype=torch.float16):\n",
    "            _, model_pnl, loss = model.get_metric(features, target_pnl)\n",
    "            # loss = criterion(target_pnl, model_pnl)\n",
    "\n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.step(optimizer)\n",
    "\n",
    "        scaler.update()\n",
    "\n",
    "        train_loss += loss.item()\n",
    "\n",
    "    train_loss /= len(loader.dataset)\n",
    "\n",
    "    return train_loss\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def validation_epoch(\n",
    "    model: nn.Module,\n",
    "    criterion: nn.Module,\n",
    "    loader: DataLoader,\n",
    "    tqdm_desc: [str, None] = None,\n",
    "):\n",
    "    device = next(model.parameters()).device\n",
    "\n",
    "    if tqdm_desc is None:\n",
    "        iterator = loader\n",
    "    else:\n",
    "        iterator = tqdm(loader, desc=tqdm_desc)\n",
    "\n",
    "    val_loss = 0.0\n",
    "    preds = []\n",
    "    weight_path = []\n",
    "    pnl_path = []\n",
    "    model.eval()\n",
    "    for features, target_pnl in iterator:\n",
    "        features = features.to(device)\n",
    "        target_pnl = target_pnl.to(device)\n",
    "\n",
    "        weights, model_pnl, loss = model.get_metric(features, target_pnl)\n",
    "\n",
    "        # loss = criterion(target_pnl, model_pnl)\n",
    "        pnl_path.append([target_pnl, model_pnl])\n",
    "        val_loss += loss.item()\n",
    "\n",
    "        # preds.append(pred.detach().cpu().numpy())\n",
    "        weight_path.append(weights.detach().cpu().numpy())\n",
    "\n",
    "    val_loss /= len(loader.dataset)\n",
    "\n",
    "    return val_loss, weights, pnl_path"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Wij0ERxmMoCl"
   },
   "source": [
    "from IPython.display import clear_output\n",
    "\n",
    "\n",
    "def plot_losses(train_losses: list[float], val_losses: list[float]):\n",
    "    clear_output()\n",
    "    fig, axs = plt.subplots(1, 2, figsize=(13, 4))\n",
    "    axs[0].plot(range(1, len(train_losses) + 1), train_losses, label=\"train\")\n",
    "    axs[0].plot(range(1, len(val_losses) + 1), val_losses, label=\"val\")\n",
    "    axs[0].set_ylabel(\"loss\")\n",
    "\n",
    "    # train_perplexities, val_perplexities = torch.exp(torch.tensor(train_losses)), torch.exp(torch.tensor(val_losses))\n",
    "\n",
    "    # axs[1].plot(range(1, len(train_perplexities) + 1), train_perplexities, label='train')\n",
    "    # axs[1].plot(range(1, len(val_perplexities) + 1), val_perplexities, label='val')\n",
    "    # axs[1].set_ylabel('perplexity')\n",
    "\n",
    "    for ax in axs:\n",
    "        ax.set_xlabel(\"epoch\")\n",
    "        ax.legend()\n",
    "\n",
    "    plt.show()"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7kOgOK7kOnaw"
   },
   "source": [
    "from typing import Tuple, List, Optional, Any\n",
    "\n",
    "\n",
    "def train(\n",
    "    model: nn.Module,\n",
    "    optimizer: torch.optim.Optimizer,\n",
    "    scheduler: Optional[Any],\n",
    "    train_loader: DataLoader,\n",
    "    val_loader: DataLoader,\n",
    "    num_epochs: int,\n",
    "    print_logs: bool = True,\n",
    ") -> Tuple[List[float], List[float]]:\n",
    "    train_losses, val_losses = [], []\n",
    "    criterion = nn.MSELoss().to(DEVICE)\n",
    "\n",
    "    for epoch in range(1, num_epochs + 1):\n",
    "        if print_logs:\n",
    "            desc_train = f\"Training {epoch}/{num_epochs}\"\n",
    "            desc_val = f\"Validation {epoch}/{num_epochs}\"\n",
    "        else:\n",
    "            desc_train, desc_val = None, None\n",
    "\n",
    "        train_loss = train_epoch(\n",
    "            model, optimizer, criterion, train_loader, tqdm_desc=desc_train\n",
    "        )\n",
    "        val_loss, weights, pnl_path = validation_epoch(\n",
    "            model, criterion, val_loader, tqdm_desc=desc_val\n",
    "        )\n",
    "\n",
    "        if scheduler is not None:\n",
    "            scheduler.step()\n",
    "\n",
    "        train_losses += [train_loss]\n",
    "        val_losses += [val_loss]\n",
    "        plot_losses(train_losses, val_losses)\n",
    "\n",
    "    return train_losses, val_losses, weights, pnl_path"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XI_ZjOWVMJ05"
   },
   "source": [
    "TEST_SIZE = 0.25"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TdKQ5Ap2JoJa",
    "outputId": "5fd48ad5-2405-4429-9912-c19565f0c8b2"
   },
   "source": [
    "train_data = data.resample(\"30 min\").ffill()\n",
    "time_split = train_data.index[int(train_data.index.shape[0] * (1 - TEST_SIZE))]\n",
    "train_df, test_df = (\n",
    "    train_data[train_data.index <= time_split],\n",
    "    train_data[train_data.index > time_split],\n",
    ")\n",
    "train_df.shape, test_df.shape"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "muNeRxRvTzP5",
    "outputId": "1230bcd7-a4dc-4e14-cd22-c3ffa5fc3b82"
   },
   "source": [
    "train_df.isna().any(), test_df.isna().any()"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 447
    },
    "id": "nRscxjBSOnax",
    "outputId": "41667bd4-c44a-41fe-c8d9-55aed0c3f162"
   },
   "source": [
    "hedger = NeuralHedger().to(DEVICE)\n",
    "\n",
    "# train_set = SpotDataset(data=train_df, instrument_cls=EuropeanCall)\n",
    "# val_set = SpotDataset(data=test_df, instrument_cls=EuropeanCall)\n",
    "\n",
    "train_set = SpotDataset(data=train_df, instrument_cls=Forward)\n",
    "val_set = SpotDataset(data=test_df, instrument_cls=Forward)\n",
    "\n",
    "train_loader = DataLoader(train_set, batch_size=32, shuffle=True, drop_last=False)\n",
    "val_loader = DataLoader(val_set, batch_size=32, shuffle=True, drop_last=False)\n",
    "\n",
    "# optimizer = torch.optim.SGD(hedger.parameters(), lr=0.001, momentum=0.9)\n",
    "optimizer = torch.optim.Adam(hedger.parameters())\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=1)\n",
    "\n",
    "train_losses, val_losses, weights, pnl_path = train(\n",
    "    model=hedger,\n",
    "    optimizer=optimizer,\n",
    "    scheduler=scheduler,\n",
    "    train_loader=train_loader,\n",
    "    val_loader=val_loader,\n",
    "    num_epochs=100,\n",
    "    print_logs=True,\n",
    ")"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3q0ps9fQfkDx"
   },
   "source": [
    "torch.save(hedger, PATH / \"fwd_out_custom.pt\")"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "S0i34ec91c9v"
   },
   "source": [
    "def assess_model(model: nn.Module, baseline: nn.Module) -> None:\n",
    "    _, weights, pnl_path = validation_epoch(model, nn.MSELoss(), val_loader)\n",
    "    _, _, baseline_path = validation_epoch(baseline, nn.MSELoss(), val_loader)\n",
    "    print(weights)\n",
    "    model_targets = torch.cat([x[0] for x in pnl_path])\n",
    "    model_pnls = torch.cat([x[1] for x in pnl_path])\n",
    "\n",
    "    baseline_targets = torch.cat([x[0] for x in baseline_path])\n",
    "    baseline_pnls = torch.cat([x[1] for x in baseline_path])\n",
    "\n",
    "    model_diff = model_targets - model_pnls\n",
    "    baseline_diff = baseline_targets - baseline_pnls\n",
    "    print(model_diff)\n",
    "\n",
    "    print(\n",
    "        f\"Means: model = {model_diff.mean():.6f}, baseline = {baseline_diff.mean():.6f}\"\n",
    "    )\n",
    "\n",
    "    print(f\"Stds: model = {model_diff.std():.6f}, baseline = {baseline_diff.std():.6f}\")\n",
    "\n",
    "    print(\n",
    "        f\"VaRs 5%: model = {torch.abs(torch.quantile(model_diff, 0.05)):.6f}, baseline = {torch.abs(torch.quantile(baseline_diff, 0.05)):.6f}\"\n",
    "    )"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zhzB_lLn3Cnu"
   },
   "source": [
    "assess_model(hedger, baseline)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "E1qfwxJwjryB",
    "outputId": "8140caac-e48e-4b69-de08-8d1bd112763a"
   },
   "source": [
    "val_loss, weights, pnl_path = validation_epoch(hedger, nn.MSELoss(), val_loader)\n",
    "weights"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Dzm34wziOwg2"
   },
   "source": [
    "weights.min(), weights.max()"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mmrH53dUt6-n"
   },
   "source": [
    "target_pnls = torch.cat([x[0] for x in pnl_path])\n",
    "model_pnls = torch.cat([x[1] for x in pnl_path])"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Lsf5c836vQpe"
   },
   "source": [
    "target_pnls.mean() - model_pnls.mean()"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "F2JukFX3JGi0",
    "outputId": "30c297b8-1e53-46a1-848b-12c08e3bf2f0"
   },
   "source": [
    "diff = target_pnls - model_pnls\n",
    "target_pnls[diff.isnan()]"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Dmf63nnom2Cq",
    "outputId": "9e414699-0232-4f69-ff72-dc5859d9c4a5"
   },
   "source": [
    "(target_pnls - model_pnls).mean()"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QJQzmCUsnKDe",
    "outputId": "ca940628-269c-473f-aa2d-63de16c2842d"
   },
   "source": [
    "(target_pnls - model_pnls).std()"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ST7WSUPovTo_",
    "outputId": "89cfc3ba-4a35-4a56-cbcb-2d6a62910bb0"
   },
   "source": [
    "target_pnls.std(), model_pnls.std()"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uItR3RPjvalc",
    "outputId": "c789c297-2a02-485e-fed0-0a0daafe43d7"
   },
   "source": [
    "target_pnls.mean() * target_pnls.std(), model_pnls.mean() * model_pnls.std()"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fVoo40hewbE5",
    "outputId": "714cd7f9-327a-4465-acec-e5b7c18365f9"
   },
   "source": [
    "target_pnls.shape"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8P2vBeDOwNxV",
    "outputId": "9700e769-622a-482e-e74a-edb38c052402"
   },
   "source": [
    "t_value = (target_pnls.mean() - model_pnls.mean()) / torch.sqrt(\n",
    "    target_pnls.std() ** 2 / target_pnls.shape[0]\n",
    "    + model_pnls.std() ** 2 / model_pnls.shape[0]\n",
    ")\n",
    "t_value"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 430
    },
    "id": "_KGWciRgvonX",
    "outputId": "27907574-c3d8-4f48-dda9-f7d36f3b1086"
   },
   "source": [
    "from matplotlib import pyplot\n",
    "\n",
    "bins = np.linspace(-10, 10, 100)\n",
    "\n",
    "pyplot.hist(target_pnls.cpu().numpy(), bins, alpha=0.5, label=\"x\")\n",
    "pyplot.hist(model_pnls.cpu().numpy(), bins, alpha=0.5, label=\"y\")\n",
    "pyplot.legend(loc=\"upper right\")\n",
    "pyplot.show()"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AOHD6BnMsetN",
    "outputId": "368ff8d2-2e77-4319-8c98-5f7b830d0b16"
   },
   "source": [
    "val_loss"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6VRj_WfVwxVi",
    "outputId": "105716d7-b5e8-49ff-93c5-33857ac364b7"
   },
   "source": [
    "for x, y in loader:\n",
    "    print(x.shape)\n",
    "    print(hedger(x.to(DEVICE)).shape)\n",
    "    break"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "eJ1dGM3fxR3h",
    "outputId": "95b4569b-8a1e-4b2c-9887-a96b7c0e6801"
   },
   "source": [
    "baseline = BaselineForward().to(DEVICE)\n",
    "for x, y in loader:\n",
    "    print(x.shape)\n",
    "    print(baseline(x.to(DEVICE)).shape)\n",
    "    break"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QeWDs3tGxZ1t"
   },
   "source": [
    "baseline = BaselineForward().to(DEVICE)\n",
    "val_loss, weights, pnl_path = validation_epoch(baseline, nn.MSELoss(), val_loader)\n",
    "weights"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jHLsWdumzEbO",
    "outputId": "eaff400b-538c-4899-ce46-1fdc8032218a"
   },
   "source": [
    "baseline_loader = DataLoader(val_set, batch_size=1, shuffle=True, drop_last=False)\n",
    "for features, t_pnl in baseline_loader:\n",
    "    break\n",
    "features"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ekQx9-51zsal",
    "outputId": "79fe8482-cbae-4dc0-bff9-480f24eaf581"
   },
   "source": [
    "features.shape"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VpFOi4nazuLC",
    "outputId": "a10d1319-0aab-458e-df91-43859b6340a6"
   },
   "source": [
    "t_pnl"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gFYm46hkz7Ae",
    "outputId": "b5bef6ed-c4ce-42be-a8a4-923f62c4c6fd"
   },
   "source": [
    "features[:, -1, :]"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Jy9QDOkP0DQu",
    "outputId": "7fb82f18-5f76-4bb9-c32a-62c333f01e3c"
   },
   "source": [
    "features[:, 0, :]"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zZ7SOCJOzkQU",
    "outputId": "2ac5b67f-1e95-4253-b659-298e7544b5ac"
   },
   "source": [
    "hedger.get_pnl(features.to(DEVICE))"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KoqSg2tozNXF"
   },
   "source": [],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gHqrPVAIxcwS",
    "outputId": "c89cd00b-e3fa-4fac-f496-a26382d5a9d6"
   },
   "source": [
    "baseline_pnls = torch.cat([x[1] for x in pnl_path])\n",
    "target_pnls = torch.cat([x[0] for x in pnl_path])\n",
    "baseline_pnls"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1TMu-BI9ztJZ",
    "outputId": "68d89e3a-f2c1-4c99-e0ea-e838967dbdb3"
   },
   "source": [
    "(target_pnls - baseline_pnls).mean(), (target_pnls - model_pnls).mean()"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pcapXTi8ym_V",
    "outputId": "9035be1b-a09f-4ed1-d7df-d466f8b8cb55"
   },
   "source": [
    "(target_pnls - baseline_pnls).std(), (target_pnls - model_pnls).std()"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BBiZ5N-xyvYj",
    "outputId": "8a31e267-1058-4636-99d0-a9f601d68964"
   },
   "source": [
    "torch.quantile(target_pnls - baseline_pnls, 0.05), torch.quantile(\n",
    "    target_pnls - model_pnls, 0.05\n",
    ")"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FGFRcBrOKR7D",
    "outputId": "35fd7f37-2af4-4435-e6f5-87da852d29a3"
   },
   "source": [
    "(baseline_pnls - model_pnls).std()"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4dsaMo5Pz7xD",
    "outputId": "a71248b0-a592-4b0e-d5f3-c7194914e5e7"
   },
   "source": [
    "baseline_pnls.std(), model_pnls.std()"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ylpJlHpA6JWo",
    "outputId": "29eb4e06-0ab4-46c9-b446-cc39d6a3462c"
   },
   "source": [
    "torch.cat([baseline_pnls, target_pnls], dim=1)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vXk75eRSz7AR",
    "outputId": "a0457ee5-3e6f-4f76-e1e8-830d529ac986"
   },
   "source": [
    "t_value = (baseline_pnls.mean() - model_pnls.mean()) / torch.sqrt(\n",
    "    baseline_pnls.std() ** 2 / baseline_pnls.shape[0]\n",
    "    + model_pnls.std() ** 2 / model_pnls.shape[0]\n",
    ")\n",
    "t_value"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "h05ZeQ4D7O_2"
   },
   "source": [
    "## Option."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jtrsaV7s7Sl0"
   },
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "class EuropeanCall(Instrument):\n",
    "    def __init__(self, rates_difference: float, spot_price: float, term: float):\n",
    "        super().__init__()\n",
    "        self.rates_difference = rates_difference\n",
    "        self.spot_price = spot_price\n",
    "        self.term = term\n",
    "\n",
    "    def coupon(self, frequency: float = 0.0, *args, **kwargs) -> float:\n",
    "        return 0\n",
    "\n",
    "    def pv_coupons(self) -> float:\n",
    "        return 0\n",
    "\n",
    "    def get_strike(self, spot_price: [float, None] = None) -> float:\n",
    "        return self.spot_price\n",
    "\n",
    "    @property\n",
    "    def strike(self) -> float:\n",
    "        return self.get_strike()\n",
    "\n",
    "    def price(self, spot_start: [float, list[float], None] = None) -> float:\n",
    "        return 0\n",
    "\n",
    "    def payoff(self, spot: [float, np.array]) -> float:\n",
    "        return max(spot - self.strike, 0)\n",
    "\n",
    "    def __repr__(self):\n",
    "        return f\"EuropeanCall(strike={self.strike}, term={self.term}, spot_ref={self.spot_price})\""
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6gpXp84S7Y2T"
   },
   "source": [],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LCwKB-3nKm1-"
   },
   "source": [
    "## Задание 1\n",
    "\n",
    "5 баллов\n",
    "Добейтесь accuracy на валидации не менее 0.44. В этом задании запрещено пользоваться предобученными моделями и ресайзом картинок.\n",
    "\n",
    "Советы:\n",
    "1. Аугментации.\n",
    "2. Оптимайзеры.\n",
    "4. Регуляризация"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "M_xi2lnZiZln",
    "outputId": "100c28b3-46f1-45da-8a2d-6869cb16738e"
   },
   "source": [
    "train_dataloader, test_dataloader = get_dataloaders(\n",
    "    config=ExperimentConfig(), augmentation_hyperparams=AugmentationHyperparams()\n",
    ")"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pWR2l6ymZfRJ"
   },
   "source": [
    "### Модель"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mDYorQXLZhTQ"
   },
   "source": [
    "class YourNet(torch.nn.Module):\n",
    "    def __init__(self, n_classes, kernel_size=3, stride=1, padding=1, dilation=1):\n",
    "        super().__init__()\n",
    "        self.accuracy_list = []\n",
    "\n",
    "        self.pretrained = False\n",
    "\n",
    "        # YOUR CODE HERE\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Conv2d(\n",
    "                in_channels=3,\n",
    "                out_channels=16,\n",
    "                kernel_size=kernel_size,\n",
    "                stride=stride,\n",
    "                padding=padding,\n",
    "                dilation=dilation,\n",
    "            ),\n",
    "            nn.MaxPool2d(kernel_size=2),\n",
    "            nn.Conv2d(\n",
    "                in_channels=16,\n",
    "                out_channels=32,\n",
    "                kernel_size=kernel_size,\n",
    "                stride=stride,\n",
    "                padding=padding,\n",
    "                dilation=dilation,\n",
    "            ),\n",
    "            nn.MaxPool2d(kernel_size=2),\n",
    "            nn.Conv2d(\n",
    "                in_channels=32,\n",
    "                out_channels=64,\n",
    "                kernel_size=kernel_size,\n",
    "                stride=stride,\n",
    "                padding=padding,\n",
    "                dilation=dilation,\n",
    "            ),\n",
    "            nn.MaxPool2d(kernel_size=2),\n",
    "            nn.Conv2d(\n",
    "                in_channels=64,\n",
    "                out_channels=128,\n",
    "                kernel_size=kernel_size,\n",
    "                stride=stride,\n",
    "                padding=padding,\n",
    "                dilation=dilation,\n",
    "            ),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "\n",
    "        self.classifier = nn.Linear(in_features=128, out_features=n_classes)\n",
    "\n",
    "    def _forward(self, x):\n",
    "        # runs the Neural Network\n",
    "        # YOUR CODE HERE\n",
    "        feature_map = self.net(x)\n",
    "        feature_vector = feature_map.mean(dim=(2, 3))\n",
    "        logits = self.classifier(feature_vector)\n",
    "\n",
    "        return logits\n",
    "\n",
    "    def forward(self, images, target=None):\n",
    "        # images ~ (batch size, num channels, height, width)\n",
    "        # target ~ (batch size)\n",
    "        # output ~ (batch size, num classes)\n",
    "        output = self._forward(images)\n",
    "\n",
    "        # get binary mask and save it to self.accuracy_list\n",
    "        if target is not None:\n",
    "            pred = torch.argmax(output, dim=-1)\n",
    "            self.accuracy_list.extend((target == pred).tolist())\n",
    "\n",
    "        return output\n",
    "\n",
    "    def get_accuracy(self, reset=False):\n",
    "        # return accuracy by all values in the dataset\n",
    "        if reset:\n",
    "            self.accuracy_list = []\n",
    "            return None\n",
    "        else:\n",
    "            return torch.mean(torch.Tensor(self.accuracy_list))"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ykBQxS-a4qfI"
   },
   "source": [
    "### Тренировочный цикл"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "St95RrzQNh9D"
   },
   "source": [
    "from IPython.display import clear_output\n",
    "\n",
    "\n",
    "def plot_losses(\n",
    "    train_losses: List[float],\n",
    "    val_losses: List[float],\n",
    "    train_accs: List[float],\n",
    "    val_accs: List[float],\n",
    "):\n",
    "    \"\"\"\n",
    "    Plot loss and perplexity of train and validation samples\n",
    "    :param train_losses: list of train losses at each epoch\n",
    "    :param val_losses: list of validation losses at each epoch\n",
    "    \"\"\"\n",
    "    clear_output()\n",
    "    fig, axs = plt.subplots(1, 2, figsize=(13, 4))\n",
    "    axs[0].plot(range(1, len(train_losses) + 1), train_losses, label=\"train\")\n",
    "    axs[0].plot(range(1, len(val_losses) + 1), val_losses, label=\"val\")\n",
    "    axs[0].set_ylabel(\"loss\")\n",
    "    axs[0].set_title(\"Loss Dynamics\")\n",
    "\n",
    "    axs[1].plot(range(1, len(train_accs) + 1), train_accs, label=\"train\")\n",
    "    axs[1].plot(range(1, len(val_accs) + 1), val_accs, label=\"val\")\n",
    "    axs[1].set_ylabel(\"accuracy\")\n",
    "    axs[1].set_title(\"Accuracy Dynamics\")\n",
    "\n",
    "    for ax in axs:\n",
    "        ax.set_xlabel(\"epoch\")\n",
    "        ax.legend()\n",
    "\n",
    "    plt.show()"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_8g55Knw4qfJ"
   },
   "source": [
    "def train_one_epoch(\n",
    "    model, train_dataloader, criterion, optimizer, tqdm_desc: str = \"Training\"\n",
    "):\n",
    "    # YOUR CODE\n",
    "    # Train your model here\n",
    "    device = next(model.parameters()).device\n",
    "\n",
    "    if tqdm_desc is None:\n",
    "        iterator = train_dataloader\n",
    "    else:\n",
    "        iterator = tqdm(train_dataloader, desc=tqdm_desc)\n",
    "\n",
    "    running_loss, running_acc = 0.0, 0.0\n",
    "    model.train()\n",
    "    model.get_accuracy(reset=True)\n",
    "    scaler = GradScaler()\n",
    "    for features, labels in iterator:\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        features = features.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        with torch.autocast(device_type=\"cuda\", dtype=torch.float16):\n",
    "            logits = model(features, labels)\n",
    "            loss = criterion(logits, labels)\n",
    "\n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.step(optimizer)\n",
    "\n",
    "        scaler.update()\n",
    "\n",
    "        running_loss += loss.item() * features.shape[0]\n",
    "\n",
    "    return running_loss / len(train_dataloader.dataset), model.get_accuracy().item()\n",
    "\n",
    "\n",
    "def predict(model, test_dataloder, criterion, tqdm_desc: str = \"Training\"):\n",
    "    # YOUR CODE\n",
    "    # Validate your model here\n",
    "    device = next(model.parameters()).device\n",
    "\n",
    "    if tqdm_desc is None:\n",
    "        iterator = test_dataloader\n",
    "    else:\n",
    "        iterator = tqdm(test_dataloader, desc=tqdm_desc)\n",
    "\n",
    "    running_loss, running_acc = 0.0, 0.0\n",
    "    model.eval()\n",
    "    model.get_accuracy(reset=True)\n",
    "    for features, labels in iterator:\n",
    "        features = features.to(device)\n",
    "        labels = labels.to(device)\n",
    "        logits = model(features, labels)\n",
    "\n",
    "        loss = criterion(logits, labels)\n",
    "\n",
    "        running_loss += loss.item() * features.shape[0]\n",
    "\n",
    "    return running_loss / len(test_dataloader.dataset), model.get_accuracy().item()\n",
    "\n",
    "\n",
    "def train(\n",
    "    model,\n",
    "    train_dataloader,\n",
    "    test_dataloader,\n",
    "    criterion,\n",
    "    optimizer,\n",
    "    device=\"cuda:0\",\n",
    "    n_epochs=10,\n",
    "    scheduler=None,\n",
    "    ckpt_path: Path = ExperimentConfig.CKPT_ROOT,\n",
    "):\n",
    "    model.to(device)\n",
    "    train_losses, val_losses = [], []\n",
    "    train_accs, val_accs = [], []\n",
    "    for epoch in range(1, n_epochs + 1):\n",
    "        # YOUR CODE\n",
    "        # Train, evaluate, print accuracy, make a step of scheduler or whatever you want...\n",
    "        train_loss, train_acc = train_one_epoch(\n",
    "            model=model,\n",
    "            train_dataloader=train_dataloader,\n",
    "            criterion=criterion,\n",
    "            optimizer=optimizer,\n",
    "            tqdm_desc=f\"Training {epoch}/{n_epochs}\",\n",
    "        )\n",
    "        val_loss, val_acc = predict(\n",
    "            model=model,\n",
    "            test_dataloder=test_dataloader,\n",
    "            criterion=criterion,\n",
    "            tqdm_desc=f\"Validating {epoch}/{n_epochs}\",\n",
    "        )\n",
    "\n",
    "        if scheduler is not None:\n",
    "            scheduler.step()\n",
    "\n",
    "        train_losses += [train_loss]\n",
    "        val_losses += [val_loss]\n",
    "        train_accs += [train_acc]\n",
    "        val_accs += [val_acc]\n",
    "        plot_losses(train_losses, val_losses, train_accs, val_accs)\n",
    "\n",
    "        if model.pretrained:\n",
    "            ckpt_name = f\"{model.__class__.__name__}_pretrained_exp.pt\"\n",
    "        else:\n",
    "            ckpt_name = f\"{model.__class__.__name__}_exp.pt\"\n",
    "        torch.save(model.state_dict(), ckpt_path / ckpt_name)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "soPKRKS54qfJ"
   },
   "source": [
    "%%time\n",
    "model = YourNet(n_classes=ExperimentConfig.N_CLASSES)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=ExperimentConfig.LR)\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(\n",
    "    optimizer, T_max=ExperimentConfig.N_EPOCHS\n",
    ")\n",
    "\n",
    "train(\n",
    "    model=model,\n",
    "    train_dataloader=train_dataloader,\n",
    "    test_dataloader=test_dataloader,\n",
    "    criterion=criterion,\n",
    "    optimizer=optimizer,\n",
    "    device=ExperimentConfig.DEVICE,\n",
    "    n_epochs=ExperimentConfig.N_EPOCHS,\n",
    "    scheduler=scheduler,\n",
    ")"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zPF6QTDV4fEP"
   },
   "source": [
    "class YourResNet18(torch.nn.Module):\n",
    "    def __init__(self, n_classes, is_pretrained: bool = ExperimentConfig.IS_PRETRAINED):\n",
    "        super().__init__()\n",
    "        self.accuracy_list = []\n",
    "\n",
    "        self.pretrained = is_pretrained\n",
    "\n",
    "        # YOUR CODE HERE\n",
    "        self.model = torchvision.models.resnet18(\n",
    "            pretrained=is_pretrained, num_classes=n_classes\n",
    "        )\n",
    "\n",
    "    def _forward(self, x):\n",
    "        # runs the Neural Network\n",
    "        # YOUR CODE HERE\n",
    "        logits = self.model(x)\n",
    "\n",
    "        return logits\n",
    "\n",
    "    def forward(self, images, target=None):\n",
    "        # images ~ (batch size, num channels, height, width)\n",
    "        # target ~ (batch size)\n",
    "        # output ~ (batch size, num classes)\n",
    "        output = self._forward(images)\n",
    "\n",
    "        # get binary mask and save it to self.accuracy_list\n",
    "        if target is not None:\n",
    "            pred = torch.argmax(output, dim=-1)\n",
    "            self.accuracy_list.extend((target == pred).tolist())\n",
    "\n",
    "        return output\n",
    "\n",
    "    def get_accuracy(self, reset=False):\n",
    "        # return accuracy by all values in the dataset\n",
    "        if reset:\n",
    "            self.accuracy_list = []\n",
    "            return None\n",
    "        else:\n",
    "            return torch.mean(torch.Tensor(self.accuracy_list))"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oPDK4qBE4zsW"
   },
   "source": [
    "%%time\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class AugmentationHyperparams:\n",
    "    RESIZE_HEIGHT: Union[int, None] = None\n",
    "    RESIZE_WIDTH: Union[int, None] = None\n",
    "    RANDOM_CROP_SIZE: Union[int, None] = None\n",
    "    RANDOM_CROP_PADDING: Union[int, None] = None\n",
    "    FLIP_PROB: Union[float, None] = 0.25\n",
    "    ROTATION_DEG: Union[float, None] = None\n",
    "    JITTER_PARAM: Union[float, None] = None\n",
    "    BRIGHTNESS: Union[float, None] = None\n",
    "    CONTRAST: Union[float, None] = None\n",
    "    SATURATION: Union[float, None] = None\n",
    "    HUE: Union[float, None] = None\n",
    "\n",
    "\n",
    "train_dataloader, test_dataloader = get_dataloaders(\n",
    "    config=ExperimentConfig(), augmentation_hyperparams=AugmentationHyperparams()\n",
    ")\n",
    "\n",
    "model = YourResNet18(n_classes=ExperimentConfig.N_CLASSES)\n",
    "# optimizer = torch.optim.Adam(model.parameters(), lr=ExperimentConfig.LR)\n",
    "optimizer = torch.optim.SGD(\n",
    "    model.parameters(), lr=ExperimentConfig.LR, momentum=0.9, weight_decay=0.01\n",
    ")\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(\n",
    "    optimizer, T_max=ExperimentConfig.N_EPOCHS\n",
    ")\n",
    "\n",
    "train(\n",
    "    model=model,\n",
    "    train_dataloader=train_dataloader,\n",
    "    test_dataloader=test_dataloader,\n",
    "    criterion=criterion,\n",
    "    optimizer=optimizer,\n",
    "    device=ExperimentConfig.DEVICE,\n",
    "    n_epochs=ExperimentConfig.N_EPOCHS,\n",
    "    scheduler=scheduler,\n",
    ")"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "8sQfBOaEWf15"
   },
   "source": [
    "%%time\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class AugmentationHyperparams:\n",
    "    RESIZE_HEIGHT: Union[int, None] = None\n",
    "    RESIZE_WIDTH: Union[int, None] = None\n",
    "    RANDOM_CROP_SIZE: Union[int, None] = None\n",
    "    RANDOM_CROP_PADDING: Union[int, None] = None\n",
    "    FLIP_PROB: Union[float, None] = 0.25\n",
    "    ROTATION_DEG: Union[float, None] = None\n",
    "    JITTER_PARAM: Union[float, None] = None\n",
    "    BRIGHTNESS: Union[float, None] = None\n",
    "    CONTRAST: Union[float, None] = None\n",
    "    SATURATION: Union[float, None] = None\n",
    "    HUE: Union[float, None] = None\n",
    "\n",
    "\n",
    "# #@dataclass\n",
    "# class AugmentationHyperparams:\n",
    "#     RESIZE_HEIGHT: Union[int, None] = None\n",
    "#     RESIZE_WIDTH: Union[int, None] = None\n",
    "#     RANDOM_CROP_SIZE: int = 32\n",
    "#     RANDOM_CROP_PADDING: int = 4\n",
    "#     FLIP_PROB: float = 0.5\n",
    "#     ROTATION_DEG: float = 15\n",
    "#     JITTER_PARAM: float = 0.25\n",
    "#     BRIGHTNESS: float = 0.2\n",
    "#     CONTRAST: float = 0.15\n",
    "#     SATURATION: float = 0.15\n",
    "#     HUE: float = 0.15\n",
    "\n",
    "train_dataloader, test_dataloader = get_dataloaders(\n",
    "    config=ExperimentConfig(), augmentation_hyperparams=AugmentationHyperparams()\n",
    ")\n",
    "\n",
    "model = YourNet(n_classes=ExperimentConfig.N_CLASSES)\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=ExperimentConfig.LR)\n",
    "# optimizer = torch.optim.Adam(model.parameters(), lr=ExperimentConfig.LR)\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(\n",
    "    optimizer, T_max=ExperimentConfig.N_EPOCHS\n",
    ")\n",
    "\n",
    "train(\n",
    "    model=model,\n",
    "    train_dataloader=train_dataloader,\n",
    "    test_dataloader=test_dataloader,\n",
    "    criterion=criterion,\n",
    "    optimizer=optimizer,\n",
    "    device=ExperimentConfig.DEVICE,\n",
    "    n_epochs=ExperimentConfig.N_EPOCHS,\n",
    "    scheduler=scheduler,\n",
    ")"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "erami24qKpYK"
   },
   "source": [
    "class YourMobileNet(torch.nn.Module):\n",
    "    def __init__(self, n_classes, is_pretrained: bool = ExperimentConfig.IS_PRETRAINED):\n",
    "        super().__init__()\n",
    "        self.accuracy_list = []\n",
    "\n",
    "        self.pretrained = is_pretrained\n",
    "\n",
    "        # YOUR CODE HERE\n",
    "        self.model = torchvision.models.mobilenet_v3_large(\n",
    "            pretrained=is_pretrained, num_classes=n_classes\n",
    "        )\n",
    "\n",
    "    def _forward(self, x):\n",
    "        # runs the Neural Network\n",
    "        # YOUR CODE HERE\n",
    "        logits = self.model(x)\n",
    "\n",
    "        return logits\n",
    "\n",
    "    def forward(self, images, target=None):\n",
    "        # images ~ (batch size, num channels, height, width)\n",
    "        # target ~ (batch size)\n",
    "        # output ~ (batch size, num classes)\n",
    "        output = self._forward(images)\n",
    "\n",
    "        # get binary mask and save it to self.accuracy_list\n",
    "        if target is not None:\n",
    "            pred = torch.argmax(output, dim=-1)\n",
    "            self.accuracy_list.extend((target == pred).tolist())\n",
    "\n",
    "        return output\n",
    "\n",
    "    def get_accuracy(self, reset=False):\n",
    "        # return accuracy by all values in the dataset\n",
    "        if reset:\n",
    "            self.accuracy_list = []\n",
    "            return None\n",
    "        else:\n",
    "            return torch.mean(torch.Tensor(self.accuracy_list))"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mPqtOKcfLGod"
   },
   "source": [
    "%%time\n",
    "model = YourMobileNet(n_classes=ExperimentConfig.N_CLASSES)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=ExperimentConfig.LR)\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(\n",
    "    optimizer, T_max=ExperimentConfig.N_EPOCHS\n",
    ")\n",
    "\n",
    "train(\n",
    "    model=model,\n",
    "    train_dataloader=train_dataloader,\n",
    "    test_dataloader=test_dataloader,\n",
    "    criterion=criterion,\n",
    "    optimizer=optimizer,\n",
    "    device=ExperimentConfig.DEVICE,\n",
    "    n_epochs=ExperimentConfig.N_EPOCHS,\n",
    "    scheduler=scheduler,\n",
    ")"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lnjt94HAeJ0Y"
   },
   "source": [
    "from enum import Enum\n",
    "\n",
    "\n",
    "class PretrainMode(Enum):\n",
    "    NOT_PRETRAINED = \"NOT_PRETRAINED\"\n",
    "    LINEAR_PROBING = \"LINEAR_PROBING\"\n",
    "    FINE_TUNING = \"FINE_TUNING\""
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9uHVD6Iv6Tip"
   },
   "source": [
    "class YourModel(torch.nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        n_classes: int,\n",
    "        arhcitecture: nn.Module,\n",
    "        pretrain_mode: PretrainMode = PretrainMode.LINEAR_PROBING,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.accuracy_list = []\n",
    "\n",
    "        # YOUR CODE HERE\n",
    "        if pretrain_mode.NOT_PRETRAINED:\n",
    "            self.pretrained = False\n",
    "        else:\n",
    "            self.pretrained = True\n",
    "\n",
    "        if not pretrain_mode.NOT_PRETRAINED:\n",
    "            self.model = torchvision.models.resnet50(pretrained=True)\n",
    "\n",
    "            # Freezing weights\n",
    "            if pretrain_mode.LINEAR_PROBING:\n",
    "                for param in self.model.parameters():\n",
    "                    param.requires_grad = False\n",
    "\n",
    "            in_features = self.model.fc.in_features\n",
    "            self.model.fc = nn.Linear(in_features=in_features, out_features=n_classes)\n",
    "        else:\n",
    "            self.model = torchvision.models.resnet50(\n",
    "                pretrained=False, num_classes=n_classes\n",
    "            )\n",
    "\n",
    "    def _forward(self, x):\n",
    "        # runs the Neural Network\n",
    "        # YOUR CODE HERE\n",
    "        logits = self.model(x)\n",
    "\n",
    "        return logits\n",
    "\n",
    "    def forward(self, images, target=None):\n",
    "        # images ~ (batch size, num channels, height, width)\n",
    "        # target ~ (batch size)\n",
    "        # output ~ (batch size, num classes)\n",
    "        output = self._forward(images)\n",
    "\n",
    "        # get binary mask and save it to self.accuracy_list\n",
    "        if target is not None:\n",
    "            pred = torch.argmax(output, dim=-1)\n",
    "            self.accuracy_list.extend((target == pred).tolist())\n",
    "\n",
    "        return output\n",
    "\n",
    "    def get_accuracy(self, reset=False):\n",
    "        # return accuracy by all values in the dataset\n",
    "        if reset:\n",
    "            self.accuracy_list = []\n",
    "            return None\n",
    "        else:\n",
    "            return torch.mean(torch.Tensor(self.accuracy_list))"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ScLK6jhqqIj9"
   },
   "source": [
    "class Experiment:\n",
    "    def __init__(\n",
    "        self,\n",
    "        experiment_config: ExperimentConfig,\n",
    "        augmentation_hyperparams: AugmentationHyperparams,\n",
    "    ):\n",
    "        self.experiment_config = experiment_config\n",
    "        self.augmentation_hyperparams = augmentation_hyperparams\n",
    "\n",
    "    def run(self, model: nn.Module) -> nn.Module:\n",
    "        train_dataloader, test_dataloader = get_dataloaders(\n",
    "            config=self.experiment_config,\n",
    "            augmentation_hyperparams=self.augmentation_hyperparams,\n",
    "        )\n",
    "\n",
    "        if (\n",
    "            self.experiment_config.MOMENTUM is not None\n",
    "            and self.experiment_config.WEIGHT_DECAY is not None\n",
    "        ):\n",
    "            optimizer = torch.optim.SGD(\n",
    "                model.parameters(),\n",
    "                lr=self.experiment_config.LR,\n",
    "                momentum=self.experiment_config.MOMENTUM,\n",
    "                weight_decay=self.experiment_config.WEIGHT_DECAY,\n",
    "            )\n",
    "        else:\n",
    "            optimizer = torch.optim.Adam(\n",
    "                model.parameters(), lr=self.experiment_config.LR\n",
    "            )\n",
    "\n",
    "        if self.experiment_config.LABEL_SMOOTHING is not None:\n",
    "            criterion = torch.nn.CrossEntropyLoss(\n",
    "                label_smoothing=self.experiment_config.LABEL_SMOOTHING\n",
    "            )\n",
    "        else:\n",
    "            criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "        eta_min = (\n",
    "            self.experiment_config.ETA_MIN\n",
    "            if self.experiment_config.ETA_MIN is not None\n",
    "            else 0.0\n",
    "        )\n",
    "        scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(\n",
    "            optimizer, T_max=self.experiment_config.N_EPOCHS, eta_min=eta_min\n",
    "        )\n",
    "\n",
    "        train(\n",
    "            model=model,\n",
    "            train_dataloader=train_dataloader,\n",
    "            test_dataloader=test_dataloader,\n",
    "            criterion=criterion,\n",
    "            optimizer=optimizer,\n",
    "            device=ExperimentConfig.DEVICE,\n",
    "            n_epochs=ExperimentConfig.N_EPOCHS,\n",
    "            scheduler=scheduler,\n",
    "        )\n",
    "\n",
    "        return model"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WAWcjLY36ZEE"
   },
   "source": [
    "%%time\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class ExperimentConfig:\n",
    "    TRAIN_ROOT: str = ROOT_PATH / ROOT_PATH / \"train\"\n",
    "    VAL_ROOT: str = ROOT_PATH / ROOT_PATH / \"val\"\n",
    "    CKPT_ROOT: str = GDRIVE_ROOT_PATH\n",
    "\n",
    "    # MEAN: Union[Tuple[float], None] = (0.485, 0.456, 0.406)\n",
    "    # STD: Union[Tuple[float], None] = (0.229, 0.224, 0.225)\n",
    "\n",
    "    MEAN: Union[Tuple[float], None] = None\n",
    "    STD: Union[Tuple[float], None] = None\n",
    "\n",
    "    N_EPOCHS: int = 100\n",
    "    # LR: float = 1e-2\n",
    "    LR: float = 0.5\n",
    "    BATCH_SIZE: int = 32\n",
    "\n",
    "    N_CLASSES = len(os.listdir(ROOT_PATH / ROOT_PATH / \"train\"))\n",
    "\n",
    "    NUM_WORKERS: int = 2\n",
    "\n",
    "    MOMENTUM: Union[float, None] = 0.9\n",
    "    WEIGHT_DECAY: Union[float, None] = 2e-05\n",
    "    ETA_MIN: Union[float, None] = 0.00001\n",
    "    LABEL_SMOOTHING: Union[float, None] = 0.1\n",
    "\n",
    "    if torch.backends.mps.is_available():\n",
    "        DEVICE = torch.device(\"mps\")\n",
    "    elif torch.cuda.is_available():\n",
    "        DEVICE = torch.device(\"cuda\")\n",
    "    else:\n",
    "        DEVICE = torch.device(\"cpu\")\n",
    "\n",
    "    IS_PRETRAINED: bool = False\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class AugmentationHyperparams:\n",
    "    RESIZE_HEIGHT: Union[int, None] = None\n",
    "    RESIZE_WIDTH: Union[int, None] = None\n",
    "    RANDOM_CROP_SIZE: int = None\n",
    "    RANDOM_CROP_PADDING: int = None\n",
    "    FLIP_PROB: float = None\n",
    "    ROTATION_DEG: float = None\n",
    "    JITTER_PARAM: float = None\n",
    "    BRIGHTNESS: float = None\n",
    "    CONTRAST: float = None\n",
    "    SATURATION: float = None\n",
    "    HUE: float = None\n",
    "\n",
    "\n",
    "model = YourModel(n_classes=ExperimentConfig.N_CLASSES)\n",
    "experiment = Experiment(\n",
    "    experiment_config=ExperimentConfig(),\n",
    "    augmentation_hyperparams=AugmentationHyperparams(),\n",
    ")\n",
    "final_model = experiment.run(model)"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3eoTAB1fSOuk"
   },
   "source": [
    "### Валидация результатов задания"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4M_BAiMNl1rL"
   },
   "source": [
    "def evaluate_task(model, test_dataloader, device=\"cuda:0\"):\n",
    "    model = model.to(device)\n",
    "    model.eval()\n",
    "    accuracy = 0.0\n",
    "    model.get_accuracy(reset=True)\n",
    "    for images, labels in tqdm(test_dataloader):\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        with torch.no_grad():\n",
    "            model(images, labels)\n",
    "    accuracy = model.get_accuracy()\n",
    "    return accuracy"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TsP57VG8KEfP"
   },
   "source": [
    "model = YourResNet50(n_classes=ExperimentConfig.N_CLASSES)\n",
    "model.load_state_dict(\n",
    "    torch.load(ExperimentConfig.CKPT_ROOT / f\"{model.__class__.__name__}.pt\")\n",
    ")\n",
    "\n",
    "accuracy = evaluate_task(model, test_dataloader)\n",
    "print(\n",
    "    f\"Оценка за это задание составит {np.clip(10 * accuracy / 0.44, 0, 10):.2f} баллов\"\n",
    ")"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HYo6Rd-bBpJe"
   },
   "source": [
    "# Отчёт об экспериментах\n",
    "\n",
    "* Описание проведенных вами экспериментов\n",
    "* Ссылка на трекер (wandb или любой другой)\n",
    "* Ваши мысли и наблюдения"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cZqSdlQQKukS"
   },
   "source": [
    "## Задание 2\n",
    "\n",
    "5 баллов\n",
    "Добейтесь accuracy на валидации не менее 0.84. В этом задании делать ресайз и использовать претрейн можно.\n",
    "\n",
    "Советы:\n",
    "1. Аугментации\n",
    "2. Предобученные модели (https://pytorch.org/vision/stable/models.html)\n",
    "3. Попробуйте сначала посмотреть качество исходной модели без дообучения, отталкиваться от него как baseline."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zDzXM5rNxNQp"
   },
   "source": [
    "### Импортируйте предобученную модель в наш интерфейс"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "w5uIQi0_aI9b"
   },
   "source": [
    "%%time\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class ExperimentConfig:\n",
    "    TRAIN_ROOT: str = ROOT_PATH / ROOT_PATH / \"train\"\n",
    "    VAL_ROOT: str = ROOT_PATH / ROOT_PATH / \"val\"\n",
    "    CKPT_ROOT: str = GDRIVE_ROOT_PATH\n",
    "\n",
    "    NORMALIZE: bool = True\n",
    "\n",
    "    N_EPOCHS: int = 20\n",
    "    # LR: float = 1e-2\n",
    "    LR: float = 0.5\n",
    "    BATCH_SIZE: int = 32\n",
    "\n",
    "    N_CLASSES = len(os.listdir(ROOT_PATH / ROOT_PATH / \"train\"))\n",
    "\n",
    "    NUM_WORKERS: int = 2\n",
    "\n",
    "    MOMENTUM: Union[float, None] = 0.9\n",
    "    WEIGHT_DECAY: Union[float, None] = 2e-05\n",
    "    ETA_MIN: Union[float, None] = 0.00001\n",
    "    LABEL_SMOOTHING: Union[float, None] = 0.1\n",
    "\n",
    "    if torch.backends.mps.is_available():\n",
    "        DEVICE = torch.device(\"mps\")\n",
    "    elif torch.cuda.is_available():\n",
    "        DEVICE = torch.device(\"cuda\")\n",
    "    else:\n",
    "        DEVICE = torch.device(\"cpu\")\n",
    "\n",
    "    IS_PRETRAINED: bool = True\n",
    "\n",
    "\n",
    "AugmentationHyperparams.RESIZE_HEIGHT = 224\n",
    "AugmentationHyperparams.RESIZE_WIDTH = 224\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class AugmentationHyperparams:\n",
    "    RESIZE_HEIGHT: Union[int, None] = 224\n",
    "    RESIZE_WIDTH: Union[int, None] = 224\n",
    "    RANDOM_CROP_SIZE: int = None\n",
    "    RANDOM_CROP_PADDING: int = None\n",
    "    FLIP_PROB: float = None\n",
    "    ROTATION_DEG: float = None\n",
    "    JITTER_PARAM: float = None\n",
    "    BRIGHTNESS: float = None\n",
    "    CONTRAST: float = None\n",
    "    SATURATION: float = None\n",
    "    HUE: float = None\n",
    "\n",
    "\n",
    "model = YourModel(\n",
    "    n_classes=ExperimentConfig.N_CLASSES, pretrain_mode=PretrainMode.LINEAR_PROBING\n",
    ")\n",
    "experiment = Experiment(\n",
    "    experiment_config=ExperimentConfig(),\n",
    "    augmentation_hyperparams=AugmentationHyperparams,\n",
    ")\n",
    "final_model = experiment.run(model)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QjfWMsmQXkfg"
   },
   "source": [
    "model = YourModel(\n",
    "    arhcitecture=torchvision.models.resnet18,\n",
    "    n_classes=ExperimentConfig.N_CLASSES,\n",
    "    pretrain_mode=PretrainMode.LINEAR_PROBING,\n",
    ")\n",
    "evaluate_task(model, test_dataloader)"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "u5D2bwOKSHVp"
   },
   "source": [
    "### Валидация результатов задания"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PEdwJE5uOrIM"
   },
   "source": [
    "model = YourResNet50(n_classes=ExperimentConfig.N_CLASSES)\n",
    "model.load_state_dict(\n",
    "    torch.load(ExperimentConfig.CKPT_ROOT / f\"{model.__class__.__name__}.pt\")\n",
    ")\n",
    "\n",
    "accuracy = evaluate_task(model, test_dataloader)\n",
    "print(\n",
    "    f\"Оценка за это задание составит {np.clip(10 * (accuracy - 0.5) / 0.34, 0, 10):.2f} баллов\"\n",
    ")"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pT8vfPSolRVb"
   },
   "source": [
    "# Отчёт об экспериментах\n",
    "\n",
    "* Описание проведенных вами экспериментов\n",
    "* Ссылка на трекер (wandb или любой другой)\n",
    "* Ваши мысли и наблюдения"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YkGZ3kuULB55"
   },
   "source": [],
   "outputs": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "max_cell_id": 35
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
